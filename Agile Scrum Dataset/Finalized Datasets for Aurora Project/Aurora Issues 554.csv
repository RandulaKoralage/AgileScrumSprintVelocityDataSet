key,issueType,sprint,status,summary,description,storyPoint,priority,watchcount,fixVersions,affectedVersions,assignee,creator,reporter,commentCount,votes,issueLinks,blockedBy,blocks,dependedOnBy,dependedOn,subtasks
AURORA-350,Story,7,Resolved,Parallelize updates to speed up deploys,"The way aurora deploy works inherently contributes to depressed deploy speeds.Aurora deploy like cap/TCU uses the ""batch"" model. You have 100 things you loop in a batch of N at a time. You restart N things all at once those N things come back online all at once (cold) you wait for the all of them to become available and repeat.Disadvantages:- you can proceed no faster than the slowest guy in the batch. If one instance is ""stuck"" or slow the whole deploy slows down.- The speed at which your deploy is bounded by your success rate which is bounded by the number of instances currently online but serving below par due to warmup (because computers). The batch methodology maximizes this effect because the restarted shards tend to come back online all at the same time.Let's say a full cycle of shutdown reschedule restart wait-for-online-and-good takes 2 minutes but the ""bad time"" is only 15 seconds. If we do these 8 at a time we have a period where 8 boxes are bad for 15 seconds. That's a big success rate spike. What if we were able to 8 of these in parallel such that only one of them is bad at any given moment. It's the same speed (all other things being equal) but the impact is much less. We could leverage that to make the deploy go even faster.It's easy to see that we could speed deploys up by 2x or more by using an algorithm which minimizes the number of instances starting at any given time but still proceeds quickly in parallel.Aurora should be rewritten to use a thread-based deploy model. You have 100 things and N threads. The main thread dispatches (in a blocking fashion if no threads are ready) restart tasks to each thread in a user-set rate-limited fashion (e.g. no more than one per 15 seconds) which is defined by your per instance warmup time (the time an instance is listening/serving but slow). Each thread then restarts one instance waits it to come back healthy and reports done/failure/etc. Continue until the list is exhausted.This way you have a steady stream of single instances coming online with no clumping of restarts and if any one gets hung up or slow it doesn't significantly impact the speed of the deploy (you can ""overprovision"" the number of threads). You can also retain most of the current deploy semantics around failure counts retry intervals etc.",null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,2,0,1,1,1,0,0,0
AURORA-149,Story,7,Resolved,python code should have a checkstyle run as part of the build,null,null,3,4,1,0,Brian Wickman,Jake Farrell,Jake Farrell,4,0,0,0,0,0,0,0
AURORA-421,Task,7,Resolved,H2-backed implementation of QuotaStore,null,null,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-433,Task,7,Resolved,Write a design doc describing the aurora shorthands and init files.,null,null,3,1,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,1,0,0,0,0,0,0,0
AURORA-335,Task,7,Resolved,H2-backed implementation of LockStore,null,null,3,3,1,0,David McLaughlin,Bill Farner,Bill Farner,3,0,0,0,0,0,0,0
AURORA-342,Story,7,Resolved,Remove the non-HTTP thrift port,We don't gain much by serving thrift over two protocols.  HTTP satisfies more use cases so i suggest we allow that to win.,null,4,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-417,Task,7,Resolved,Add API calls needed for new client cron commands,For the aurora client we're separating the client commands to run and kill a job from the client commands to enter and remove a job from the cron schedule. To support this we need to be able to send a request to the scheduler to enter jobs in the cron schedule without running them.,null,3,1,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,1,0,1,1,1,0,0,0
AURORA-438,Story,7,Resolved,Turn on JSHint check during build,Force JSHint failures to break the build. Requires making all existing JS pass the JSHint task currently in Gradle. ,null,3,1,1,0,David McLaughlin,David McLaughlin,David McLaughlin,1,0,0,0,0,0,0,0
AURORA-442,Bug,7,Resolved,Admin SLA commands should be resilient to task queries producing no result,The getTasksStatus RPC results in INVALID_REQUEST when the provided query does not generate any match. Changing the RPC to return an empty result would not make much sense as it would make client logic more complicated elsewhere. The admin sla commands should ignore the error case and produce empty output instead.,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-411,Bug,7,Resolved,On job page 'Running duration' is always 'a few seconds',"Despite jobs running for several hours this column appears to always display ""a few seconds"".",null,3,2,1,0,Suman Karumuri,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-381,Task,7,Resolved,Add a Navbar with Aurora logo on every page,Add a Nav bar with an aurora logo on every page.,null,3,2,1,0,Suman Karumuri,Suman Karumuri,Suman Karumuri,3,0,0,0,0,0,0,0
AURORA-228,Story,7,Resolved,Consider using gradle javascript plugin,http://eriwen.github.io/gradle-js-plugin/This might be a step in the right direction to make the JS part of our build more first-class.,null,5,2,1,0,David McLaughlin,Bill Farner,Bill Farner,4,0,0,0,0,0,0,0
AURORA-384,Story,7,Resolved,Remove cron jobs table from /role page,Remove cron job table from role and role/env page. Show cron jobs just like other jobs. Show the cron job config in the job page. Currently we throw an exception when a job has no tasks. Update the getTasks API so we just return an empty task list instead of throwing an job not found exception. [~wfarner] [~mchucarroll] Can you please weigh in on this. ,null,3,3,1,0,Suman Karumuri,Suman Karumuri,Suman Karumuri,3,0,0,0,0,0,0,0
AURORA-410,Bug,7,Resolved,MetricCalculator thread should block until storage is ready,The SLA stats MetricCalculator thread does not wait until the storage is ready and attempts to run on a non-leading scheduler. This results in the executor thread death and inability to pick up SLA stat calculation on leader change.,null,1,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-368,Bug,7,Resolved,newer pants/commons lib break aurora packaging,Ever since pants and commons library were upgraded we are unable to package gc_executor binary. If it matter we are using OEL6 with py26. Refer to attachment for PANTS_VERBOSE output.https://github.com/apache/incubator-aurora/commit/ddd2329eaefa780a680ed34e1aecb9c5240f03ddIt complain following error:{code}Untranslateable: Package SourcePackage(u'http://protobuf.googlecode.com/files/protobuf-2.5.0.tar.gz') is not translateable.{code},null,3,3,1,1,Brian Wickman,Bhuvaneswaran A,Bhuvaneswaran A,12,0,0,0,0,0,0,0
AURORA-404,Task,7,Resolved,Validate values between UpdateConfig and HealthCheckConfig,With the adoption of server-side health checks and finally honoring initial_interval_secs in the job update we need to put some basic validation in place to make sure the dependencies are sane. Specifically watch_secs > initial_interval_secs.,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-406,Story,7,Resolved,SLA stats should not be in internal TSDB,The recently-added SLA stats are registered as regular gauges which go into the in-memory TSDB.  Since we track SLA stats per job this causes too much heap consumption for large job counts.This can be fixed trivially by exporting stats through StatsProvider#untracked().  This will cause values to show on /vars and /vars.json but not be tracked in the TSDB.,null,2,2,1,0,Maxim Khutornenko,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-378,Task,7,Resolved,Add config grouping visualisation to job page,As a user I'd like to be able to quickly visualise any differences in my job configurations across multiple instances. This could help me identify canaries or other special instances as well as serving as a progress bar during job updates.,null,3,3,1,0,David McLaughlin,David McLaughlin,David McLaughlin,3,0,0,0,0,0,0,0
AURORA-350,Story,11,Resolved,Parallelize updates to speed up deploys,"The way aurora deploy works inherently contributes to depressed deploy speeds.Aurora deploy like cap/TCU uses the ""batch"" model. You have 100 things you loop in a batch of N at a time. You restart N things all at once those N things come back online all at once (cold) you wait for the all of them to become available and repeat.Disadvantages:- you can proceed no faster than the slowest guy in the batch. If one instance is ""stuck"" or slow the whole deploy slows down.- The speed at which your deploy is bounded by your success rate which is bounded by the number of instances currently online but serving below par due to warmup (because computers). The batch methodology maximizes this effect because the restarted shards tend to come back online all at the same time.Let's say a full cycle of shutdown reschedule restart wait-for-online-and-good takes 2 minutes but the ""bad time"" is only 15 seconds. If we do these 8 at a time we have a period where 8 boxes are bad for 15 seconds. That's a big success rate spike. What if we were able to 8 of these in parallel such that only one of them is bad at any given moment. It's the same speed (all other things being equal) but the impact is much less. We could leverage that to make the deploy go even faster.It's easy to see that we could speed deploys up by 2x or more by using an algorithm which minimizes the number of instances starting at any given time but still proceeds quickly in parallel.Aurora should be rewritten to use a thread-based deploy model. You have 100 things and N threads. The main thread dispatches (in a blocking fashion if no threads are ready) restart tasks to each thread in a user-set rate-limited fashion (e.g. no more than one per 15 seconds) which is defined by your per instance warmup time (the time an instance is listening/serving but slow). Each thread then restarts one instance waits it to come back healthy and reports done/failure/etc. Continue until the list is exhausted.This way you have a steady stream of single instances coming online with no clumping of restarts and if any one gets hung up or slow it doesn't significantly impact the speed of the deploy (you can ""overprovision"" the number of threads). You can also retain most of the current deploy semantics around failure counts retry intervals etc.",null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,2,0,1,1,1,0,0,0
AURORA-149,Story,11,Resolved,python code should have a checkstyle run as part of the build,null,null,3,4,1,0,Brian Wickman,Jake Farrell,Jake Farrell,4,0,0,0,0,0,0,0
AURORA-421,Task,11,Resolved,H2-backed implementation of QuotaStore,null,null,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-433,Task,11,Resolved,Write a design doc describing the aurora shorthands and init files.,null,null,3,1,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,1,0,0,0,0,0,0,0
AURORA-408,Task,11,Resolved,"Update client ""job"" commands to remove cron-related behavior.",null,null,3,3,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,13,0,1,1,1,0,0,0
AURORA-496,Task,11,Resolved,Modify config binding helper registration in clientv2,Config binding helpers (components that add macros to the pystachioconfig language) were registered in a way that used self-construction. In practice binding helpers need initialization that comes from command-line parameters. With the implicit construction method we can't provide construction parameters to the helpers.We need to switches to an explicit construction/registration insteadof auto-construction when the class is registered. (Interestingly thisis the way that the documentation on the binding helpers code says thatit works!)Instead of writing:         FooHelper.register()We should write:        BindingHelper.register(FooHelper())Which makes it possible to do:       BindingHelper.register(FooHelper(url=bar)),null,3,1,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,1,0,0,0,0,0,0,0
AURORA-335,Task,11,Resolved,H2-backed implementation of LockStore,null,null,3,3,1,0,David McLaughlin,Bill Farner,Bill Farner,3,0,0,0,0,0,0,0
AURORA-342,Story,11,Resolved,Remove the non-HTTP thrift port,We don't gain much by serving thrift over two protocols.  HTTP satisfies more use cases so i suggest we allow that to win.,null,4,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-417,Task,11,Resolved,Add API calls needed for new client cron commands,For the aurora client we're separating the client commands to run and kill a job from the client commands to enter and remove a job from the cron schedule. To support this we need to be able to send a request to the scheduler to enter jobs in the cron schedule without running them.,null,3,1,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,1,0,1,1,1,0,0,0
AURORA-438,Story,11,Resolved,Turn on JSHint check during build,Force JSHint failures to break the build. Requires making all existing JS pass the JSHint task currently in Gradle. ,null,3,1,1,0,David McLaughlin,David McLaughlin,David McLaughlin,1,0,0,0,0,0,0,0
AURORA-442,Bug,11,Resolved,Admin SLA commands should be resilient to task queries producing no result,The getTasksStatus RPC results in INVALID_REQUEST when the provided query does not generate any match. Changing the RPC to return an empty result would not make much sense as it would make client logic more complicated elsewhere. The admin sla commands should ignore the error case and produce empty output instead.,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-479,Task,11,Resolved,Drop restart_threshold > watch_secs validation in UpdateConfig,"The ""restart_threshold > watch_secs"" validation introduced as a part of AURORA-404 is not necessary. While having an elevated restart_threshold value for a larger service is logical having it tied to watch_secs is not. A counter example could be a CPU-demanding service that takes just a few seconds to become healthy (low watch_secs) but takes long(er) to get scheduled (restart_threshold).",null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-407,Task,11,Resolved,"Implement clientv2 ""cron"" noun.",null,null,3,1,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,1,0,2,2,2,0,0,0
AURORA-449,Story,11,Resolved,Upgrade to Bootstrap 3,null,null,3,2,1,0,Suman Karumuri,Chris Lambert,Chris Lambert,1,0,0,0,0,0,0,0
AURORA-425,Task,11,Resolved,Merge Active and completed tasks on job page into a single table,"Merge active and completed tasks on job page into a single table. Put the table in a tabbed panel with the following tabs ""All"" ""Active"" and ""Completed"".  Selecting all should show all tasks active should show active tasks and completed should show completed tasks. Default selected tab should be ""Active"".",null,3,2,1,0,Suman Karumuri,Suman Karumuri,Suman Karumuri,3,0,0,0,0,0,0,0
AURORA-390,Task,11,Resolved,UI should be able to query any scheduler backend,"Currently we test the scheduler UI with the test data generated from the IsolatedSchedulerModule. While this is useful for basic testing the data generated is of poor quality and is leading to many bugs that are discovered late. It would be awesome if the UI on my laptop can query any scheduler backend. For example if the UI can query a test or a staging environment we can test the UI with real data without an elaborate setup process. Further it would simplify debugging prod issues and this will also take us closer to making the UI a separate self hosted service to run e2e tests. Currently the UI on the scheduler can only query the scheduler which is hosting the UI because the /api end point doesn't allow CORS calls. If we want to enable this we have 2 options: a) Enable CORS support on /api end point by adding "" Access-Control-Allow-Origin: *"" header.b) Make a JSON-P call from the UI front end to the backend. Since we make the Ajax calls to the backend using thrift library we need to bypass the ajax stuff in the thrift library by writing our own wrapper around the thrift library to make the calls using JSON-P. (like the angular-thrift library[1]).Since any script can already query the JSON end point and since it less risky and simple change I am leaning towards a).[~wfarner][~davmclau] and [~kevints] Please weigh in.[1] https://github.com/massaroni/angular-thrift",null,3,3,1,0,Suman Karumuri,Suman Karumuri,Suman Karumuri,11,0,0,0,0,0,0,0
AURORA-447,Bug,11,Resolved,Cron changes broke python thrift test,src/test/python/apache/aurora/config/test_thrift.py F.........=================================== FAILURES ===================================______________________________ test_simple_config ______________________________    def test_simple_config():      job = convert_pystachio_to_thrift(HELLO_WORLD)      assert job.instanceCount == 1      tti = job.taskConfig      assert job.key == JobKey(        role=HELLO_WORLD.role().get()        environment=HELLO_WORLD.environment().get()        name=HELLO_WORLD.name().get())      assert job.owner == Identity(role=HELLO_WORLD.role().get() user=getpass.getuser())>     assert job.cronSchedule == ''E     assert None == ''E      +  where None = JobConfiguration(instanceCount=1 cronSchedule=None cronCollisionPolicy=0 ke...01 constraints=set([])) owner=Identity(role=u'john_doe' user='mchucarroll')).cronSchedulesrc/test/python/apache/aurora/config/test_thrift.py:56: AssertionError====================== 1 failed 9 passed in 1.55 seconds ======================,null,3,3,1,0,Kevin Sweeney,Mark Chu-Carroll,Mark Chu-Carroll,2,0,0,0,0,0,0,0
AURORA-446,Task,11,Resolved,Remove --groups_per_batch option from the perform_maintenace_hosts,This option is not useful and will interfere with the upcoming SLA enhancements.,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-441,Task,11,Resolved,Add grouping option into admin SLA commands,Admin SLA commands would benefit from a --grouping option similar to host maintenance commands. This would allow arbitrary (more than 1 host) downtime simulations.,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-452,Bug,11,Resolved,End-to-end tests fail on release distributions,Vagrant-based tests currently assume that /vagrant is a git repository and try to do things like clone it.  In a release distribution /vagrant is just a snapshot of our repository.,null,1,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-484,Task,11,Resolved,"Add a ""developing aurora client"" document.",null,null,3,2,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,1,0,1,0,0,0,0,0
AURORA-31,Story,11,Resolved,Support an authentication mechanism for client-scheduler communication,Aurora has the plumbing for authenticated requests but no system is currently implemented.,null,3,2,1,0,null,Kevin Sweeney,Kevin Sweeney,0,0,2,0,0,0,0,0
AURORA-520,Task,13,Resolved,"Update ""aurora job diff""","Users complain because the ""aurora job diff"" command doesn't work the way they'd like it to. In its current form it's got two major problems.(1) It reports spurious differences between running jobs and local configurations due to automatically filled fields that shouldn't be part of the comparison. For example a job config specifies who created using an Identity record which has two fields: the rolename running the job and the username of the person who ran the command. For comparing live jobs against local configs that's irrelevant.(2) The diffs are very hard to read. Diffs are generated by downloading the running task configs for a job and writing them to the disk in json; then uploading the local config getting *it* converted to thrift and writing that to the disk in json and then running the Unix diff command on the two json files.Unix diff isn't the most pleasant thing to read under the best of circumstances. But making matters worse the entire json format of the files being diffed is unfamiliar to users! So they're looking at a hard-to-read diff syntax ranging over an unfamiliar data syntax.To fix this I'd like to replace the use of Unix diff. The json records for the configs are semantically just trees. Writing a comparison function that compares corresponding trees is pretty easy and can generate *much* better diffs. An example of the diff to be generated by this code would be something like the following - assuming that the local config increases the number of instances from 2 to 3 and the CPU request from 2 to 4:{noformat}Local config has a different number of tasks: 3 local vs 2 runningTask diffs found in instance 1:    Field 'numCpus' is '4' local but '2' remote2 total diff(s) found{noformat}",null,3,1,0,0,null,Mark Chu-Carroll,Mark Chu-Carroll,1,0,1,0,0,0,0,0
AURORA-571,Bug,15,Resolved,Admin maintenance fails SLA check when no prod tasks on host,Return value of _check_sla() is not initialized when no eligible tasks are found on host (e.g. non-prod/low instance count).,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-94,Task,15,Resolved,Refactor/remove SchedulerCore in favor of StateManager,SchedulerCore does not seem to provide much value and serves as a thin proxy primarily between SchedulerThriftInterface and StateManager.,null,4,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,3,0,0,0,0,0,0,0
AURORA-544,Task,15,Resolved,Add an option to allow users to specify log levels in client,null,null,3,1,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,1,0,0,0,0,0,0,0
AURORA-545,Task,15,Resolved,Add a flag to allow users to prevent blocking of unknown exceptions in client,null,null,3,1,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,1,0,0,0,0,0,0,0
AURORA-350,Story,15,Resolved,Parallelize updates to speed up deploys,"The way aurora deploy works inherently contributes to depressed deploy speeds.Aurora deploy like cap/TCU uses the ""batch"" model. You have 100 things you loop in a batch of N at a time. You restart N things all at once those N things come back online all at once (cold) you wait for the all of them to become available and repeat.Disadvantages:- you can proceed no faster than the slowest guy in the batch. If one instance is ""stuck"" or slow the whole deploy slows down.- The speed at which your deploy is bounded by your success rate which is bounded by the number of instances currently online but serving below par due to warmup (because computers). The batch methodology maximizes this effect because the restarted shards tend to come back online all at the same time.Let's say a full cycle of shutdown reschedule restart wait-for-online-and-good takes 2 minutes but the ""bad time"" is only 15 seconds. If we do these 8 at a time we have a period where 8 boxes are bad for 15 seconds. That's a big success rate spike. What if we were able to 8 of these in parallel such that only one of them is bad at any given moment. It's the same speed (all other things being equal) but the impact is much less. We could leverage that to make the deploy go even faster.It's easy to see that we could speed deploys up by 2x or more by using an algorithm which minimizes the number of instances starting at any given time but still proceeds quickly in parallel.Aurora should be rewritten to use a thread-based deploy model. You have 100 things and N threads. The main thread dispatches (in a blocking fashion if no threads are ready) restart tasks to each thread in a user-set rate-limited fashion (e.g. no more than one per 15 seconds) which is defined by your per instance warmup time (the time an instance is listening/serving but slow). Each thread then restarts one instance waits it to come back healthy and reports done/failure/etc. Continue until the list is exhausted.This way you have a steady stream of single instances coming online with no clumping of restarts and if any one gets hung up or slow it doesn't significantly impact the speed of the deploy (you can ""overprovision"" the number of threads). You can also retain most of the current deploy semantics around failure counts retry intervals etc.",null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,2,0,1,1,1,0,0,0
AURORA-377,Bug,15,Resolved,No Veto reason is exposed for a task stuck in PENDING due to host constraints,Tasks stuck in PENDING state due to unsatisfied host constraint don't have the reason set in TaskEvent.message. This makes the troubleshooting harder as neither UI nor aurora status can give any clues:{noformat}INFO] role: mesos env: test name: monitoring shard: 147 status: PENDING on Nonecpus: 0.5 ram: 512 MB disk: 3072 MBfailure count: 0 (max 1)events: 2014-05-02 09:05:43 PENDING: Nonemetadata:package: mesos/monitoring v14{noformat},null,3,3,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,3,1,1,0,0,0,0,0
AURORA-553,Task,15,Resolved,Switch to getTasksWithoutConfig RPC on the client where applicable,Client commands/APIs that don't require TaskConfig data should be switched from getTasksConfig to getTasksWithoutConfig RPC for better perf.,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-149,Story,15,Resolved,python code should have a checkstyle run as part of the build,null,null,3,4,1,0,Brian Wickman,Jake Farrell,Jake Farrell,4,0,0,0,0,0,0,0
AURORA-421,Task,15,Resolved,H2-backed implementation of QuotaStore,null,null,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-433,Task,15,Resolved,Write a design doc describing the aurora shorthands and init files.,null,null,3,1,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,1,0,0,0,0,0,0,0
AURORA-408,Task,15,Resolved,"Update client ""job"" commands to remove cron-related behavior.",null,null,3,3,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,13,0,1,1,1,0,0,0
AURORA-496,Task,15,Resolved,Modify config binding helper registration in clientv2,Config binding helpers (components that add macros to the pystachioconfig language) were registered in a way that used self-construction. In practice binding helpers need initialization that comes from command-line parameters. With the implicit construction method we can't provide construction parameters to the helpers.We need to switches to an explicit construction/registration insteadof auto-construction when the class is registered. (Interestingly thisis the way that the documentation on the binding helpers code says thatit works!)Instead of writing:         FooHelper.register()We should write:        BindingHelper.register(FooHelper())Which makes it possible to do:       BindingHelper.register(FooHelper(url=bar)),null,3,1,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,1,0,0,0,0,0,0,0
AURORA-318,Story,15,Resolved,Improve documentation and unit testing for Host Maintenance API,There is little documentation to explain the host maintenance API as well as little test coverage. This should be improved to help facilitate usage as well as future improvements.,null,4,2,1,0,Joe Smith,Joe Smith,Joe Smith,3,0,0,0,0,0,0,0
AURORA-473,Story,15,Resolved,V2 client lacks informative output when updating,This is visible in the end-to-end tests where the v1 client displays job update progress:{noformat}+ vagrant ssh -c 'aurora update devcluster/vagrant/test/http_example /vagrant/src/test/sh/org/apache/aurora/e2e/http/http_example_updated.aurora' INFO] Updating job: http_example INFO] Starting job update. INFO] Examining instances: [0] INFO] Killing instances: [0] INFO] Instances killed INFO] Adding instances: [0] INFO] Instances added INFO] Watching instances: [0] INFO] Detected RUNNING instance 0{noformat}The v2 client lacks this:{noformat}+ vagrant ssh -c 'aurora2 job update devcluster/vagrant/test/http_example /vagrant/src/test/sh/org/apache/aurora/e2e/http/http_example_updated.aurora'Warning: this update is a large change. Press ^C within 5 seconds to abort++ vagrant ssh -c 'aurora2 task run devcluster/vagrant/test/http_example '\''pwd'\'''{noformat},null,3,2,1,0,Mark Chu-Carroll,Bill Farner,Bill Farner,6,0,0,0,0,0,0,0
AURORA-502,Bug,15,Resolved,Aurora2 binary needs to reference admin commands,The aurora2 binary is missing admin commands that have to be otherwise imported from the client v1 lib thus resulting in a version conflict.,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-497,Bug,15,Resolved,Client V2 does not suppress unhandled error stack trace,While testing client v2 I noticed that a KeyboardInterrupt results in a unsuppressed stack trace. The CommandLine should implement logic similar to twitter.common.app: https://github.com/twitter/commons/blob/master/src/python/twitter/common/app/application.py#L735-L753,null,3,2,1,0,Mark Chu-Carroll,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-428,Task,15,Resolved,Allow project override in list-missing-shipits script,null,null,4,1,1,0,David McLaughlin,Dominic Hamon,Dominic Hamon,1,0,0,0,0,0,0,0
AURORA-445,Task,15,Resolved,Admin perform_maintenance_hosts to check job SLA before draining,The perform_maintenance_hosts needs to support hardcoded SLA values with a possibility of an override. The override must require a ΓÇ£sudoΓÇ¥ message explaining the override reason.,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-437,Bug,15,Resolved,aurora clientv2 help is malformed,"Seem to be doing '\n'.join(string) instead of '\n'.join(list of strings) somewhere:{noformat}$ aurora-beta help job statusUsage for verb ""job status"":  s  t  a  t  u  s     [  -  -  w  r  i  t  e  -  j  s  o  n  ]     v  a  l  u  eOptions:  --write-json  Generate command output in JSON format  jobspec=value    --aurora_cluster_config=value  Cluster config file  --no-no_socks_always_proxy  Always create a proxy if no proxies are supplied.  Proxies via --tunnel_host.  --socks_proxy=PROXY_ADDR  Attempt to proxy all connections through the socks proxy at PROXY_ADDR  --socks_resolve=['local' 'remote']  LOCATION to perform DNS resolution where LOCATION is one of ['local' 'remote']  --tunnel_host=str  Host to tunnel commands through (default: %(default))Get status information about a scheduled job or group of jobs.The jobspec parameter can omit parts of the jobkey or use shell-style globs.{noformat}",null,3,1,1,0,Mark Chu-Carroll,Brian Wickman,Brian Wickman,0,0,1,0,0,0,0,0
AURORA-439,Bug,15,Resolved,stacktrace from 'aurora sla get-job-uptime -h',"{noformat}mba=~=; aurora-beta sla get-job-uptime -hTraceback (most recent call last):  File ""/Users/wickman/Python/CPython-2.6.9/lib/python2.6/runpy.py"" line 122 in _run_module_as_main    ""__main__"" fname loader pkg_name)  File ""/Users/wickman/Python/CPython-2.6.9/lib/python2.6/runpy.py"" line 34 in _run_code    exec code in run_globals  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/__main__.py"" line 24 in <module>    bootstrap_pex(__entry_point__)  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/.bootstrap/_twitter_common_python/pex_bootstrapper.py"" line 47 in bootstrap_pex    pex.PEX(entry_point).execute()  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/.bootstrap/_twitter_common_python/pex.py"" line 137 in execute    self.execute_entry(entry_point args)  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/.bootstrap/_twitter_common_python/pex.py"" line 167 in execute_entry    runner(entry_point)  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/.bootstrap/_twitter_common_python/pex.py"" line 190 in execute_pkg_resources    runner()  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/twitter/aurora/client/cli_internal/client.py"" line 191 in proxy_main    bridge.execute(sys.argv)  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/.deps/apache.aurora.clientv2-0.5.1_DEV1400185041-py2.6.egg/apache/aurora/client/cli/bridge.py"" line 90 in execute    return cl.execute(args)  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/twitter/aurora/client/cli_internal/client.py"" line 165 in execute    return self.commandline.execute(args[1:])  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/.deps/apache.aurora.clientv2-0.5.1_DEV1400185041-py2.6.egg/apache/aurora/client/cli/__init__.py"" line 378 in execute    noun context = self._parse_args(args)  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/.deps/apache.aurora.clientv2-0.5.1_DEV1400185041-py2.6.egg/apache/aurora/client/cli/__init__.py"" line 331 in _parse_args    options = self.parser.parse_args(args)  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/.deps/argparse-1.2.1-py2.6.egg/argparse.py"" line 1703 in parse_args    args argv = self.parse_known_args(args namespace)  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/.deps/argparse-1.2.1-py2.6.egg/argparse.py"" line 1735 in parse_known_args    namespace args = self._parse_known_args(args namespace)  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/.deps/argparse-1.2.1-py2.6.egg/argparse.py"" line 1923 in _parse_known_args    positionals_end_index = consume_positionals(start_index)  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/.deps/argparse-1.2.1-py2.6.egg/argparse.py"" line 1900 in consume_positionals    take_action(action args)  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/.deps/argparse-1.2.1-py2.6.egg/argparse.py"" line 1809 in take_action    action(self namespace argument_values option_string)  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/.deps/argparse-1.2.1-py2.6.egg/argparse.py"" line 1111 in __call__    namespace arg_strings = parser.parse_known_args(arg_strings namespace)  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/.deps/argparse-1.2.1-py2.6.egg/argparse.py"" line 1735 in parse_known_args    namespace args = self._parse_known_args(args namespace)  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/.deps/argparse-1.2.1-py2.6.egg/argparse.py"" line 1923 in _parse_known_args    positionals_end_index = consume_positionals(start_index)  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/.deps/argparse-1.2.1-py2.6.egg/argparse.py"" line 1900 in consume_positionals    take_action(action args)  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/.deps/argparse-1.2.1-py2.6.egg/argparse.py"" line 1809 in take_action    action(self namespace argument_values option_string)  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/.deps/argparse-1.2.1-py2.6.egg/argparse.py"" line 1111 in __call__    namespace arg_strings = parser.parse_known_args(arg_strings namespace)  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/.deps/argparse-1.2.1-py2.6.egg/argparse.py"" line 1735 in parse_known_args    namespace args = self._parse_known_args(args namespace)  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/.deps/argparse-1.2.1-py2.6.egg/argparse.py"" line 1941 in _parse_known_args    start_index = consume_optional(start_index)  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/.deps/argparse-1.2.1-py2.6.egg/argparse.py"" line 1881 in consume_optional    take_action(action args option_string)  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/.deps/argparse-1.2.1-py2.6.egg/argparse.py"" line 1809 in take_action    action(self namespace argument_values option_string)  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/.deps/argparse-1.2.1-py2.6.egg/argparse.py"" line 1015 in __call__    parser.print_help()  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/.deps/argparse-1.2.1-py2.6.egg/argparse.py"" line 2328 in print_help    self._print_message(self.format_help() file)  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/.deps/argparse-1.2.1-py2.6.egg/argparse.py"" line 2302 in format_help    return formatter.format_help()  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/.deps/argparse-1.2.1-py2.6.egg/argparse.py"" line 300 in format_help    help = self._root_section.format_help()  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/.deps/argparse-1.2.1-py2.6.egg/argparse.py"" line 230 in format_help    func(*args)  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/.deps/argparse-1.2.1-py2.6.egg/argparse.py"" line 230 in format_help    func(*args)  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/.deps/argparse-1.2.1-py2.6.egg/argparse.py"" line 536 in _format_action    help_text = self._expand_help(action)  File ""/Users/wickman/.tools-cache/home/mesos/tools/client-beta/libexec/aurora-client-beta/.deps/argparse-1.2.1-py2.6.egg/argparse.py"" line 622 in _expand_help    return self._get_help_string(action) % paramsValueError: unsupported format character ')' (0x29) at index 52{noformat}",null,3,2,1,0,Mark Chu-Carroll,Brian Wickman,Brian Wickman,1,0,0,0,0,0,0,0
AURORA-503,Bug,15,Resolved,clientv2 DistributedCommandRunner is missing a symbol,"{noformat}  def resolve(self):    resp = self._api.query(self.query_from(self._role self._env self._job self.instances))    if resp.responseCode == ResponseCode.OK:      for task in resp.result.scheduleStatusResult.tasks:        yield task    else:      print_aurora_log(logging.ERROR          ""Error: could not retrieve task information for run command: %s"" % resp.messageDEPRECATED)      raise ValueError(""Could not retrieve task information: %s"" % resp.messageDEPRECATED){noformat}print_aurora_log is an undefined symbol here.  there's a version of it defined in apache.aurora.client.cli but including it would make for a cyclic dependency between .api and .cli.",null,3,1,1,0,Mark Chu-Carroll,Brian Wickman,Brian Wickman,0,0,0,0,0,0,0,0
AURORA-505,Task,15,Resolved,Add a target for a standalone clientv2,null,null,3,1,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,1,0,0,0,0,0,0,0
AURORA-508,Task,15,Resolved,Fix ugliness in aurora help,"""aurora help"" currently has some aesthetic issues:- in some places the default name for a parameter is used: 'job status [--write-json] value'; metavars should be used to fill that in.- In usage lists (like ""aurora help job"") the long list of usage lines is difficult to follow; blank lines in between would make it clearer.- In some cases strings aren't getting handled properly resulting in lists of characters isntead of strings (eg ""aurora help job create"")",null,3,1,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,0,0,0,0,0,0,0,0
AURORA-513,Bug,15,Resolved,Errors during thrift RPC calls cause ugly stack dumps,"Anonymized error message below. The user did an update; during the course of the update what appears to be a transient network glitch caused a thrift socket to become None which led to an invalid attempt to dereference None which caused a stack dump. The actual error is in thrift-generated code. INFO] Examining instances: [360 361 362 363 364 365] INFO] Adding instances: [360 361 362 363 364 365] INFO] Instances added INFO] Watching instances: [360 361 362 363 364 365]Traceback (most recent call last):  File ""...aurora-client/twitter/common/app/application.py"" line 738 in _wrap_method    return_code = method()  File ""...aurora-client/twitter/common/app/application.py"" line 760 in <lambda>    main = lambda: main_method(*args **kwargs)  File ""...aurora-client/.deps/apache.aurora.clientv2-0.5.1_DEV1401741199-py2.6.egg/apache/aurora/client/base.py"" line 72 in wrapped_function    return fn(*args)  File ""...aurora-client/.deps/apache.aurora.clientv2-0.5.1_DEV1401741199-py2.6.egg/apache/aurora/client/commands/core.py"" line 614 in update    resp = api.update_job(config options.health_check_interval_seconds options.shards)  File ""...aurora-client/.deps/apache.aurora.clientv2-0.5.1_DEV1401741199-py2.6.egg/apache/aurora/client/hooks/hooked_api.py"" line 184 in update_job    config health_check_interval_seconds=health_check_interval_seconds instances=instances))  File ""...aurora-client/.deps/apache.aurora.clientv2-0.5.1_DEV1401741199-py2.6.egg/apache/aurora/client/hooks/hooked_api.py"" line 145 in _hooked_call    resp = api_call()  File ""...aurora-client/.deps/apache.aurora.clientv2-0.5.1_DEV1401741199-py2.6.egg/apache/aurora/client/api/__init__.py"" line 128 in update_job    return updater.update(instances)  File ""...aurora-client/.deps/apache.aurora.clientv2-0.5.1_DEV1401741199-py2.6.egg/apache/aurora/client/api/updater.py"" line 455 in update    if not self._update(instance_configs):  File ""...aurora-client/.deps/apache.aurora.clientv2-0.5.1_DEV1401741199-py2.6.egg/apache/aurora/client/api/updater.py"" line 143 in _update    failed_instances = self._watcher.watch(instances_to_watch) if instances_to_watch else set()  File ""...aurora-client/.deps/apache.aurora.clientv2-0.5.1_DEV1401741199-py2.6.egg/apache/aurora/client/api/instance_watcher.py"" line 95 in watch    running_tasks = self._get_tasks_by_instance_id(instance_ids)  File ""...aurora-client/.deps/apache.aurora.clientv2-0.5.1_DEV1401741199-py2.6.egg/apache/aurora/client/api/instance_watcher.py"" line 134 in _get_tasks_by_instance_id    resp = self._scheduler.getTasksStatus(query)  File ""...aurora-client/.deps/apache.aurora.clientv2-0.5.1_DEV1401741199-py2.6.egg/apache/aurora/client/api/scheduler_client.py"" line 264 in method_wrapper    return method(*(args + auth_args))  File ""...aurora-client/.deps/apache.gen.aurora-0.5.1_DEV1401741199-py2.6.egg/gen/apache/aurora/api/ReadOnlyScheduler.py"" line 129 in getTasksStatus    return self.recv_getTasksStatus()  File ""...aurora-client/.deps/apache.gen.aurora-0.5.1_DEV1401741199-py2.6.egg/gen/apache/aurora/api/ReadOnlyScheduler.py"" line 140 in recv_getTasksStatus    (fname mtype rseqid) = self._iprot.readMessageBegin()  File ""...aurora-client/.deps/thrift-0.9.1-py2.6-macosx-10.4-x86_64.egg/thrift/protocol/TJSONProtocol.py"" line 317 in readMessageBegin    self.readJSONArrayStart()  File ""...aurora-client/.deps/thrift-0.9.1-py2.6-macosx-10.4-x86_64.egg/thrift/protocol/TJSONProtocol.py"" line 305 in readJSONArrayStart    self.readJSONSyntaxChar(LBRACKET)  File ""...aurora-client/.deps/thrift-0.9.1-py2.6-macosx-10.4-x86_64.egg/thrift/protocol/TJSONProtocol.py"" line 210 in readJSONSyntaxChar    current = self.reader.read()  File ""...aurora-client/.deps/thrift-0.9.1-py2.6-macosx-10.4-x86_64.egg/thrift/protocol/TJSONProtocol.py"" line 139 in read    self.data = self.protocol.trans.read(1)  File ""...aurora-client/.deps/thrift-0.9.1-py2.6-macosx-10.4-x86_64.egg/thrift/transport/THttpClient.py"" line 97 in read    return self.__http.file.read(sz)AttributeError: 'NoneType' object has no attribute 'read'",null,3,2,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,2,0,0,0,0,0,0,0
AURORA-516,Task,15,Resolved,Increase maximum instances/job in aurora scheduler,We've got a user that needs more than 4000 instances of a job. This limit is hard-wired into the scheduler so we need to update it.,null,3,2,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,2,0,0,0,0,0,0,0
AURORA-347,Story,15,Resolved,CLI should surface information about locks,Client should be able to list information about locks held.,null,4,2,1,0,Maxim Khutornenko,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-528,Task,15,Resolved,Document available SLA metrics,Add an .md doc describing available SLA stats and their meanings.,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-537,Bug,15,Resolved,SLA safe domain host-scoped falls back to cluster-wide when no tasks returned,It's possible for the host-scoped query to not return any tasks which currently results in a follow-up no-filter full cluster pull. This is highly undesirable for perf reasons.,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-539,Task,15,Resolved,Create a getTaskStatusLight RPC,We need a lightweight API to be used by UI and client in places where ExecutorConfig data is not not required. The sheer size of it slows down a large job pull to a crawl. This is especially sensible now that we switched from binary to json transport. ,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,1,0,0,0,0,0
AURORA-542,Task,15,Resolved,perform_maintenance_hosts should drain hosts that passed SLA check,When using a non-default grouping with perform_maintenance_hosts the entire collection of hosts is skipped in case SLA check fails. Change it to proceed with SLA-compliant hosts instead.  ,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-31,Story,15,Resolved,Support an authentication mechanism for client-scheduler communication,Aurora has the plumbing for authenticated requests but no system is currently implemented.,null,3,2,1,0,null,Kevin Sweeney,Kevin Sweeney,0,0,2,0,0,0,0,0
AURORA-520,Task,23,Resolved,"Update ""aurora job diff""","Users complain because the ""aurora job diff"" command doesn't work the way they'd like it to. In its current form it's got two major problems.(1) It reports spurious differences between running jobs and local configurations due to automatically filled fields that shouldn't be part of the comparison. For example a job config specifies who created using an Identity record which has two fields: the rolename running the job and the username of the person who ran the command. For comparing live jobs against local configs that's irrelevant.(2) The diffs are very hard to read. Diffs are generated by downloading the running task configs for a job and writing them to the disk in json; then uploading the local config getting *it* converted to thrift and writing that to the disk in json and then running the Unix diff command on the two json files.Unix diff isn't the most pleasant thing to read under the best of circumstances. But making matters worse the entire json format of the files being diffed is unfamiliar to users! So they're looking at a hard-to-read diff syntax ranging over an unfamiliar data syntax.To fix this I'd like to replace the use of Unix diff. The json records for the configs are semantically just trees. Writing a comparison function that compares corresponding trees is pretty easy and can generate *much* better diffs. An example of the diff to be generated by this code would be something like the following - assuming that the local config increases the number of instances from 2 to 3 and the CPU request from 2 to 4:{noformat}Local config has a different number of tasks: 3 local vs 2 runningTask diffs found in instance 1:    Field 'numCpus' is '4' local but '2' remote2 total diff(s) found{noformat}",null,3,1,0,0,null,Mark Chu-Carroll,Mark Chu-Carroll,1,0,1,0,0,0,0,0
AURORA-571,Bug,23,Resolved,Admin maintenance fails SLA check when no prod tasks on host,Return value of _check_sla() is not initialized when no eligible tasks are found on host (e.g. non-prod/low instance count).,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-94,Task,23,Resolved,Refactor/remove SchedulerCore in favor of StateManager,SchedulerCore does not seem to provide much value and serves as a thin proxy primarily between SchedulerThriftInterface and StateManager.,null,4,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,3,0,0,0,0,0,0,0
AURORA-544,Task,23,Resolved,Add an option to allow users to specify log levels in client,null,null,3,1,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,1,0,0,0,0,0,0,0
AURORA-545,Task,23,Resolved,Add a flag to allow users to prevent blocking of unknown exceptions in client,null,null,3,1,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,1,0,0,0,0,0,0,0
AURORA-581,Task,23,Resolved,Add lightweight hooks for mutating clientv1 commands.,Aurora clientv2 commands currently support very flexible hooks which get used for a variety of purposes. One of the most popular usecases is as a safety-check mechanism: hooks can add extra safety checks to commands that mutate or kill aurora jobs. Unfortunately these hooks are clientv2 only. Once we've got users transitioned to clientv2 that will be fine but for now clientv1 is acting as a backdoor to allow users to bypass hooks.Cluster administrators should have the ability to prevent this by applying some kind of hooks to the aurora commands that mutate jobs. At the same time we don't want to provide the same level of support for hooks that we have in v2 so the v1 hooks should be simpler and lighter-weight since they're  just a temporary stopgap.,null,3,1,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,0,0,0,0,0,0,0,0
AURORA-350,Story,23,Resolved,Parallelize updates to speed up deploys,"The way aurora deploy works inherently contributes to depressed deploy speeds.Aurora deploy like cap/TCU uses the ""batch"" model. You have 100 things you loop in a batch of N at a time. You restart N things all at once those N things come back online all at once (cold) you wait for the all of them to become available and repeat.Disadvantages:- you can proceed no faster than the slowest guy in the batch. If one instance is ""stuck"" or slow the whole deploy slows down.- The speed at which your deploy is bounded by your success rate which is bounded by the number of instances currently online but serving below par due to warmup (because computers). The batch methodology maximizes this effect because the restarted shards tend to come back online all at the same time.Let's say a full cycle of shutdown reschedule restart wait-for-online-and-good takes 2 minutes but the ""bad time"" is only 15 seconds. If we do these 8 at a time we have a period where 8 boxes are bad for 15 seconds. That's a big success rate spike. What if we were able to 8 of these in parallel such that only one of them is bad at any given moment. It's the same speed (all other things being equal) but the impact is much less. We could leverage that to make the deploy go even faster.It's easy to see that we could speed deploys up by 2x or more by using an algorithm which minimizes the number of instances starting at any given time but still proceeds quickly in parallel.Aurora should be rewritten to use a thread-based deploy model. You have 100 things and N threads. The main thread dispatches (in a blocking fashion if no threads are ready) restart tasks to each thread in a user-set rate-limited fashion (e.g. no more than one per 15 seconds) which is defined by your per instance warmup time (the time an instance is listening/serving but slow). Each thread then restarts one instance waits it to come back healthy and reports done/failure/etc. Continue until the list is exhausted.This way you have a steady stream of single instances coming online with no clumping of restarts and if any one gets hung up or slow it doesn't significantly impact the speed of the deploy (you can ""overprovision"" the number of threads). You can also retain most of the current deploy semantics around failure counts retry intervals etc.",null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,2,0,1,1,1,0,0,0
AURORA-377,Bug,23,Resolved,No Veto reason is exposed for a task stuck in PENDING due to host constraints,Tasks stuck in PENDING state due to unsatisfied host constraint don't have the reason set in TaskEvent.message. This makes the troubleshooting harder as neither UI nor aurora status can give any clues:{noformat}INFO] role: mesos env: test name: monitoring shard: 147 status: PENDING on Nonecpus: 0.5 ram: 512 MB disk: 3072 MBfailure count: 0 (max 1)events: 2014-05-02 09:05:43 PENDING: Nonemetadata:package: mesos/monitoring v14{noformat},null,3,3,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,3,1,1,0,0,0,0,0
AURORA-553,Task,23,Resolved,Switch to getTasksWithoutConfig RPC on the client where applicable,Client commands/APIs that don't require TaskConfig data should be switched from getTasksConfig to getTasksWithoutConfig RPC for better perf.,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-585,Story,26,Resolved,aurora/thermos test failure on py26 due to pex,"The target {{./pants src/test/python:all -vxs}} fail because valid pex is not built. Refer to attached log for verbose output.{code}[bhuvan@build incubator-aurora]$ ./build-support/pex.venv/bin/pexTraceback (most recent call last):  File ""./build-support/pex.venv/bin/pex"" line 5 in <module>    from pkg_resources import load_entry_point  File ""/home/bhuvan/projects/mesos/incubator-aurora/build-support/pex.venv/lib/python2.6/site-packages/pkg_resources.py"" line 2876 in <module>    working_set = WorkingSet._build_master()  File ""/home/bhuvan/projects/mesos/incubator-aurora/build-support/pex.venv/lib/python2.6/site-packages/pkg_resources.py"" line 449 in _build_master    ws.require(__requires__)  File ""/home/bhuvan/projects/mesos/incubator-aurora/build-support/pex.venv/lib/python2.6/site-packages/pkg_resources.py"" line 745 in require    needed = self.resolve(parse_requirements(requirements))  File ""/home/bhuvan/projects/mesos/incubator-aurora/build-support/pex.venv/lib/python2.6/site-packages/pkg_resources.py"" line 639 in resolve    raise DistributionNotFound(req)pkg_resources.DistributionNotFound: argparse{code}The fix is to explicitly install this library.{code}./build-support/pex.venv/bin/pip install argparse==1.2.1{code}We should fix pants to include this library as one of dependent when it build the pex of pex.",null,1,7,1,1,Joshua Cohen,Bhuvaneswaran A,Bhuvaneswaran A,13,0,4,1,1,0,0,0
AURORA-678,Task,26,Resolved,Serve static HTTP assets out of a classpath directory,Static asset registration with our HTTP server is somewhat complicated requiring a manual mapping to be made from the request to match and the classpath entry to serve.  Jetty has built-in support for serving static assets out of a directory on the classpath which would reduce all of our asset binding code to a few lines.  It also opens the doors to easy extension of the web interface at runtime by adding to the classpath and would also reduce iteration time when developing the web interface.,null,3,3,1,0,Joshua Cohen,Bill Farner,Bill Farner,2,0,1,1,1,0,0,0
AURORA-722,Bug,26,Resolved,snapshot performance issues,In one of our larger production clusters we're seeing issues with snapshot performance that cause the scheduler to failover before completing a snapshot.For background the scheduler writes a compressed (when -deflate_snapshots is enabled) binary-encoded Snapshot (from api.thrift) to the mesos replicated log every hour (or -dlog_snapshot_interval). This snapshot represents most of the scheduler's heap usage including the configuration for all tasks running in the cluster.Add appropriate instrumentation to the snapshot routine and patch any obvious performance bottlenecks.,null,3,3,1,0,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,5,0,1,0,0,0,0,0
AURORA-649,Task,26,Resolved,Implement scheduler API methods linking updater logic and storage,null,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,7,0,0,0,0,0,0,0
AURORA-686,Story,26,Resolved,Job updates may fail due to exceeding role quota,Current way of checking job quota during in-flight updates (i.e. within addInstance transaction) may lead to failed updates and inferior user experience. Since we are tracking quota at the role level but the update lock applied at the job level there is always a possibility to exceed the allowed quota for long running updates. This is especially a problem with the server side-driven process where a resumed update will restart in a potentially quite different quota environment (i.e. due to other jobs created while the update was paused). Possible solutions:- per job quota tracking - requires significant refactoring;- hierarchical locking (e.g. add role lock in addition to job lock) - limits update concurrency per role;- front-loaded consumption (e.g. add additional job consumption during startJobUpdate and re-evaluate on update completion/termination) - will require persisting front-loaded value within job update schema but may be the way to go given current quota implementation.  ,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,1,0,0,0,0,0
AURORA-737,Task,26,Resolved,Improve clientv2 usage helplines.,"This is created in response to user complaints.The ""usage"" line in aurora clientv2 help is automatically generated from command options. When an option doesn't explicitly declare a string to be used as the displayname of an option the system defaults to using the type of the parameter. For some parameters this is perfectly fine. For example""--watch-secs=int"" is clear about what it expects.In other places though it's very unclear. For example for creating a job the user sees:{noformat}  create [--bind=pystachio-binding] [--read-json] [--wait-until=('PENDING' 'RUNNING' 'FINISHED')] [--open-browser] CLUSTER/ROLE/ENV/NAME str{noformat}What is the ""str"" supposed to mean? In all of  the places where the typename is displayed and its meaning is unclear the code should explicitly specify a display name/format for the parameter.",null,3,1,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,1,0,0,0,0,0,0,0
AURORA-697,Bug,26,Resolved,GZip compression regression in scheduler,Looks like we accidentally dropped the gzip compression filter from the thrift over HTTP servlet. ,null,3,3,1,0,Joshua Cohen,David McLaughlin,David McLaughlin,4,0,0,0,0,0,0,0
AURORA-571,Bug,26,Resolved,Admin maintenance fails SLA check when no prod tasks on host,Return value of _check_sla() is not initialized when no eligible tasks are found on host (e.g. non-prod/low instance count).,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-700,Task,26,Resolved,Scheduler UI should use asynchronous HTTP requests,Currently the scheduler UI code was written to assume synchronous network requests - every API call blocks JS execution. This is really going to limit how many API calls we can make per controller before performance is noticeably degraded. Especially with features like the new update API and the pending reasons API call. ,null,3,2,1,0,David McLaughlin,David McLaughlin,David McLaughlin,3,0,0,0,0,0,0,0
AURORA-608,Task,26,Resolved,GcExecutorLauncher should throttle initial activity spike,The current implementation of the GcExecutorLauncher randomizes the GC activity by spreading different host GC execution over the hour. It does not however protect from the startup spike of accepted GC offers before the host cache is populated. This proved to be a perf problem for Mesos master under certain conditions.,null,3,3,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,8,0,2,0,0,0,0,0
AURORA-626,Task,26,Resolved,Add wait_for_batch_completion option into parallel updater,With the parallel updater refactoring we lost an implicit but sometimes useful feature of the sequential updater - controlled batched restart of instances of the same batch. This feature could be useful for certain services with instance topology assumptions.Add a wait_for_batch_completion option into UpdateConfig to block worker threads until the entire batch is completed.,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-609,Bug,26,Resolved,Admin host maintenance command does not block on post drain script,Admin needs to wait on post drain script execution to honor any additional delays introduced in the script.,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-94,Task,26,Resolved,Refactor/remove SchedulerCore in favor of StateManager,SchedulerCore does not seem to provide much value and serves as a thin proxy primarily between SchedulerThriftInterface and StateManager.,null,4,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,3,0,0,0,0,0,0,0
AURORA-692,Task,26,Resolved,aurora_admin should have a find_scheduler command,aurora_admin should have a find_scheduler command that prints out the host/port pair of the scheduler.  this is handy if you're in a bind and need to figure out which is the leading scheduler e.g. if they're backed by serversets.,null,3,2,1,0,Maxim Khutornenko,Brian Wickman,Brian Wickman,1,0,0,0,0,0,0,0
AURORA-732,Task,26,Resolved,Disable server-driven job updates by default,The server-side job updates are functional but not fully-baked yet.  Add a command line argument to disable the startJobUpdate RPC by default.,null,3,2,1,0,Maxim Khutornenko,Bill Farner,Bill Farner,1,0,2,0,0,0,0,0
AURORA-544,Task,26,Resolved,Add an option to allow users to specify log levels in client,null,null,3,1,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,1,0,0,0,0,0,0,0
AURORA-545,Task,26,Resolved,Add a flag to allow users to prevent blocking of unknown exceptions in client,null,null,3,1,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,1,0,0,0,0,0,0,0
AURORA-131,Story,26,Resolved,Deprecate v1 client,null,null,3,2,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,1,0,1,0,0,0,0,0
AURORA-642,Story,26,Resolved,aurora job inspect calls print_out() incorrectly,null,null,3,2,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,3,0,0,0,0,0,0,0
AURORA-613,Task,26,Resolved,Implement job update logic,Implement logic in the scheduler to execute rolling job updates.,null,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,5,0,1,1,1,0,0,0
AURORA-614,Task,26,Resolved,Include information about updates in the scheduler UI,Some initial thoughts:- replace the currently-hacked progress bar with a real progress bar indicating how far along an update is (note: job configuration discrepancies should still be displayed however)- when viewing a job show update history- create a new page that shows all in-progress updats,null,3,2,1,0,David McLaughlin,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-495,Bug,26,Resolved,UI should always show a pending reason,The pending reason in the UI is empty which leaves the user confused. The scheduler should be updated to always show a reason for pending the task.,null,2,4,1,0,David McLaughlin,Suman Karumuri,Suman Karumuri,8,0,1,0,0,0,0,0
AURORA-615,Task,26,Resolved,Update aurora client to use job update RPCs,Delete client code that orchestrates job updates and instead use the scheduler RPCs to do the same.,null,3,2,1,0,Mark Chu-Carroll,Bill Farner,Bill Farner,3,0,0,0,0,0,0,0
AURORA-717,Story,26,Resolved,Store new task configuration in JobUpdateConfiguration as InstanceTaskConfig,Convert these fields in JobUpdateConfiguration:{noformat}  /** Desired TaskConfig when the update completes. */  2: TaskConfig newTaskConfig  /** Desired instance count when the update completes. */  3: i32 instanceCount{noformat}to:{noformat}  2: InstanceTaskConfig newTaskConfig{noformat}This allows us to use {{set<Range>}} for the new task configurations and expose only the work required for a job update.,null,3,2,1,0,Maxim Khutornenko,Bill Farner,Bill Farner,1,0,1,0,0,0,0,0
AURORA-714,Task,26,Resolved,Remove 30sec wait from host_drain command,"This has been a ""pseudo-SLA"" delay to make sure hosts are not drained too fast. Now that we have a real SLA checks in place this delay is no longer needed.",null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-666,Bug,26,Resolved,Aurora job status --write-json does not convert status values,"When using --write-json with {{aurora job status}} the status fields are not converted to literals:{noformat}  ""inactive"": [      {        ""status"": 3        ""assignedTask"": {          ""task"": {            ""isService"": 0{noformat}",null,3,3,1,0,Mark Chu-Carroll,Maxim Khutornenko,Maxim Khutornenko,3,0,0,0,0,0,0,0
AURORA-669,Bug,26,Resolved,Thermos runner collect_updates() gets stuck in a while loop when timeout is 0,"The following code in runner.py:collect_update() may result in an infinite while loop when the provided timeout is passed as 0:{noformat} while True:       ...        if timeout and total_time >= timeout:          break       ...{noformat}We have observed a case when the thermos runner gets stuck in a ""deadlocked"" state not reacting to SIGTERM with the last message in __main__.log as:{noformat}D0827 15:35:26.022495 30886 runner.py:856] Run loop: Work to be done within 0.0s{noformat}",null,3,4,1,0,Brian Wickman,Maxim Khutornenko,Maxim Khutornenko,4,0,0,0,0,0,0,0
AURORA-313,Task,26,Resolved,Add variable min offer jitter time window so Aurora can decline offers faster,The jitter time defining the upper bound of a random time window that gets added to {{min_offer_hold_time}} is currently hard coded to 5 minutes.This makes Aurora sit on resource offers very long and it starves other schedulers.The jitter time should be configurable so Aurora can decline offers faster.,null,3,2,1,0,Joshua Cohen,Bjoern Metzdorf,Bjoern Metzdorf,1,0,0,0,0,0,0,0
AURORA-369,Story,26,Resolved,Create a REST-like interface to aurora,For ease of scripting it would be nice if a client could interact with the scheduler over a HTTP/JSON interface (REST-like but not necessarily REST).  We technically have this now using TJSONProtocol but the format is not human-friendly since it uses field IDs rather than names.,null,3,5,1,0,Bill Farner,Bill Farner,Bill Farner,3,1,1,0,0,0,0,0
AURORA-458,Bug,26,Resolved,Web interface has become slow especially the job page,The web interface is noticeably more sluggish since the revamp.  This is most noticeable for large jobs where the job page may display a blank page for several seconds before showing anything useful.  We need to adapt the API to reduce the amount of data fetched to render these pages.,null,2,2,1,0,David McLaughlin,Bill Farner,Bill Farner,7,0,0,0,0,0,0,7
AURORA-579,Story,26,Resolved,Upgrading Mesos version from 0.18.0 to 0.19.0,null,null,3,3,1,0,Dominic Hamon,Jake Farrell,Jake Farrell,5,0,1,0,0,0,0,0
AURORA-658,Bug,26,Resolved,unable to run scheduler without mesos infrastructure for development,now that IsolatedSchedulerModule is removed in https://reviews.apache.org/r/20648/ there is no [easy] way to run the scheduler under Intellij IDEA(or similar) without mesos infrastructure.The IsolatedSchedulerModule was a huge nicety for doing development work and simulating codes paths without the overhead of configuring/running mesos itself.There should still be an equivalent option.,null,3,2,1,0,Bill Farner,alexius ludeman,alexius ludeman,1,0,0,0,0,0,0,0
AURORA-679,Task,26,Resolved,Upgrade jetty,We're currently using a Jetty version from the 6.x series which reached end of life in 2010 \[1\].  In addition to moving to a supported/stable Jetty release Jetty 7 gives us the ability to rewrite HTTP requests which will be necessary to satisfy AURORA-678 for the single page angular app.\[1\] http://wiki.eclipse.org/Jetty/Starting/Porting_to_Jetty_7,null,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,1,1,1,0,0,0
AURORA-683,Bug,26,Resolved,vagrant up fails due to missing box ubuntu/trusty64,"{noformat}$ vagrant upBringing machine 'devcluster' up with 'virtualbox' provider...There are errors in the configuration of this machine. Please fixthe following errors and try again:vm:* The box 'ubuntu/trusty64' could not be found.{noformat}Appears to be caused by this change:{noformat}$ git show 467bc56049cc775eaf61520a464b363d44023024 Vagrantfilecommit 467bc56049cc775eaf61520a464b363d44023024Author: Joe Smith <yasumoto7@gmail.com>Date:   Wed Sep 3 15:55:17 2014 -0700    Increment Mesos version to 0.20.0        Bugs closed: AURORA-674        Reviewed at https://reviews.apache.org/r/25208/diff --git a/Vagrantfile b/Vagrantfileindex c8cb2d4..ea0b252 100644--- a/Vagrantfile+++ b/Vagrantfile@@ -1811 +187 @@ VAGRANTFILE_API_VERSION = ""2""  Vagrant.configure(VAGRANTFILE_API_VERSION) do |config|-  config.vm.box = ""precise64""--  # The url from where the 'config.vm.box' box will be fetched if it-  # doesn't already exist on the user's system.-  config.vm.box_url = ""http://files.vagrantup.com/precise64.box""+  config.vm.box = ""ubuntu/trusty64""    config.vm.define ""devcluster"" do |dev|     dev.vm.network :private_network ip: ""192.168.33.7""{noformat}",null,1,3,1,0,Bill Farner,Bill Farner,Bill Farner,5,0,0,0,0,0,0,0
AURORA-694,Bug,26,Resolved,When MemStorage is layered over DbStorage SQL is not transactioned,Noticed this when a {{JdbcSQLException}} bubbled out of a database call in a unit test which should not happen if all calls go through the {{@Transactional}} methods in {{DbStorage}}.  Closer inspection reveals that {{MemStorage}} delegates operations to {{@Delegated}} 'table' implementations but does not delegate in a way that database transactions are used.,null,2,2,1,0,Zameer Manji,Bill Farner,Bill Farner,2,0,0,0,0,0,0,0
AURORA-585,Story,39,Resolved,aurora/thermos test failure on py26 due to pex,"The target {{./pants src/test/python:all -vxs}} fail because valid pex is not built. Refer to attached log for verbose output.{code}[bhuvan@build incubator-aurora]$ ./build-support/pex.venv/bin/pexTraceback (most recent call last):  File ""./build-support/pex.venv/bin/pex"" line 5 in <module>    from pkg_resources import load_entry_point  File ""/home/bhuvan/projects/mesos/incubator-aurora/build-support/pex.venv/lib/python2.6/site-packages/pkg_resources.py"" line 2876 in <module>    working_set = WorkingSet._build_master()  File ""/home/bhuvan/projects/mesos/incubator-aurora/build-support/pex.venv/lib/python2.6/site-packages/pkg_resources.py"" line 449 in _build_master    ws.require(__requires__)  File ""/home/bhuvan/projects/mesos/incubator-aurora/build-support/pex.venv/lib/python2.6/site-packages/pkg_resources.py"" line 745 in require    needed = self.resolve(parse_requirements(requirements))  File ""/home/bhuvan/projects/mesos/incubator-aurora/build-support/pex.venv/lib/python2.6/site-packages/pkg_resources.py"" line 639 in resolve    raise DistributionNotFound(req)pkg_resources.DistributionNotFound: argparse{code}The fix is to explicitly install this library.{code}./build-support/pex.venv/bin/pip install argparse==1.2.1{code}We should fix pants to include this library as one of dependent when it build the pex of pex.",null,1,7,1,1,Joshua Cohen,Bhuvaneswaran A,Bhuvaneswaran A,13,0,4,1,1,0,0,0
AURORA-175,Task,39,Resolved,thermos runner should discriminate failures using exit status,We do the correct thing on the executor side when there is a configuration/interpolation problem (report FAILURE.)On the thermos_runner side we don't exit with a separate exit status for bad configuration nor do we even pay attention to the exit status from the thermos executor.  So when the runner exits unexpectedly that's always treated as a LOST.  Instead there should be a contract between the thermos_runner and thermos_executor about certain classes of failures indicated by exit statuses so that we can differentiate between legit LOST and FAILURE for example if the user no longer exists on the box.,null,2,2,1,0,Brian Wickman,Brian Wickman,Brian Wickman,3,0,1,1,1,0,0,0
AURORA-728,Bug,39,Resolved,Executor does not handle announcer errors properly,"Failures in the announcer lead to mesos and aurora running out of sync.Consider the following stacktrace:{code}Traceback (most recent call last):  File ""/root/.pex/install/twitter.common.exceptions-0.3.0-py2-none-any.whl.aa74e2e8535b1ea39bf9512cf70dba3e5aea7b1b/twitter.common.exceptions-0.3.0-py2-none-any.whl/twitter/common/exceptions/__init__.py"" line 126 in _excepting_run    self.__real_run(*args **kw)  File ""/root/.pex/install/twitter.common.concurrent-0.3.0-py2-none-any.whl.3c9a3bf0ac76acff13a6803a37138bc9f18e54c7/twitter.common.concurrent-0.3.0-py2-none-any.whl/twitter/common/concurrent/deferred.py"" line 43 in run    self._closure()  File ""/opt/thermos/bin/thermos_executor.pex/apache/aurora/executor/aurora_executor.py"" line 258 in <lambda>  File ""/opt/thermos/bin/thermos_executor.pex/apache/aurora/executor/aurora_executor.py"" line 121 in _run  File ""/opt/thermos/bin/thermos_executor.pex/apache/aurora/executor/aurora_executor.py"" line 161 in _start_status_manager  File ""/opt/thermos/bin/thermos_executor.pex/apache/aurora/executor/common/announcer.py"" line 74 in from_assigned_task  File ""/opt/thermos/bin/thermos_executor.pex/apache/aurora/executor/common/announcer.py"" line 100 in make_serverset  File ""/root/.pex/install/kazoo-1.3.1-py2-none-any.whl.261c1cd5b2337063b238f0c52eeed45a1df90891/kazoo-1.3.1-py2-none-any.whl/kazoo/client.py"" line 475 in start    raise self.handler.timeout_exception(""Connection time-out"")kazoo.handlers.threading.TimeoutError: Connection time-out{code}*Current behaviour:* The executor dies. Mesos considers the task as RUNNING whereas aurora will eventually consider the task as LOST.*Expected behaviour:* The executor catches the exception and dispatches TASK_LOST or TASK_FAILED",null,2,4,1,0,Zameer Manji,Stephan Erb,Stephan Erb,6,0,0,0,0,0,0,0
AURORA-678,Task,39,Resolved,Serve static HTTP assets out of a classpath directory,Static asset registration with our HTTP server is somewhat complicated requiring a manual mapping to be made from the request to match and the classpath entry to serve.  Jetty has built-in support for serving static assets out of a directory on the classpath which would reduce all of our asset binding code to a few lines.  It also opens the doors to easy extension of the web interface at runtime by adding to the classpath and would also reduce iteration time when developing the web interface.,null,3,3,1,0,Joshua Cohen,Bill Farner,Bill Farner,2,0,1,1,1,0,0,0
AURORA-722,Bug,39,Resolved,snapshot performance issues,In one of our larger production clusters we're seeing issues with snapshot performance that cause the scheduler to failover before completing a snapshot.For background the scheduler writes a compressed (when -deflate_snapshots is enabled) binary-encoded Snapshot (from api.thrift) to the mesos replicated log every hour (or -dlog_snapshot_interval). This snapshot represents most of the scheduler's heap usage including the configuration for all tasks running in the cluster.Add appropriate instrumentation to the snapshot routine and patch any obvious performance bottlenecks.,null,3,3,1,0,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,5,0,1,0,0,0,0,0
AURORA-742,Task,39,Resolved,Add client commands to query server-driven updates.,null,null,3,1,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,1,0,0,0,0,0,0,0
AURORA-780,Bug,39,Resolved,python checkstyle looks at 3rdparty,"When attempting to commit https://reviews.apache.org/r/25835/ I was blocked by Python checkstyle as the rename of checked-in bootstrap test files (some written in python) was picked up.{noformat}T401:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:002 From import must import names in lexical order.     |from __future__ import absolute_import unicode_literals print_function divisionT401:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:005 From import must import names in lexical order.     |from os import environ stat remove as _delete_fileT401:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:006 From import must import names in lexical order.     |from os.path import isfile dirname basename abspathT405:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:004 Import block starting here contains imports from multiple module types: stdlib 3rdparty.     |from sys import argvT100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:018 Indentation of 4 instead of 2     |    BUCKET_NAME = environ['TWBS_S3_BUCKET']T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:020 Indentation of 4 instead of 2     |    raise SystemExit(""TWBS_S3_BUCKET environment variable not set!"")T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:024 Indentation of 4 instead of 2     |    hasher = sha256()T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:026 Indentation of 4 instead of 2     |        hasher.update(input_file.read())T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:033 Indentation of 4 instead of 2     |    try:T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:034 Indentation of 4 instead of 2     |        _delete_file(filename)T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:036 Indentation of 4 instead of 2     |        passT100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:040 Indentation of 4 instead of 2     |    kib = stat(_tarball_filename_for(directory)).st_size // BYTES_PER_MBT100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:045 Indentation of 4 instead of 2     |    return abspath('./{}.tar.gz'.format(basename(directory)))T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:049 Indentation of 4 instead of 2     |    print(""Creating tarball of {}..."".format(directory))T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:054 Indentation of 4 instead of 2     |    print(""Extracting tarball of {}..."".format(directory))T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:059 Indentation of 4 instead of 2     |    _delete_file_quietly(NEED_TO_UPLOAD_MARKER)T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:061 Indentation of 4 instead of 2     |        print(""Downloading {} tarball from S3..."".format(friendly_name))T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:064 Indentation of 4 instead of 2     |        open(NEED_TO_UPLOAD_MARKER 'a').close()T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:073 Indentation of 4 instead of 2     |    _create_tarball(directory)T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:084 Indentation of 4 instead of 2     |    argv.pop(0)T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:086 Indentation of 4 instead of 2     |        raise SystemExit(""USAGE: s3_cache.py <download | upload> <friendly name> <dependencies file> <directory>"")T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:092 Indentation of 4 instead of 2     |        raise SystemExit(""Could not access bucket!"")T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:100 Indentation of 4 instead of 2     |        download(directory)T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:102 Indentation of 4 instead of 2     |        if isfile(NEED_TO_UPLOAD_MARKER):  # FIXMET100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:103 Indentation of 4 instead of 2     |            upload(directory)T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:105 Indentation of 4 instead of 2     |            print(""No need to upload anything."")T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:107 Indentation of 4 instead of 2     |        raise SystemExit(""Unrecognized mode {!r}"".format(mode))T802:WARNING 3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:064 open() calls should be made within a contextmanager.     |        open(NEED_TO_UPLOAD_MARKER 'a').close()E501:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:050 line too long (105 > 100 characters)     |    run(['tar' '-czf' _tarball_filename_for(directory) '-C' dirname(directory) basename(directory)])E501:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:086 line too long (114 > 100 characters)     |        raise SystemExit(""USAGE: s3_cache.py <download | upload> <friendly name> <dependencies file> <directory>""){noformat}",null,3,2,1,0,Joshua Cohen,Kevin Sweeney,Kevin Sweeney,2,0,0,0,0,0,0,0
AURORA-748,Bug,39,Resolved,Help command is broken,$ aurora2.pex help update startlog(ERROR): Unknown error: sequence item 24: expected string instancemethod foundlog(ERROR): Unknown error: sequence item 24: expected string instancemethod foundThis also happens for `help update pause`.,null,4,3,1,0,Joe Smith,Kevin Burg,Kevin Burg,2,0,0,0,0,0,0,0
AURORA-781,Story,39,Resolved,Fix bind parameter processing in client,In client commands there are two problems involving pystachio bindings:(1) Binding parameters sometimes don't work correctly;(2) If a binding never gets resolved an error isn't generated.,null,3,2,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,3,0,0,0,0,0,0,0
AURORA-649,Task,39,Resolved,Implement scheduler API methods linking updater logic and storage,null,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,7,0,0,0,0,0,0,0
AURORA-772,Task,39,Resolved,Add username to the update events,Depending on your auth scheme different users can perform operations on a single update. E.g. one user can start the update but another user pause and resume it. To be able to reveal this information when displaying updates we should attach the user to each JobUpdateEvent instance. ,null,3,1,1,0,David McLaughlin,David McLaughlin,David McLaughlin,1,0,0,0,0,0,0,0
AURORA-741,Story,39,Resolved,DbJobUpdateStore can't fetch updates that have no initial state,If an IJobUpdate has an empty set for {{instructions.initialState}} it can be saved but not retrieved.Here's an example stack trace where this was encountered{noformat}java.lang.IllegalStateException: Optional.get() cannot be called on an absent valueat com.google.common.base.Absent.get(Absent.java:47)at org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.changeJobUpdateStatus(JobUpdateControllerImpl.java:388)at org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.recordAndChangeJobUpdateStatus(JobUpdateControllerImpl.java:330)at org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.access$200(JobUpdateControllerImpl.java:93)at org.apache.aurora.scheduler.updater.JobUpdateControllerImpl$1.execute(JobUpdateControllerImpl.java:151)at org.apache.aurora.scheduler.storage.Storage$MutateWork$NoResult.apply(Storage.java:131)at org.apache.aurora.scheduler.storage.Storage$MutateWork$NoResult.apply(Storage.java:127)at org.apache.aurora.scheduler.storage.mem.MemStorage.doWork(MemStorage.java:175)at org.apache.aurora.scheduler.storage.mem.MemStorage.access$400(MemStorage.java:59)at org.apache.aurora.scheduler.storage.mem.MemStorage$4.apply(MemStorage.java:200)at org.apache.aurora.scheduler.storage.mem.MemStorage$4.apply(MemStorage.java:197)at org.apache.aurora.scheduler.storage.db.DbStorage.write(DbStorage.java:150)at org.mybatis.guice.transactional.TransactionalMethodInterceptor.invoke(TransactionalMethodInterceptor.java:101)at org.apache.aurora.scheduler.storage.mem.MemStorage.write(MemStorage.java:197)at org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.start(JobUpdateControllerImpl.java:131){noformat},null,1,2,1,0,Maxim Khutornenko,Bill Farner,Bill Farner,1,0,1,1,1,0,0,0
AURORA-187,Bug,39,Resolved,scheduler failover should never abort an update,User reported they had an aborted update{noformat} INFO] Response from scheduler: ERROR (message: Aborting update without rollback! Fatal error: Storage is not READY){noformat}This seems like a regression.  Users should never get aborted updates due to scheduler failovers.,null,2,2,1,0,Maxim Khutornenko,Brian Wickman,Brian Wickman,2,0,0,0,0,0,0,0
AURORA-733,Story,39,Resolved,MedianAlgorithm results should be windowed in time,{{MedianAlgorithm}} computes the median of numeric values extracted from {{IScheduledTask}} s.  Unlike other {{SlaAlgorithm}} implementations it ignores the {{timeFrame}} argument and computes the median for all tasks provided.  This results in a graph that is historically-weighted and less responsive to load.  Consider using the {{timeFrame}} to filter tasks before computing the mdeian.,null,3,2,1,0,Maxim Khutornenko,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-686,Story,39,Resolved,Job updates may fail due to exceeding role quota,Current way of checking job quota during in-flight updates (i.e. within addInstance transaction) may lead to failed updates and inferior user experience. Since we are tracking quota at the role level but the update lock applied at the job level there is always a possibility to exceed the allowed quota for long running updates. This is especially a problem with the server side-driven process where a resumed update will restart in a potentially quite different quota environment (i.e. due to other jobs created while the update was paused). Possible solutions:- per job quota tracking - requires significant refactoring;- hierarchical locking (e.g. add role lock in addition to job lock) - limits update concurrency per role;- front-loaded consumption (e.g. add additional job consumption during startJobUpdate and re-evaluate on update completion/termination) - will require persisting front-loaded value within job update schema but may be the way to go given current quota implementation.  ,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,1,0,0,0,0,0
AURORA-412,Task,39,Resolved,Upgrade psutil once post-2.1.1 release is cut,We've tickled https://code.google.com/p/psutil/issues/detail?id=503 in production a few times.  This is now patched on psutil master but a release has not yet been cut.  Once that happens we should upgrade to a newer release.,null,3,2,1,0,Brian Wickman,Brian Wickman,Brian Wickman,3,0,0,0,0,0,0,0
AURORA-737,Task,39,Resolved,Improve clientv2 usage helplines.,"This is created in response to user complaints.The ""usage"" line in aurora clientv2 help is automatically generated from command options. When an option doesn't explicitly declare a string to be used as the displayname of an option the system defaults to using the type of the parameter. For some parameters this is perfectly fine. For example""--watch-secs=int"" is clear about what it expects.In other places though it's very unclear. For example for creating a job the user sees:{noformat}  create [--bind=pystachio-binding] [--read-json] [--wait-until=('PENDING' 'RUNNING' 'FINISHED')] [--open-browser] CLUSTER/ROLE/ENV/NAME str{noformat}What is the ""str"" supposed to mean? In all of  the places where the typename is displayed and its meaning is unclear the code should explicitly specify a display name/format for the parameter.",null,3,1,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,1,0,0,0,0,0,0,0
AURORA-718,Story,39,Resolved,JobUpdateConfiguration should reflect work required for a job update,JobUpdateConfiguration contains three fields to reflect the 'before' and 'after' state of a job: instanceCount newTaskConfig oldTaskConfigs.  These could be leveraged to do the same but also show the 'actual work' required for the update.  For example in an update that is scoped to specific instances or where not all instances need to be modified (no-ops) these fields should indicate which instances the scheduler needs to modify.This ticket tracks a change to how oldTaskConfigs is computed.  AURORA-717 tracks conversion of the other two fields.,null,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,3,1,1,0,0,0
AURORA-755,Story,39,Resolved,Issue with partial deploys in the update instance summary,The new update UI doesn't seem to handle the use case of increasing instance count of a job with the same config as the old one. ,null,3,1,1,0,David McLaughlin,David McLaughlin,David McLaughlin,1,0,0,0,0,0,0,0
AURORA-745,Story,39,Resolved,Show in-flight and recently completed updates in scheduler UI,We should add a page just to summarise all currently in progress updates as well as showing recently completed updates. ,null,3,1,1,0,David McLaughlin,David McLaughlin,David McLaughlin,1,0,0,0,0,0,0,0
AURORA-764,Story,39,Resolved,Stop sending deleted task events ignore incoming deleted task events.,null,null,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-84,Task,39,Resolved,Deprecate the Identity struct,The Identity field is nested in several structs and the {{role}} field it contains is ~always redundant to a field in {{JobKey}}. Consider removing Identity and using (or adding) a non-user-bearing field like JobKey.An open question is whether whether {{Identity.user}} should be retained.  Most likely yes.,null,3,6,1,0,Maxim Khutornenko,Bill Farner,Bill Farner,29,0,1,0,0,0,0,0
AURORA-798,Bug,42,Resolved,investigate flaky test: LockManagerImplTest/testNoDeadlock,A test caused CI to fail on an unrelated Python change:See https://builds.apache.org/job/Aurora/618/testReport/junit/org.apache.aurora.scheduler.state/LockManagerImplTest/testNoDeadlock/{noformat}java.lang.RuntimeException: java.lang.AssertionError:   Expectation failure on verify:    Mutable.fetchLock(<LockKey job:JobKey(role:jim environment:devel name:myJob)>): expected: 2 actual: 1Stacktracejava.lang.RuntimeException: java.lang.AssertionError:   Expectation failure on verify:    Mutable.fetchLock(<LockKey job:JobKey(role:jim environment:devel name:myJob)>): expected: 2 actual: 1at com.google.common.testing.ClusterException.create(ClusterException.java:116)at com.google.common.testing.TearDownStack.runTearDown(TearDownStack.java:69)at com.google.common.testing.junit4.TearDownTestCase.tearDown(TearDownTestCase.java:113)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)at org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:168)at org.junit.rules.RunRules.evaluate(RunRules.java:20)at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)at org.junit.runners.ParentRunner.run(ParentRunner.java:309)at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:69)at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:48)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:105)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:355)at org.gradle.internal.concurrent.DefaultExecutorFactory$StoppableExecutorImpl$1.run(DefaultExecutorFactory.java:64)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:724)Caused by: java.lang.AssertionError:   Expectation failure on verify:    Mutable.fetchLock(<LockKey job:JobKey(role:jim environment:devel name:myJob)>): expected: 2 actual: 1at org.easymock.internal.MocksControl.verify(MocksControl.java:226)at com.twitter.common.testing.easymock.EasyMockTest$1.tearDown(EasyMockTest.java:54)at com.google.common.testing.TearDownStack.runTearDown(TearDownStack.java:58)... 45 moreStandard ErrorOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waiting{noformat},null,3,2,1,0,Maxim Khutornenko,Kevin Sweeney,Kevin Sweeney,2,0,0,0,0,0,0,0
AURORA-72,Story,42,Resolved,Improve root README.md,README.md is the first thing many prospective contributors will see when viewing the source code as well as the first thing many users will automatically jump to. Update it to be more helpful possibly merge with docs/README.md,null,3,2,1,0,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-863,Bug,42,Resolved,provision-dev-cluster.sh refers to mesos egg instead of mesos.native,This makes the executor fail to build in the vagrant environment. We were apparently depending on the mesos.native egg on pypi which was removed in MESOS-1898,null,1,4,1,0,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,4,0,2,2,2,0,0,0
AURORA-627,Task,42,Resolved,use latest psutil library for thermos in pants,"Unable to execute thermos due to following error. It's due to this bug in {{psutil}}. [issue 442|https://code.google.com/p/psutil/issues/detail?id=442]. We were using v1.1.2. We should use v1.1.3 or newer.Facing same issue with gc_executor and thermos_runner.{code}./dist/thermos_executor.pex                                                                   [latest] 18:30:53Traceback (most recent call last):  File ""/Volumes/apple/quark/incubator-aurora/dist/thermos_executor.pex/.bootstrap/_twitter_common_python/pex.py"" line 225 in execute    self.execute_interpreter()  File ""/usr/lib64/python2.6/contextlib.py"" line 34 in __exit__    self.gen.throw(type value traceback)  File ""/Volumes/apple/quark/incubator-aurora/dist/thermos_executor.pex/.bootstrap/_twitter_common_python/pex.py"" line 175 in patch_pkg_resources    yield  File ""/Volumes/apple/quark/incubator-aurora/dist/thermos_executor.pex/.bootstrap/_twitter_common_python/pex.py"" line 223 in execute    self.execute_entry(entry_point args)  File ""/Volumes/apple/quark/incubator-aurora/dist/thermos_executor.pex/.bootstrap/_twitter_common_python/pex.py"" line 271 in execute_entry    runner(entry_point)  File ""/Volumes/apple/quark/incubator-aurora/dist/thermos_executor.pex/.bootstrap/_twitter_common_python/pex.py"" line 293 in execute_pkg_resources    runner = entry.load(require=False)  # trust that the environment is sane  File ""/Volumes/apple/quark/incubator-aurora/dist/thermos_executor.pex/.bootstrap/pkg_resources.py"" line 2048 in load    entry = __import__(self.module_name globals()globals() ['__name__'])  File ""/Volumes/apple/quark/incubator-aurora/dist/thermos_executor.pex/apache/aurora/executor/bin/thermos_executor_main.py"" line 31 in <module>  File ""/Volumes/apple/quark/incubator-aurora/dist/thermos_executor.pex/apache/aurora/executor/thermos_task_runner.py"" line 31 in <module>  File ""/Volumes/apple/quark/incubator-aurora/dist/thermos_executor.pex/apache/thermos/core/runner.py"" line 70 in <module>  File ""/Volumes/apple/quark/incubator-aurora/dist/thermos_executor.pex/apache/thermos/core/helper.py"" line 21 in <module>  File ""/home/bhuvan/.pex/install/psutil-1.1.2-cp26-none-linux_x86_64.whl.a1805e756711e817e309c89cedf92d2a070c3ee7/psutil-1.1.2-cp26-none-linux_x86_64.whl/psutil/__init__.py"" line 89 in <module>    import psutil._pslinux as _psplatform  File ""/home/bhuvan/.pex/install/psutil-1.1.2-cp26-none-linux_x86_64.whl.a1805e756711e817e309c89cedf92d2a070c3ee7/psutil-1.1.2-cp26-none-linux_x86_64.whl/psutil/_pslinux.py"" line 21 in <module>    import _psutil_linuxImportError: /home/bhuvan/.pex/install/psutil-1.1.2-cp26-none-linux_x86_64.whl.a1805e756711e817e309c89cedf92d2a070c3ee7/psutil-1.1.2-cp26-none-linux_x86_64.whl/_psutil_linux.so: undefined symbol: prlimit{code}",null,3,4,1,0,Joe Smith,Bhuvaneswaran A,Bhuvaneswaran A,3,0,2,1,1,0,0,0
AURORA-779,Bug,42,Resolved,v2 client has worse error message than v1,"Copied from a user report at Twitter:I had a typo in an aurora config where I was resolving a mustache variable outside of a string:{code}instances = {{profile.instances}}{code}where I should have been doing{code}instances = ""{{profile.instances}}""{code}The error message on the v2 client was:{quote}Error executing command: Error loading configuration: name 'profile' is not defined{quote}The v1 client gave me a line number:{quote}  File ""router.aurora"" line 90 in <module>    instances = {{profile.instances}}NameError: name 'profile' is not defined{quote}",null,3,3,1,0,Mark Chu-Carroll,Kevin Sweeney,Kevin Sweeney,10,0,0,0,0,0,0,0
AURORA-833,Task,42,Resolved,Extract complex gradle tasks from build.gradle,Prime candidates:- thrift codegen task- custom jacoco output parsingContext:http://www.gradle.org/docs/current/userguide/custom_tasks.html,null,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,2,0,0,0,0,0,0,0
AURORA-839,Story,42,Resolved,Add documentation describing the scheduler's storage system,The storage system in the scheduler is the most complicated part of the system and pretty unapproachable for new developers.  Some details will help acquaint people with the different moving pieces involved.,null,3,4,1,0,Maxim Khutornenko,Bill Farner,Bill Farner,5,0,0,0,0,0,0,0
AURORA-763,Task,42,Resolved,Document how to use the new asynchronous updater feature,We should document how the new async update works. ,null,3,2,1,0,Bill Farner,David McLaughlin,David McLaughlin,1,0,0,0,0,0,0,0
AURORA-830,Task,42,Resolved,Make Executor Overhead Configurable,Currently the overhead allocated for executors is hard coded into the {{ResourceSlot}} class. This should be changed so the overhead is taken from a command line flag. This is necessary so users can choose the impact executor overhead had on their cluster.,null,4,1,1,0,Zameer Manji,Zameer Manji,Zameer Manji,2,0,0,0,0,0,0,0
AURORA-585,Story,42,Resolved,aurora/thermos test failure on py26 due to pex,"The target {{./pants src/test/python:all -vxs}} fail because valid pex is not built. Refer to attached log for verbose output.{code}[bhuvan@build incubator-aurora]$ ./build-support/pex.venv/bin/pexTraceback (most recent call last):  File ""./build-support/pex.venv/bin/pex"" line 5 in <module>    from pkg_resources import load_entry_point  File ""/home/bhuvan/projects/mesos/incubator-aurora/build-support/pex.venv/lib/python2.6/site-packages/pkg_resources.py"" line 2876 in <module>    working_set = WorkingSet._build_master()  File ""/home/bhuvan/projects/mesos/incubator-aurora/build-support/pex.venv/lib/python2.6/site-packages/pkg_resources.py"" line 449 in _build_master    ws.require(__requires__)  File ""/home/bhuvan/projects/mesos/incubator-aurora/build-support/pex.venv/lib/python2.6/site-packages/pkg_resources.py"" line 745 in require    needed = self.resolve(parse_requirements(requirements))  File ""/home/bhuvan/projects/mesos/incubator-aurora/build-support/pex.venv/lib/python2.6/site-packages/pkg_resources.py"" line 639 in resolve    raise DistributionNotFound(req)pkg_resources.DistributionNotFound: argparse{code}The fix is to explicitly install this library.{code}./build-support/pex.venv/bin/pip install argparse==1.2.1{code}We should fix pants to include this library as one of dependent when it build the pex of pex.",null,1,7,1,1,Joshua Cohen,Bhuvaneswaran A,Bhuvaneswaran A,13,0,4,1,1,0,0,0
AURORA-440,Task,42,Resolved,Document cron,null,null,2,4,1,0,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,2,2,1,0,0,0,0,0
AURORA-175,Task,42,Resolved,thermos runner should discriminate failures using exit status,We do the correct thing on the executor side when there is a configuration/interpolation problem (report FAILURE.)On the thermos_runner side we don't exit with a separate exit status for bad configuration nor do we even pay attention to the exit status from the thermos executor.  So when the runner exits unexpectedly that's always treated as a LOST.  Instead there should be a contract between the thermos_runner and thermos_executor about certain classes of failures indicated by exit statuses so that we can differentiate between legit LOST and FAILURE for example if the user no longer exists on the box.,null,2,2,1,0,Brian Wickman,Brian Wickman,Brian Wickman,3,0,1,1,1,0,0,0
AURORA-728,Bug,42,Resolved,Executor does not handle announcer errors properly,"Failures in the announcer lead to mesos and aurora running out of sync.Consider the following stacktrace:{code}Traceback (most recent call last):  File ""/root/.pex/install/twitter.common.exceptions-0.3.0-py2-none-any.whl.aa74e2e8535b1ea39bf9512cf70dba3e5aea7b1b/twitter.common.exceptions-0.3.0-py2-none-any.whl/twitter/common/exceptions/__init__.py"" line 126 in _excepting_run    self.__real_run(*args **kw)  File ""/root/.pex/install/twitter.common.concurrent-0.3.0-py2-none-any.whl.3c9a3bf0ac76acff13a6803a37138bc9f18e54c7/twitter.common.concurrent-0.3.0-py2-none-any.whl/twitter/common/concurrent/deferred.py"" line 43 in run    self._closure()  File ""/opt/thermos/bin/thermos_executor.pex/apache/aurora/executor/aurora_executor.py"" line 258 in <lambda>  File ""/opt/thermos/bin/thermos_executor.pex/apache/aurora/executor/aurora_executor.py"" line 121 in _run  File ""/opt/thermos/bin/thermos_executor.pex/apache/aurora/executor/aurora_executor.py"" line 161 in _start_status_manager  File ""/opt/thermos/bin/thermos_executor.pex/apache/aurora/executor/common/announcer.py"" line 74 in from_assigned_task  File ""/opt/thermos/bin/thermos_executor.pex/apache/aurora/executor/common/announcer.py"" line 100 in make_serverset  File ""/root/.pex/install/kazoo-1.3.1-py2-none-any.whl.261c1cd5b2337063b238f0c52eeed45a1df90891/kazoo-1.3.1-py2-none-any.whl/kazoo/client.py"" line 475 in start    raise self.handler.timeout_exception(""Connection time-out"")kazoo.handlers.threading.TimeoutError: Connection time-out{code}*Current behaviour:* The executor dies. Mesos considers the task as RUNNING whereas aurora will eventually consider the task as LOST.*Expected behaviour:* The executor catches the exception and dispatches TASK_LOST or TASK_FAILED",null,2,4,1,0,Zameer Manji,Stephan Erb,Stephan Erb,6,0,0,0,0,0,0,0
AURORA-176,Task,42,Resolved,more gracefully handle cases where user does not exist on machine,"Tasks are going LOST for this reason:{noformat}Initialization of task runner failed: Could not construct sandbox: 'getpwnam(): name not found: zmanji'{noformat}I think everything is actually behaving correctly but this should probably be propagated as a task FAILED rather than LOST.From Jon B:As far as the specific case described here (failure during task runner initialization) this is actually done - it now results in FAILED:{noformat}2 mins ago - FAILED : Initialization of task runner failed: Could not construct sandbox: 'getpwnam(): name not found: cosmingheorghe'{noformat}However it's still possible for a task to go LOST when a user doesn't exist any more when the runner terminates abnormally (after the sandbox is set up and task is already running):{noformat}D1024 21:17:11.360357 52726 runner.py:748] runnable: applicationD1024 21:17:11.360486 52726 runner.py:750] waiting: D1024 21:17:11.361073 52726 runner.py:647] _set_process_status(application <= WAITING seq=4[auto])D1024 21:17:11.361279 52726 ckpt.py:367] Running state machine for process=application/seq=4D1024 21:17:11.361418 52726 runner.py:225] _on_process_transition: ProcessStatus(seq=4 process=u'application' start_time=None coordinator_pid=None pid=None return_code=None state=0 stop_time=None fork_time=None)D1024 21:17:11.428257 52726 runner.py:90] Process on_waiting ProcessStatus(seq=4 process=u'application' start_time=None coordinator_pid=None pid=None return_code=None state=0 stop_time=None fork_time=None)E1024 21:17:11.429981 52726 runner.py:545] Caught exception in self.control(): Unable to get pwent information!E1024 21:17:11.432827 52726 runner.py:546]   Traceback (most recent call last):  File ""twitter/thermos/runner/runner.py"" line 543 in control    yield  File ""twitter/thermos/runner/runner.py"" line 831 in run    self._run()  File ""twitter/thermos/runner/runner.py"" line 839 in _run    iteration_wait = runner.run()  File ""twitter/thermos/runner/runner.py"" line 278 in run    launched = self.runner._run_plan(self.runner._regular_plan)  File ""twitter/thermos/runner/runner.py"" line 764 in _run_plan    self._set_process_status(process_name ProcessState.WAITING)  File ""twitter/thermos/runner/runner.py"" line 650 in _set_process_status    self._dispatcher.dispatch(self._state runner_ckpt self._recovery)  File ""twitter/thermos/base/ckpt.py"" line 372 in dispatch    self._run_process_dispatch(process_update.state process_update)  File ""twitter/thermos/base/ckpt.py"" line 200 in _run_process_dispatch    getattr(handler handler_function)(process_update)  File ""twitter/thermos/runner/runner.py"" line 93 in on_waiting    process_update.process process_update.seq + 1))  File ""twitter/thermos/runner/runner.py"" line 675 in _task_process_from_process_name    fork=close_ckpt_and_fork)  File ""twitter/thermos/runner/process.py"" line 287 in __init__    ProcessBase.__init__(self *args **kw)  File ""twitter/thermos/runner/process.py"" line 93 in __init__    user current_user = self._getpwuid() # may raise self.UnknownUserError  File ""twitter/thermos/runner/process.py"" line 214 in _getpwuid    raise self.UnknownUserError('Unable to get pwent information!')UnknownUserError: Unable to get pwent information!and then the executor marks it as LOSTI1024 21:17:11.947812 52673 status_manager.py:69] Executor polling thread detected termination condition.I1024 21:17:11.948065 52673 task_runner_wrapper.py:184] Runner is dead skipping kill.I1024 21:18:11.114897 52673 status_manager.py:109] Waiting for terminal state current state: ACTIVE...I1024 21:18:11.616302 52673 status_manager.py:109] Waiting for terminal state current state: ACTIVEI1024 21:18:12.117630 52673 status_manager.py:125] State we've accepted: Thermos(ACTIVE) / Failure: NoneE1024 21:18:12.117769 52673 status_manager.py:129] Runner is dead but task state unexpectedly ACTIVE!...D1024 21:18:12.664916 52673 ckpt.py:336] Flipping task state from FINALIZING to KILLEDD1024 21:18:12.665034 52673 runner.py:229] _on_task_transition: TaskStatus(state=3 runner_uid=0 runner_pid=52673 timestamp_ms=1382649492664)D1024 21:18:12.737503 52673 runner.py:188] Task on_killed(TaskStatus(state=3 runner_uid=0 runner_pid=52673 timestamp_ms=1382649492664))I1024 21:18:12.737726 52673 helper.py:125]   Coordinator stage_twemcache [pid: 52758] completed.I1024 21:18:12.737891 52673 helper.py:136]   Process stage_twemcache [pid: 52759] completed.I1024 21:18:12.738014 52673 runner.py:903] Transitioning application to LOSTD1024 21:18:12.738142 52673 helper.py:204] TaskRunnerHelper.kill_process(stage_twemcache)I1024 21:18:12.738306 52673 helper.py:125]   Coordinator stage_twemcache [pid: 52758] completed.I1024 21:18:12.738466 52673 helper.py:136]   Process stage_twemcache [pid: 52759] completed.D1024 21:18:12.738584 52673 helper.py:212]    => SIGKILL coordinator group 52758I1024 21:18:12.738967 52673 status_manager.py:150] Sending terminal state update: TASK_LOST{noformat}",null,2,2,1,0,Brian Wickman,Brian Wickman,Brian Wickman,2,0,1,1,1,0,0,0
AURORA-802,Bug,42,Resolved,Quota is not checked correctly in startJobUpdate,The prod resources represented by the IJobUpdate are rolled up into IResourceAggregate and thus anonymized before being passed into the QuotaManager. This makes QuotaManager treat update resources as purely additive leading to double counting.,null,1,2,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,3,0,0,0,0,0,0,0
AURORA-678,Task,42,Resolved,Serve static HTTP assets out of a classpath directory,Static asset registration with our HTTP server is somewhat complicated requiring a manual mapping to be made from the request to match and the classpath entry to serve.  Jetty has built-in support for serving static assets out of a directory on the classpath which would reduce all of our asset binding code to a few lines.  It also opens the doors to easy extension of the web interface at runtime by adding to the classpath and would also reduce iteration time when developing the web interface.,null,3,3,1,0,Joshua Cohen,Bill Farner,Bill Farner,2,0,1,1,1,0,0,0
AURORA-722,Bug,42,Resolved,snapshot performance issues,In one of our larger production clusters we're seeing issues with snapshot performance that cause the scheduler to failover before completing a snapshot.For background the scheduler writes a compressed (when -deflate_snapshots is enabled) binary-encoded Snapshot (from api.thrift) to the mesos replicated log every hour (or -dlog_snapshot_interval). This snapshot represents most of the scheduler's heap usage including the configuration for all tasks running in the cluster.Add appropriate instrumentation to the snapshot routine and patch any obvious performance bottlenecks.,null,3,3,1,0,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,5,0,1,0,0,0,0,0
AURORA-742,Task,42,Resolved,Add client commands to query server-driven updates.,null,null,3,1,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,1,0,0,0,0,0,0,0
AURORA-780,Bug,42,Resolved,python checkstyle looks at 3rdparty,"When attempting to commit https://reviews.apache.org/r/25835/ I was blocked by Python checkstyle as the rename of checked-in bootstrap test files (some written in python) was picked up.{noformat}T401:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:002 From import must import names in lexical order.     |from __future__ import absolute_import unicode_literals print_function divisionT401:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:005 From import must import names in lexical order.     |from os import environ stat remove as _delete_fileT401:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:006 From import must import names in lexical order.     |from os.path import isfile dirname basename abspathT405:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:004 Import block starting here contains imports from multiple module types: stdlib 3rdparty.     |from sys import argvT100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:018 Indentation of 4 instead of 2     |    BUCKET_NAME = environ['TWBS_S3_BUCKET']T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:020 Indentation of 4 instead of 2     |    raise SystemExit(""TWBS_S3_BUCKET environment variable not set!"")T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:024 Indentation of 4 instead of 2     |    hasher = sha256()T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:026 Indentation of 4 instead of 2     |        hasher.update(input_file.read())T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:033 Indentation of 4 instead of 2     |    try:T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:034 Indentation of 4 instead of 2     |        _delete_file(filename)T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:036 Indentation of 4 instead of 2     |        passT100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:040 Indentation of 4 instead of 2     |    kib = stat(_tarball_filename_for(directory)).st_size // BYTES_PER_MBT100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:045 Indentation of 4 instead of 2     |    return abspath('./{}.tar.gz'.format(basename(directory)))T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:049 Indentation of 4 instead of 2     |    print(""Creating tarball of {}..."".format(directory))T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:054 Indentation of 4 instead of 2     |    print(""Extracting tarball of {}..."".format(directory))T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:059 Indentation of 4 instead of 2     |    _delete_file_quietly(NEED_TO_UPLOAD_MARKER)T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:061 Indentation of 4 instead of 2     |        print(""Downloading {} tarball from S3..."".format(friendly_name))T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:064 Indentation of 4 instead of 2     |        open(NEED_TO_UPLOAD_MARKER 'a').close()T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:073 Indentation of 4 instead of 2     |    _create_tarball(directory)T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:084 Indentation of 4 instead of 2     |    argv.pop(0)T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:086 Indentation of 4 instead of 2     |        raise SystemExit(""USAGE: s3_cache.py <download | upload> <friendly name> <dependencies file> <directory>"")T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:092 Indentation of 4 instead of 2     |        raise SystemExit(""Could not access bucket!"")T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:100 Indentation of 4 instead of 2     |        download(directory)T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:102 Indentation of 4 instead of 2     |        if isfile(NEED_TO_UPLOAD_MARKER):  # FIXMET100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:103 Indentation of 4 instead of 2     |            upload(directory)T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:105 Indentation of 4 instead of 2     |            print(""No need to upload anything."")T100:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:107 Indentation of 4 instead of 2     |        raise SystemExit(""Unrecognized mode {!r}"".format(mode))T802:WARNING 3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:064 open() calls should be made within a contextmanager.     |        open(NEED_TO_UPLOAD_MARKER 'a').close()E501:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:050 line too long (105 > 100 characters)     |    run(['tar' '-czf' _tarball_filename_for(directory) '-C' dirname(directory) basename(directory)])E501:ERROR   3rdparty/javascript/scheduler/assets/bower_components/bootstrap/test-infra/s3_cache.py:086 line too long (114 > 100 characters)     |        raise SystemExit(""USAGE: s3_cache.py <download | upload> <friendly name> <dependencies file> <directory>""){noformat}",null,3,2,1,0,Joshua Cohen,Kevin Sweeney,Kevin Sweeney,2,0,0,0,0,0,0,0
AURORA-774,Task,42,Resolved,Expose MTTA/R SLA metrics for non-prod jobs,In a cluster with limited resources where production jobs take scheduling priority and/or preempt non-prod jobs it will be useful to track median times to assigned/running for non-prod jobs. This will help estimating the performance impact in the event of a (un-)planned capacity removal.,null,3,2,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-689,Story,42,Resolved,Start vetting Mesos 0.21.0,This should include both the changes in python-land as well as for the scheduler.Should include a review of https://reviews.apache.org/r/24264 as well.,null,3,3,1,0,David McLaughlin,Joe Smith,Joe Smith,4,0,1,0,0,0,0,0
AURORA-788,Bug,42,Resolved,GC executor doesn't need to exit after period of inactivity,The GC Executor is currently configured to exit after a hardcoded limit of activity since it processed a launchTask request. This causes needless task churn in the cluster especially given that the scheduler's default launch interval will cause the executor to need to be relaunched on average every 15 minutes.,null,4,2,1,0,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,1,0,1,0,0,0,0,0
AURORA-751,Task,42,Resolved,Remove SANDBOX_DELETED task state,Given the upcoming GC deprecation remove SANDBOX_DELETED state from the TaskStateMachine. It was only used to correctly drive the scheduler UI.,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-786,Bug,42,Resolved,Client does not log Response.messageDEPRECATED errors,"The implementation of context.py:log_response() checks only the new {{details}} field but not the old {{messageDEPRECATED}} one. This leads to ignoring unhandled updater errors wrapped into a synthetic Response object:{noformat}...log(info): Cleaning upError: Update failed; see log for details.log(info): Error executing command: Update failed; see log for details.Error executing command: Update failed; see log for details.{noformat}The ""Update failed; see log for details."" message is misleading as there will be nothing in the log in this case.",null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-363,Task,42,Resolved,the new pants selects 2.6.x by default if it's available,The new pants finds all the python interpreters on the path and selects the minimum version that is compatible with it.  Previous behavior would use sys.executable (the current interpreter) which is more desirable.  We should update pants invocations so that we select the current interpreter or at least CPython>=2.7<3,null,3,2,1,0,Joe Smith,Brian Wickman,Brian Wickman,3,0,2,0,0,0,0,0
AURORA-748,Bug,42,Resolved,Help command is broken,$ aurora2.pex help update startlog(ERROR): Unknown error: sequence item 24: expected string instancemethod foundlog(ERROR): Unknown error: sequence item 24: expected string instancemethod foundThis also happens for `help update pause`.,null,4,3,1,0,Joe Smith,Kevin Burg,Kevin Burg,2,0,0,0,0,0,0,0
AURORA-781,Story,42,Resolved,Fix bind parameter processing in client,In client commands there are two problems involving pystachio bindings:(1) Binding parameters sometimes don't work correctly;(2) If a binding never gets resolved an error isn't generated.,null,3,2,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,3,0,0,0,0,0,0,0
AURORA-142,Task,42,Resolved,Remove getVersion API from client,The getVersion RPC has been deprecated in favor of the Response.serverInfo field.  Change the client to stop using getVersion.,null,3,2,1,0,Bill Farner,Suman Karumuri,Suman Karumuri,2,0,3,2,2,0,0,0
AURORA-333,Task,42,Resolved,finish all deprecations in schema/base.py,There are currently a number of deprecations listed in src/main/python/apache/aurora/config/schema/base.pycron_policydaemonhealth_check_interval_secsand a number of other structs that should be removed:recipesPacker,null,3,3,1,0,Zameer Manji,Brian Wickman,Brian Wickman,3,0,0,0,0,0,0,0
AURORA-504,Bug,42,Resolved,there should be a section to describe how to clone git repo in howtocontribute page,The aurora how to contirbue guide here http://aurora.incubator.apache.org/docs/howtocontribute/says not a lot of useful information for example even not a section to describe where to find the latest code.It may confusing people who try to find latest code at this page and then follow other doc to build-deploy.,null,4,2,1,0,Joshua Cohen,Chengwei Yang,Chengwei Yang,1,0,0,0,0,0,0,0
AURORA-770,Bug,42,Resolved,V2 client logs HTTP connections to info,I see this with all v2 client commands:{noformat}log(info): Starting new HTTP connection (1): 192.168.33.7log(info): Starting new HTTP connection (1): 192.168.33.7{noformat}Presumably these should be debug-level log messages.,null,3,3,1,0,Joshua Cohen,Bill Farner,Bill Farner,2,0,0,0,0,0,0,0
AURORA-801,Bug,42,Resolved,deadlock in scheduler startup,The recently-added update code adds a deadlock to the scheduler whenever there are concurrent {{SchedulerActive}} and {{TasksDeleted}} events on the EventBus.Relevant bits from /threads{noformat}Name: AsyncProcessor-0State: BLOCKEDDaemon: trueID: 2461    org.apache.aurora.scheduler.updater.JobUpdateEventSubscriber.tasksDeleted(JobUpdateEventSubscriber.java:64)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    com.google.common.eventbus.EventSubscriber.handleEvent(EventSubscriber.java:74)    com.google.common.eventbus.SynchronizedEventSubscriber.handleEvent(SynchronizedEventSubscriber.java:47)    com.google.common.eventbus.EventBus.dispatch(EventBus.java:322)    com.google.common.eventbus.EventBus.dispatchQueuedEvents(EventBus.java:304)    com.google.common.eventbus.EventBus.post(EventBus.java:275)    org.apache.aurora.scheduler.events.PubsubEventModule$2.post(PubsubEventModule.java:68)    org.apache.aurora.scheduler.state.StateManagerImpl.updateTaskAndExternalState(StateManagerImpl.java:443)    org.apache.aurora.scheduler.state.StateManagerImpl.access$100(StateManagerImpl.java:80)    org.apache.aurora.scheduler.state.StateManagerImpl$8.execute(StateManagerImpl.java:460)    org.apache.aurora.scheduler.storage.Storage$MutateWork$NoResult.apply(Storage.java:132)    org.apache.aurora.scheduler.storage.Storage$MutateWork$NoResult$Quiet.apply(Storage.java:149)    org.apache.aurora.scheduler.storage.log.LogStorage$7.apply(LogStorage.java:559)    org.apache.aurora.scheduler.storage.log.LogStorage$7.apply(LogStorage.java:556)    org.apache.aurora.scheduler.storage.mem.MemStorage.doWork(MemStorage.java:175)    org.apache.aurora.scheduler.storage.mem.MemStorage.access$400(MemStorage.java:59)    org.apache.aurora.scheduler.storage.mem.MemStorage$4.apply(MemStorage.java:200)    org.apache.aurora.scheduler.storage.mem.MemStorage$4.apply(MemStorage.java:197)    org.apache.aurora.scheduler.storage.db.DbStorage.write(DbStorage.java:150)    org.apache.aurora.scheduler.storage.db.DbStorage$$EnhancerByGuice$$51136dc.CGLIB$write$0(<generated>)    org.apache.aurora.scheduler.storage.db.DbStorage$$EnhancerByGuice$$51136dc$$FastClassByGuice$$8e80cfa0.invoke(<generated>)    com.google.inject.internal.cglib.proxy.$MethodProxy.invokeSuper(MethodProxy.java:228)    com.google.inject.internal.InterceptorStackCallback$InterceptedMethodInvocation.proceed(InterceptorStackCallback.java:72)    org.mybatis.guice.transactional.TransactionalMethodInterceptor.invoke(TransactionalMethodInterceptor.java:101)    com.google.inject.internal.InterceptorStackCallback$InterceptedMethodInvocation.proceed(InterceptorStackCallback.java:72)    com.google.inject.internal.InterceptorStackCallback.intercept(InterceptorStackCallback.java:52)    org.apache.aurora.scheduler.storage.db.DbStorage$$EnhancerByGuice$$51136dc.write(<generated>)    org.apache.aurora.scheduler.storage.mem.MemStorage.write(MemStorage.java:197)    org.apache.aurora.scheduler.storage.log.LogStorage.write(LogStorage.java:556)    org.apache.aurora.scheduler.storage.CallOrderEnforcingStorage.write(CallOrderEnforcingStorage.java:130)    org.apache.aurora.scheduler.state.StateManagerImpl.deleteTasks(StateManagerImpl.java:451)    org.apache.aurora.scheduler.async.HistoryPruner.deleteTasks(HistoryPruner.java:126)    org.apache.aurora.scheduler.async.HistoryPruner.access$500(HistoryPruner.java:51)    org.apache.aurora.scheduler.async.HistoryPruner$3.run(HistoryPruner.java:164)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)    java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)    java.lang.Thread.run(Thread.java:745)Name: Lifecycle-0State: BLOCKEDDaemon: trueID: 2462    org.apache.aurora.scheduler.storage.log.LogStorage.write(LogStorage.java:544)    org.apache.aurora.scheduler.storage.CallOrderEnforcingStorage.write(CallOrderEnforcingStorage.java:130)    org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.systemResume(JobUpdateControllerImpl.java:195)    org.apache.aurora.scheduler.updater.JobUpdateEventSubscriber.schedulerActive(JobUpdateEventSubscriber.java:83)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    com.google.common.eventbus.EventSubscriber.handleEvent(EventSubscriber.java:74)    com.google.common.eventbus.SynchronizedEventSubscriber.handleEvent(SynchronizedEventSubscriber.java:47)    com.google.common.eventbus.EventBus.dispatch(EventBus.java:322)    com.google.common.eventbus.EventBus.dispatchQueuedEvents(EventBus.java:304)    com.google.common.eventbus.EventBus.post(EventBus.java:275)    org.apache.aurora.scheduler.events.PubsubEventModule$2.post(PubsubEventModule.java:68)    org.apache.aurora.scheduler.SchedulerLifecycle$7$2.run(SchedulerLifecycle.java:336)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)    java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)    java.lang.Thread.run(Thread.java:745){noformat},null,1,1,1,0,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,2,0,1,0,0,0,0,0
AURORA-803,Task,42,Resolved,"Return valid JSON structure as ""job status"" result with ""--write-json""","Users writing scripts that use the ""job status"" command would prefer that when a job isn't running that fact be expressed through a valid JSON response rather than an exit code.So for example right now if you run ""aurora job status devcluster/mchucarroll/test/foobar"" you'll get back an error message on standard error with exit code 6.Script users would prefer a response like:{""job"": ""devcluster/mchucarroll/test/foobar"" ""error"": ""No running jobs found""}",null,3,1,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,1,0,0,0,0,0,0,0
AURORA-806,Task,42,Resolved,Support per batch post_drain execution in admin host_drain command,The changed semantic of the host_drain command rendered {{--post_drain_script}} option less relevant and as a result it was moved into maintenance.py to run once for all drained hosts. That proved to be inconvenient for draining large sets of machines where per-batch script execution would speed up overall maintenance time.Consider moving post drain script execution back into host_maintenance.py to run for every batch of hosts. ,null,2,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-807,Bug,42,Resolved,GC executor doesn't ignore launchTasks when it's shutting down,Instead it queues the task (which it will never process) leading Mesos to report a {{TASK_LOST}} when it exits seconds later.,null,3,2,1,1,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-819,Task,42,Resolved,Investigate JaCoCo plugin failure in Jenkins Build 633,Jenkins Build #633 failed with the following error message from gradle:{noformat}:jacocoTestReportCoverage report generated: file://<https://builds.apache.org/job/Aurora/ws/dist/reports/jacoco/test/html/index.html>:jacocoTestReport FAILEDFAILURE: Build failed with an exception.* Where:Build file '<https://builds.apache.org/job/Aurora/ws/build.gradle'> line: 595* What went wrong:Execution failed for task ':jacocoTestReport'.> Test coverage missing for org/apache/aurora/scheduler/http/api/ApiBeta$2. Expression: (coverage != 0). Values: coverage = 0* Try:Run with --info or --debug option to get more log output.* Exception is:org.gradle.api.tasks.TaskExecutionException: Execution failed for task ':jacocoTestReport'.        at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:69)        at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.execute(ExecuteActionsTaskExecuter.java:46)        at org.gradle.api.internal.tasks.execution.PostExecutionAnalysisTaskExecuter.execute(PostExecutionAnalysisTaskExecuter.java:35)        at org.gradle.api.internal.tasks.execution.SkipUpToDateTaskExecuter.execute(SkipUpToDateTaskExecuter.java:64)        at org.gradle.api.internal.tasks.execution.ValidatingTaskExecuter.execute(ValidatingTaskExecuter.java:58)        at org.gradle.api.internal.tasks.execution.SkipEmptySourceFilesTaskExecuter.execute(SkipEmptySourceFilesTaskExecuter.java:42)        at org.gradle.api.internal.tasks.execution.SkipTaskWithNoActionsExecuter.execute(SkipTaskWithNoActionsExecuter.java:52)        at org.gradle.api.internal.tasks.execution.SkipOnlyIfTaskExecuter.execute(SkipOnlyIfTaskExecuter.java:53)        at org.gradle.api.internal.tasks.execution.ExecuteAtMostOnceTaskExecuter.execute(ExecuteAtMostOnceTaskExecuter.java:43)        at org.gradle.api.internal.AbstractTask.executeWithoutThrowingTaskFailure(AbstractTask.java:305)        at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.executeTask(AbstractTaskPlanExecutor.java:79)        at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.processTask(AbstractTaskPlanExecutor.java:63)        at org.gradle.execution.taskgraph.AbstractTaskPlanExecutor$TaskExecutorWorker.run(AbstractTaskPlanExecutor.java:51)        at org.gradle.execution.taskgraph.DefaultTaskPlanExecutor.process(DefaultTaskPlanExecutor.java:23)        at org.gradle.execution.taskgraph.DefaultTaskGraphExecuter.execute(DefaultTaskGraphExecuter.java:88)        at org.gradle.execution.SelectedTaskExecutionAction.execute(SelectedTaskExecutionAction.java:29)        at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:62)        at org.gradle.execution.DefaultBuildExecuter.access$200(DefaultBuildExecuter.java:23)        at org.gradle.execution.DefaultBuildExecuter$2.proceed(DefaultBuildExecuter.java:68)        at org.gradle.execution.DryRunBuildExecutionAction.execute(DryRunBuildExecutionAction.java:32)        at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:62)        at org.gradle.execution.DefaultBuildExecuter.execute(DefaultBuildExecuter.java:55)        at org.gradle.initialization.DefaultGradleLauncher.doBuildStages(DefaultGradleLauncher.java:149)        at org.gradle.initialization.DefaultGradleLauncher.doBuild(DefaultGradleLauncher.java:106)        at org.gradle.initialization.DefaultGradleLauncher.run(DefaultGradleLauncher.java:86)        at org.gradle.launcher.exec.InProcessBuildActionExecuter$DefaultBuildController.run(InProcessBuildActionExecuter.java:80)        at org.gradle.launcher.cli.ExecuteBuildAction.run(ExecuteBuildAction.java:33)        at org.gradle.launcher.cli.ExecuteBuildAction.run(ExecuteBuildAction.java:24)        at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:36)        at org.gradle.launcher.exec.InProcessBuildActionExecuter.execute(InProcessBuildActionExecuter.java:26)        at org.gradle.launcher.cli.RunBuildAction.run(RunBuildAction.java:51)        at org.gradle.internal.Actions$RunnableActionAdapter.execute(Actions.java:171)        at org.gradle.launcher.cli.CommandLineActionFactory$ParseAndBuildAction.execute(CommandLineActionFactory.java:237)        at org.gradle.launcher.cli.CommandLineActionFactory$ParseAndBuildAction.execute(CommandLineActionFactory.java:210)        at org.gradle.launcher.cli.JavaRuntimeValidationAction.execute(JavaRuntimeValidationAction.java:35)        at org.gradle.launcher.cli.JavaRuntimeValidationAction.execute(JavaRuntimeValidationAction.java:24)        at org.gradle.launcher.cli.CommandLineActionFactory$WithLogging.execute(CommandLineActionFactory.java:206)        at org.gradle.launcher.cli.CommandLineActionFactory$WithLogging.execute(CommandLineActionFactory.java:169)        at org.gradle.launcher.cli.ExceptionReportingAction.execute(ExceptionReportingAction.java:33)        at org.gradle.launcher.cli.ExceptionReportingAction.execute(ExceptionReportingAction.java:22)        at org.gradle.launcher.Main.doAction(Main.java:33)        at org.gradle.launcher.bootstrap.EntryPoint.run(EntryPoint.java:45)        at org.gradle.launcher.bootstrap.ProcessBootstrap.runNoExit(ProcessBootstrap.java:54)        at org.gradle.launcher.bootstrap.ProcessBootstrap.run(ProcessBootstrap.java:35)        at org.gradle.launcher.GradleMain.main(GradleMain.java:23)        at org.gradle.wrapper.BootstrapMainStarter.start(BootstrapMainStarter.java:30)        at org.gradle.wrapper.WrapperExecutor.execute(WrapperExecutor.java:127)        at org.gradle.wrapper.GradleWrapperMain.main(GradleWrapperMain.java:56)Caused by: java.lang.AssertionError: Test coverage missing for org/apache/aurora/scheduler/http/api/ApiBeta$2. Expression: (coverage != 0). Values: coverage = 0        at build_gsqlbkk7l35mk455mp7a81015$_run_closure24_closure62_closure63_closure64.doCall(<https://builds.apache.org/job/Aurora/ws/build.gradle>:595)        at build_gsqlbkk7l35mk455mp7a81015$_run_closure24_closure62_closure63.doCall(<https://builds.apache.org/job/Aurora/ws/build.gradle>:589)        at build_gsqlbkk7l35mk455mp7a81015$_run_closure24_closure62.doCall(<https://builds.apache.org/job/Aurora/ws/build.gradle>:588)        at org.gradle.api.internal.AbstractTask$ClosureTaskAction.execute(AbstractTask.java:548)        at org.gradle.api.internal.AbstractTask$ClosureTaskAction.execute(AbstractTask.java:529)        at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeAction(ExecuteActionsTaskExecuter.java:80)        at org.gradle.api.internal.tasks.execution.ExecuteActionsTaskExecuter.executeActions(ExecuteActionsTaskExecuter.java:61)        ... 47 moreBUILD FAILEDTotal time: 6 mins 0.964 secsBuild step 'Execute shell' marked build as failureRecording test results{noformat}The task is to investigate and remedy this error.,null,3,2,1,0,Zameer Manji,Zameer Manji,Zameer Manji,3,0,0,0,0,0,0,0
AURORA-820,Task,42,Resolved,Admin host_drain should throttle status waiting calls,With the removal of the 30 second wait in host_drain (https://reviews.apache.org/r/25667/) there is nothing left to control the pace of status calls. Add a delay loop and a timeout to prevent infinite waiting.,null,2,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-836,Bug,42,Resolved,test_integration_success in test_thermos_task_runner is flaky,This fails consistently on my workstation but seems to pass on mac laptops and jenkins.{noformat}$ ./pants build --timeout=60 src/test/python/apache/aurora/executor:thermos_task_runner -vxsBuild operating on top level addresses: set([BuildFileAddress(/home/wfarner/code/aurora/src/test/python/apache/aurora/executor/BUILD thermos_task_runner)])======================================================================== test session starts =========================================================================platform linux2 -- Python 2.7.6 -- py-1.4.25 -- pytest-2.6.3 -- /usr/bin/python2.7plugins: cov timeoutcollected 8 items src/test/python/apache/aurora/executor/test_thermos_task_runner.py::TestThermosTaskRunnerIntegration::test_integration_success Writing log files to disk in /tmp/tmpX_YDxuBuild operating on top level addresses: set([BuildFileAddress(/home/wfarner/code/aurora/src/main/python/apache/aurora/executor/bin/BUILD thermos_runner)])Building PythonBinary PythonBinary(BuildFileAddress(/home/wfarner/code/aurora/src/main/python/apache/aurora/executor/bin/BUILD thermos_runner)):Wrote /home/wfarner/code/aurora/dist/thermos_runner.pexWriting log files to disk in /tmp/tmpX_YDxuFAILED============================================================================== FAILURES ==============================================================================_____________________________________________________ TestThermosTaskRunnerIntegration.test_integration_success ______________________________________________________self = <test_thermos_task_runner.TestThermosTaskRunnerIntegration object at 0x7f89258d9090>    def test_integration_success(self):      with self.yield_sleepy(ThermosTaskRunner sleep=0 exit_code=0) as task_runner:>       task_runner.start()src/test/python/apache/aurora/executor/test_thermos_task_runner.py:136: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ /tmp/tmpxQyM2Q/apache/aurora/executor/thermos_task_runner.py:282: in start    self.wait_start(timeout=timeout)_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ self = <apache.aurora.executor.thermos_task_runner.ThermosTaskRunner object at 0x7f89258eaa90> timeout = Amount(1 mins)    def wait_start(self timeout=MAX_WAIT):      log.debug('Waiting for task to start.')          def is_started():        return self._monitor and (self._monitor.active or self._monitor.finished)          waited = Amount(0 Time.SECONDS)          while waited < timeout:        if not is_started():          log.debug('  - sleeping...')          self._clock.sleep(self.POLL_INTERVAL.as_(Time.SECONDS))          waited += self.POLL_INTERVAL        else:          break            if not self.is_alive:          if self._popen_rc != 0:            raise TaskError('Task failed: %s' % self._popen_reason())          else:>           log.info('Task runner exited: %s' % self._popen_reason())E           AttributeError: 'ThermosTaskRunner' object has no attribute '_popen_reason'/tmp/tmpxQyM2Q/apache/aurora/executor/thermos_task_runner.py:304: AttributeError!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!====================================================================== 1 failed in 2.42 seconds ======================================================================src.test.python.apache.aurora.executor.thermos_task_runner                      .....   FAILURE{noformat},null,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-837,Bug,42,Resolved,validateSessionKeyForTasks can pass empty set of roles to checkAuthenticated,SchedulerThriftInterface.java contains the following:{noformat}  private SessionContext validateSessionKeyForTasks(      SessionKey session      Query.Builder taskQuery      Iterable<IScheduledTask> tasks) throws AuthFailedException {    // Authenticate the session against any affected roles always including the role for a    // role-scoped query.  This papers over the implementation detail that dormant cron jobs are    // authenticated this way.    ImmutableSet.Builder<String> targetRoles = ImmutableSet.<String>builder()        .addAll(FluentIterable.from(tasks).transform(GET_ROLE));    if (taskQuery.get().isSetOwner()) {      targetRoles.add(taskQuery.get().getOwner().getRole());    }    return sessionValidator.checkAuthenticated(session targetRoles.build());  }{noformat}Since the owner field is deprecated and a cron job may not have any tasks available this can pass an empty set into {{checkAuthenticated}}. We should also grab the role from the query.,null,1,1,1,0,Zameer Manji,Zameer Manji,Zameer Manji,1,0,0,0,0,0,0,0
AURORA-841,Story,42,Resolved,LeaderRedirectFilter using rewritten URI path as redirect target,When the LeaderRedirectFilter attempts to send a 302 to point requests to the current leader it uses {{HttpServletRequest#getRequestUri}} unfortunately after AURORA-678 the path returned from this method has already been rewritten causing us to issue a redirect to an invalid path.,null,3,1,1,0,Joshua Cohen,Joshua Cohen,Joshua Cohen,1,0,0,0,0,0,0,0
AURORA-846,Bug,42,Resolved,document /etc/aurora/clusters.json,I don't think this is documented anywhere.  Things like proxy_url were a surprise to me.,null,3,2,1,0,Joshua Cohen,Jay Buffington,Jay Buffington,1,0,0,0,0,0,0,0
AURORA-848,Story,42,Resolved,Handle resourceOffers callback asynchronously,Since the mesos driver synchronizes all callbacks it's very important to return as quickly as possible to avoid blocking other callbacks.  In the case of {{resourceOffers}} we start by calling {{storage.write}} which will stall if the write lock is held.  In very large busy clusters we've observed {{resourceOffers}} routinely taking > 1 second which can lead to delays in receiving status updates.I suggest the entire body of {{resourceOffers}} be asynchronous to prevent it from backing up status updates.,null,2,3,1,0,Zameer Manji,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-84,Task,42,Resolved,Deprecate the Identity struct,The Identity field is nested in several structs and the {{role}} field it contains is ~always redundant to a field in {{JobKey}}. Consider removing Identity and using (or adding) a non-user-bearing field like JobKey.An open question is whether whether {{Identity.user}} should be retained.  Most likely yes.,null,3,6,1,0,Maxim Khutornenko,Bill Farner,Bill Farner,29,0,1,0,0,0,0,0
AURORA-852,Story,42,Resolved,create architectural diagram with description of components,Write a doc that gives a high level overview of all of the components need to use aurora:* client* scheduler* zookeeper* mesos master* mesos slave* aurora executor* thermos runner* thermos observer,null,3,4,1,0,Stephan Erb,Jay Buffington,Jay Buffington,3,2,0,0,0,0,0,0
AURORA-834,Story,42,Closed,what to-do with the distribution files,the result of./gradlew distZip./build-support/release/make-python-sdistsis new-host:incubator-aurora joestein$ ls -l /opt/apache/incubator-aurora/disttotal 93008-rw-r--r--  1 joestein  staff     58265 Oct 13 17:30 apache.aurora.client-0.5.1-SNAPSHOT.tar.gz-rw-r--r--  1 joestein  staff     86480 Oct 13 17:30 apache.aurora.clientv2-0.5.1-SNAPSHOT.tar.gz-rw-r--r--  1 joestein  staff      9033 Oct 13 17:30 apache.aurora.common-0.5.1-SNAPSHOT.tar.gz-rw-r--r--  1 joestein  staff      9868 Oct 13 17:30 apache.aurora.config-0.5.1-SNAPSHOT.tar.gz-rw-r--r--  1 joestein  staff     32612 Oct 13 17:30 apache.aurora.executor-0.5.1-SNAPSHOT.tar.gz-rw-r--r--  1 joestein  staff     45445 Oct 13 17:31 apache.gen.aurora-0.5.1-SNAPSHOT.tar.gz-rw-r--r--  1 joestein  staff      4216 Oct 13 17:31 apache.gen.thermos-0.5.1-SNAPSHOT.tar.gz-rw-r--r--  1 joestein  staff      8329 Oct 13 17:30 apache.thermos-0.5.1-SNAPSHOT.tar.gz-rw-r--r--  1 joestein  staff      9406 Oct 13 17:30 apache.thermos.common-0.5.1-SNAPSHOT.tar.gz-rw-r--r--  1 joestein  staff      6586 Oct 13 17:31 apache.thermos.config-0.5.1-SNAPSHOT.tar.gz-rw-r--r--  1 joestein  staff     19830 Oct 13 17:31 apache.thermos.core-0.5.1-SNAPSHOT.tar.gz-rw-r--r--  1 joestein  staff     11507 Oct 13 17:31 apache.thermos.monitoring-0.5.1-SNAPSHOT.tar.gz-rw-r--r--  1 joestein  staff    111181 Oct 13 17:31 apache.thermos.observer-0.5.1-SNAPSHOT.tar.gz-rwxr-xr-x  1 joestein  wheel   1680218 Dec 16  2013 aurora_admin.pex-rwxr-xr-x  1 joestein  wheel   2366295 Dec 16  2013 aurora_client.pexdrwxr-xr-x  3 joestein  wheel       102 Dec  6  2013 distributions-rwxr-xr-x  1 joestein  wheel  20008774 Dec 16  2013 gc_executor.pex-rwxr-xr-x  1 joestein  wheel  20822380 Dec 16  2013 thermos_executor.pex-rwxr-xr-x  1 joestein  wheel   2285911 Dec 16  2013 thermos_observer.pexalso how it relates to the vagrant setup path (which is most followed I think)aurorabuild client client2 admin_client executor observer schedulerwould be great to know what these all mean and do exactly in regards to running aurora in production thanks! If it exists maybe link it better with the setup deploy section please thanks!,null,3,3,0,0,null,Joe Stein,Joe Stein,3,1,1,0,0,0,0,0
AURORA-782,Story,42,Resolved,Remove command bridging from client,The v2 client will resolve v1 commands.  Remove this to stop supporting old command syntax.,null,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,1,2,1,1,0,0,0
AURORA-798,Bug,46,Resolved,investigate flaky test: LockManagerImplTest/testNoDeadlock,A test caused CI to fail on an unrelated Python change:See https://builds.apache.org/job/Aurora/618/testReport/junit/org.apache.aurora.scheduler.state/LockManagerImplTest/testNoDeadlock/{noformat}java.lang.RuntimeException: java.lang.AssertionError:   Expectation failure on verify:    Mutable.fetchLock(<LockKey job:JobKey(role:jim environment:devel name:myJob)>): expected: 2 actual: 1Stacktracejava.lang.RuntimeException: java.lang.AssertionError:   Expectation failure on verify:    Mutable.fetchLock(<LockKey job:JobKey(role:jim environment:devel name:myJob)>): expected: 2 actual: 1at com.google.common.testing.ClusterException.create(ClusterException.java:116)at com.google.common.testing.TearDownStack.runTearDown(TearDownStack.java:69)at com.google.common.testing.junit4.TearDownTestCase.tearDown(TearDownTestCase.java:113)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)at org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:168)at org.junit.rules.RunRules.evaluate(RunRules.java:20)at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)at org.junit.runners.ParentRunner.run(ParentRunner.java:309)at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:69)at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:48)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:105)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:355)at org.gradle.internal.concurrent.DefaultExecutorFactory$StoppableExecutorImpl$1.run(DefaultExecutorFactory.java:64)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:724)Caused by: java.lang.AssertionError:   Expectation failure on verify:    Mutable.fetchLock(<LockKey job:JobKey(role:jim environment:devel name:myJob)>): expected: 2 actual: 1at org.easymock.internal.MocksControl.verify(MocksControl.java:226)at com.twitter.common.testing.easymock.EasyMockTest$1.tearDown(EasyMockTest.java:54)at com.google.common.testing.TearDownStack.runTearDown(TearDownStack.java:58)... 45 moreStandard ErrorOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waiting{noformat},null,3,2,1,0,Maxim Khutornenko,Kevin Sweeney,Kevin Sweeney,2,0,0,0,0,0,0,0
AURORA-882,Bug,46,Resolved,CI broken due to UpdaterTest::test_update_instances_wait_for_batch_completion_filled_batch,See https://builds.apache.org/job/Aurora/676/console,null,1,2,1,0,null,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-248,Bug,46,Resolved,Use Mock with specs in client tests,While investigating AURORA-247 figured out that none of our tests is capable of catching unknown options due to spec-less way options are mocked. Use Mock(spec=['option1' 'option2' ...]) instead of Mock() everywhere in client tests to prevent issues like AURORA-247. ,null,2,4,1,0,David McLaughlin,Maxim Khutornenko,Maxim Khutornenko,4,0,0,0,0,0,0,0
AURORA-72,Story,46,Resolved,Improve root README.md,README.md is the first thing many prospective contributors will see when viewing the source code as well as the first thing many users will automatically jump to. Update it to be more helpful possibly merge with docs/README.md,null,3,2,1,0,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-825,Task,46,Resolved,Cron tasks don't check quota when launched,We don't check production quota when a cron task is launched by the CronJobManager. This leaves a potential to temporarily exceed allocated quota if prod consumption grew close to the limit _after_ a cron job was created. ,null,3,3,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,13,0,1,0,0,0,0,0
AURORA-886,Task,46,Resolved,aurora job create --wait-until should exit with error code if the job being waited on fails,If I invoke:aurora job create --wait-until=FINISHED ...and the job being waited on fails I think the aurora command should exit with an error code or should at least have the option to print something formatted that can be parsed.I'm not sure what the current thinking on exit codes is I would understand the argument that even if the job failed the aurora client did it's job without error. So I'd be happy with any way of detecting job failure (exit code or otherwise).,null,3,1,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,1,0,0,0,0,0,0,0
AURORA-863,Bug,46,Resolved,provision-dev-cluster.sh refers to mesos egg instead of mesos.native,This makes the executor fail to build in the vagrant environment. We were apparently depending on the mesos.native egg on pypi which was removed in MESOS-1898,null,1,4,1,0,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,4,0,2,2,2,0,0,0
AURORA-627,Task,46,Resolved,use latest psutil library for thermos in pants,"Unable to execute thermos due to following error. It's due to this bug in {{psutil}}. [issue 442|https://code.google.com/p/psutil/issues/detail?id=442]. We were using v1.1.2. We should use v1.1.3 or newer.Facing same issue with gc_executor and thermos_runner.{code}./dist/thermos_executor.pex                                                                   [latest] 18:30:53Traceback (most recent call last):  File ""/Volumes/apple/quark/incubator-aurora/dist/thermos_executor.pex/.bootstrap/_twitter_common_python/pex.py"" line 225 in execute    self.execute_interpreter()  File ""/usr/lib64/python2.6/contextlib.py"" line 34 in __exit__    self.gen.throw(type value traceback)  File ""/Volumes/apple/quark/incubator-aurora/dist/thermos_executor.pex/.bootstrap/_twitter_common_python/pex.py"" line 175 in patch_pkg_resources    yield  File ""/Volumes/apple/quark/incubator-aurora/dist/thermos_executor.pex/.bootstrap/_twitter_common_python/pex.py"" line 223 in execute    self.execute_entry(entry_point args)  File ""/Volumes/apple/quark/incubator-aurora/dist/thermos_executor.pex/.bootstrap/_twitter_common_python/pex.py"" line 271 in execute_entry    runner(entry_point)  File ""/Volumes/apple/quark/incubator-aurora/dist/thermos_executor.pex/.bootstrap/_twitter_common_python/pex.py"" line 293 in execute_pkg_resources    runner = entry.load(require=False)  # trust that the environment is sane  File ""/Volumes/apple/quark/incubator-aurora/dist/thermos_executor.pex/.bootstrap/pkg_resources.py"" line 2048 in load    entry = __import__(self.module_name globals()globals() ['__name__'])  File ""/Volumes/apple/quark/incubator-aurora/dist/thermos_executor.pex/apache/aurora/executor/bin/thermos_executor_main.py"" line 31 in <module>  File ""/Volumes/apple/quark/incubator-aurora/dist/thermos_executor.pex/apache/aurora/executor/thermos_task_runner.py"" line 31 in <module>  File ""/Volumes/apple/quark/incubator-aurora/dist/thermos_executor.pex/apache/thermos/core/runner.py"" line 70 in <module>  File ""/Volumes/apple/quark/incubator-aurora/dist/thermos_executor.pex/apache/thermos/core/helper.py"" line 21 in <module>  File ""/home/bhuvan/.pex/install/psutil-1.1.2-cp26-none-linux_x86_64.whl.a1805e756711e817e309c89cedf92d2a070c3ee7/psutil-1.1.2-cp26-none-linux_x86_64.whl/psutil/__init__.py"" line 89 in <module>    import psutil._pslinux as _psplatform  File ""/home/bhuvan/.pex/install/psutil-1.1.2-cp26-none-linux_x86_64.whl.a1805e756711e817e309c89cedf92d2a070c3ee7/psutil-1.1.2-cp26-none-linux_x86_64.whl/psutil/_pslinux.py"" line 21 in <module>    import _psutil_linuxImportError: /home/bhuvan/.pex/install/psutil-1.1.2-cp26-none-linux_x86_64.whl.a1805e756711e817e309c89cedf92d2a070c3ee7/psutil-1.1.2-cp26-none-linux_x86_64.whl/_psutil_linux.so: undefined symbol: prlimit{code}",null,3,4,1,0,Joe Smith,Bhuvaneswaran A,Bhuvaneswaran A,3,0,2,1,1,0,0,0
AURORA-779,Bug,46,Resolved,v2 client has worse error message than v1,"Copied from a user report at Twitter:I had a typo in an aurora config where I was resolving a mustache variable outside of a string:{code}instances = {{profile.instances}}{code}where I should have been doing{code}instances = ""{{profile.instances}}""{code}The error message on the v2 client was:{quote}Error executing command: Error loading configuration: name 'profile' is not defined{quote}The v1 client gave me a line number:{quote}  File ""router.aurora"" line 90 in <module>    instances = {{profile.instances}}NameError: name 'profile' is not defined{quote}",null,3,3,1,0,Mark Chu-Carroll,Kevin Sweeney,Kevin Sweeney,10,0,0,0,0,0,0,0
AURORA-833,Task,46,Resolved,Extract complex gradle tasks from build.gradle,Prime candidates:- thrift codegen task- custom jacoco output parsingContext:http://www.gradle.org/docs/current/userguide/custom_tasks.html,null,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,2,0,0,0,0,0,0,0
AURORA-824,Bug,46,Resolved,scheduleCronJob does not check quota or task limits,The scheduleCronJob RPC should call validateTaskLimits() and checkQuota().,null,2,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,1,0,0,0,0,0
AURORA-498,Bug,46,Resolved,test_end_to_end.sh uses stale aurora client,While working on a parallel updater noticed that running test_end_to_end.sh does not rebuild aurora client resulting in a potentially invalid run.,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-839,Story,46,Resolved,Add documentation describing the scheduler's storage system,The storage system in the scheduler is the most complicated part of the system and pretty unapproachable for new developers.  Some details will help acquaint people with the different moving pieces involved.,null,3,4,1,0,Maxim Khutornenko,Bill Farner,Bill Farner,5,0,0,0,0,0,0,0
AURORA-763,Task,46,Resolved,Document how to use the new asynchronous updater feature,We should document how the new async update works. ,null,3,2,1,0,Bill Farner,David McLaughlin,David McLaughlin,1,0,0,0,0,0,0,0
AURORA-830,Task,46,Resolved,Make Executor Overhead Configurable,Currently the overhead allocated for executors is hard coded into the {{ResourceSlot}} class. This should be changed so the overhead is taken from a command line flag. This is necessary so users can choose the impact executor overhead had on their cluster.,null,4,1,1,0,Zameer Manji,Zameer Manji,Zameer Manji,2,0,0,0,0,0,0,0
AURORA-888,Task,46,Resolved,Update client documentation to reflect the shift to clientv2.,null,null,3,1,1,0,null,Mark Chu-Carroll,Mark Chu-Carroll,0,0,2,0,0,0,0,0
AURORA-476,Story,46,Resolved,Run vagrant-based tests regularly,Our end-to-end tests offer a decent amount of integration test coverage and sometimes manage to catch issues that our unit test suites otherwise do not.  It would be awesome to run these in Jenkins perhaps on AWS.,null,3,2,1,0,null,Bill Farner,Bill Farner,0,0,1,0,0,0,0,0
AURORA-885,Task,46,Resolved,Improve lock held message in client output,When a user tries to kill a job that's locked by an in-progress/failed update the error message is confusing. It should clearly state that the problem is an update lock and how to release that lock.,null,3,2,1,0,David McLaughlin,Mark Chu-Carroll,Mark Chu-Carroll,2,0,1,0,0,0,0,0
AURORA-874,Task,46,Resolved,Make clientv2 job status include a header line for tasks like v1.,Clientv2 status shows information in a different form than v1 and deliberately ommitted some information. However users have complained about that information being missing and some tests were written to depend on its presence.,null,3,1,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,1,0,0,0,0,0,0,0
AURORA-875,Story,46,Resolved,Update Aurora to depend on mesos 0.20.1,null,null,3,1,1,0,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-877,Bug,46,Resolved,Build fails if thrift cannot be downloaded,Recently failed: https://builds.apache.org/job/Aurora/669{noformat}:bootstrapThriftgzip: stdin: not in gzip formattar: Child returned status 1tar: Error is not recoverable: exiting nowmake: *** [thrift-0.9.1/compiler/cpp/thrift] Error 2 FAILED{noformat},null,1,1,1,1,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,3,0,0,0,0,0,0,0
AURORA-84,Task,46,Resolved,Deprecate the Identity struct,The Identity field is nested in several structs and the {{role}} field it contains is ~always redundant to a field in {{JobKey}}. Consider removing Identity and using (or adding) a non-user-bearing field like JobKey.An open question is whether whether {{Identity.user}} should be retained.  Most likely yes.,null,3,6,1,0,Maxim Khutornenko,Bill Farner,Bill Farner,29,0,1,0,0,0,0,0
AURORA-878,Task,46,Resolved,Cache Host Attributes along Offer,At a large production cluster [~wfarner] and I have noticed that a lot of time is spent reading from the attribute store during scheduling. This is because when scheduling tasks we need to check the attributes of the slave before accepting an offer. We do this to compute diversity constraints.We can prevent frequent reading from the attribute store in this process by caching attributes alongside the offers. That way when we get an offer from a slave we can check the diversity constraints without reading from the AttributeStore.,null,3,3,1,0,Zameer Manji,Zameer Manji,Zameer Manji,4,0,0,0,0,0,0,0
AURORA-880,Task,46,Resolved,Add some wiggle room when requiring min coverage be raised,There are apparently differences in the calculation between local and jenkins builds to reduce build flakiness we should account for this.,null,4,1,1,0,Joshua Cohen,Joshua Cohen,Joshua Cohen,2,0,0,0,0,0,0,0
AURORA-887,Bug,46,Resolved,"""aurora job create --open-browser"" fails with error.","When calling ""aurora job create"" with the ""--open-browser"" flag it fails with:{noformat}Internal error executing command: 'AnnotatedAuroraConfig' object has no attribute 'env'{noformat}",null,3,1,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,1,0,0,0,0,0,0,0
AURORA-883,Task,46,Resolved,Create a utility that provides early CI feedback on code reviews,We can keep our build green and make life easier for committers and reviewers alike by giving review-time feedback on unit test results.  This will make it more difficult for changes to sneak in that didn't run all the tests or code quality checks.,null,2,1,1,0,Bill Farner,Bill Farner,Bill Farner,3,0,0,0,0,0,0,0
AURORA-782,Story,46,Resolved,Remove command bridging from client,The v2 client will resolve v1 commands.  Remove this to stop supporting old command syntax.,null,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,1,2,1,1,0,0,0
AURORA-925,Task,52,Resolved,refactor build.gradle to extract thrift compilation as a separate task class,null,null,3,3,1,0,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-798,Bug,52,Resolved,investigate flaky test: LockManagerImplTest/testNoDeadlock,A test caused CI to fail on an unrelated Python change:See https://builds.apache.org/job/Aurora/618/testReport/junit/org.apache.aurora.scheduler.state/LockManagerImplTest/testNoDeadlock/{noformat}java.lang.RuntimeException: java.lang.AssertionError:   Expectation failure on verify:    Mutable.fetchLock(<LockKey job:JobKey(role:jim environment:devel name:myJob)>): expected: 2 actual: 1Stacktracejava.lang.RuntimeException: java.lang.AssertionError:   Expectation failure on verify:    Mutable.fetchLock(<LockKey job:JobKey(role:jim environment:devel name:myJob)>): expected: 2 actual: 1at com.google.common.testing.ClusterException.create(ClusterException.java:116)at com.google.common.testing.TearDownStack.runTearDown(TearDownStack.java:69)at com.google.common.testing.junit4.TearDownTestCase.tearDown(TearDownTestCase.java:113)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)at org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:168)at org.junit.rules.RunRules.evaluate(RunRules.java:20)at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)at org.junit.runners.ParentRunner.run(ParentRunner.java:309)at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:69)at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:48)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:105)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:355)at org.gradle.internal.concurrent.DefaultExecutorFactory$StoppableExecutorImpl$1.run(DefaultExecutorFactory.java:64)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:724)Caused by: java.lang.AssertionError:   Expectation failure on verify:    Mutable.fetchLock(<LockKey job:JobKey(role:jim environment:devel name:myJob)>): expected: 2 actual: 1at org.easymock.internal.MocksControl.verify(MocksControl.java:226)at com.twitter.common.testing.easymock.EasyMockTest$1.tearDown(EasyMockTest.java:54)at com.google.common.testing.TearDownStack.runTearDown(TearDownStack.java:58)... 45 moreStandard ErrorOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waiting{noformat},null,3,2,1,0,Maxim Khutornenko,Kevin Sweeney,Kevin Sweeney,2,0,0,0,0,0,0,0
AURORA-891,Task,52,Resolved,Drop argparse dependency,Now that we're on Python 2.7 we don't need to depend on argparse anymore - it's part of the standard library.,null,4,2,1,0,Joshua Cohen,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-914,Task,52,Resolved,Instrument task scheduling pipeline,"We need a better instrumentation of the task scheduling loop to helps us troubleshoot scheduling performance problems. Specifically:- Add {{@Timed}} in TaskScheduler.schedule() (inside the write lock)- Add {{@Timed}} in OfferQueue.launchFirst()- Add {{@Timed}} for every iteration of the OfferQueue.launchFirst() loop- Differentiate between ""static"" (e.g.: resource shortage) vs. ""dynamic"" (e.g.: constraint mismatch) Vetos and add a counter to track each Veto type.",null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,1,0,0,0,0,0
AURORA-923,Bug,52,Resolved,Run verb does not return an exit code.,The run verb of the task noun does not return an exit code. This results in log messages like:{noformat}log(info): Command terminated with error code None{noformat},null,3,1,1,0,Zameer Manji,Zameer Manji,Zameer Manji,1,0,0,0,0,0,0,0
AURORA-882,Bug,52,Resolved,CI broken due to UpdaterTest::test_update_instances_wait_for_batch_completion_filled_batch,See https://builds.apache.org/job/Aurora/676/console,null,1,2,1,0,null,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-912,Bug,52,Resolved,Scheduler cannot read PruneJobUpdateHistory log operations,AURORA-743 added support for reading PruneJobUpdateHistory log operations but no support exists for reading them.  At this time the default behavior of the scheduler is to fail when encountering unknown log operation types.https://reviews.apache.org/r/27538/ was added as a short-term fix for this but it's apparent that job update history pruning support is incomplete without the ability to read these operations.,null,1,2,1,0,Maxim Khutornenko,Bill Farner,Bill Farner,1,0,2,1,1,0,0,0
AURORA-889,Bug,52,Resolved,aurora2 beta-update list is broken,"Subcommand always fails with:{noformat}$ aurora2 beta-update list devclusterFatal error running command; traceback can be found in /home/vagrant/.aurora/errors/aurora-1414084327.error-logvagrant@192:~$ cat /home/vagrant/.aurora/errors/aurora-1414084327.error-logERROR LOG: command arguments = ['beta-update' 'list' 'devcluster']Traceback (most recent call last):  File ""/usr/local/bin/aurora2/apache/aurora/client/cli/__init__.py"" line 406 in _execute    result = noun.execute(context)  File ""/usr/local/bin/aurora2/apache/aurora/client/cli/__init__.py"" line 515 in execute    return self.verbs[context.options.verb].execute(context)  File ""/usr/local/bin/aurora2/apache/aurora/client/cli/update.py"" line 182 in execute    update_statuses=context.options.status)TypeError: query_job_updates() got an unexpected keyword argument 'jobKey'{noformat}",null,1,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-793,Bug,52,Resolved,Client prints redundant messages,The client has a tendency to print the same message multiple times:Job configuration does not exist:{noformat}$ aurora2 job create -v devcluster/www-data/devel/not_here /vagrant/hello_world.auroralog(info): Error executing command: Error loading configuration: [Errno 2] No such file or directory: '/vagrant/hello_world.aurora'log(info): Error executing command: Error loading configuration: [Errno 2] No such file or directory: '/vagrant/hello_world.aurora'Error executing command: Error loading configuration: [Errno 2] No such file or directory: '/vagrant/hello_world.aurora'{noformat}Job already exists:{noformat}$ aurora2 job create -v devcluster/www-data/devel/hello_world /vagrant/hello_world.auroralog(info): Creating job hello_worldlog(info): Creating job hello_worldlog(info): Starting new HTTP connection (1): vagrant-ubuntu-trusty-64log(info): Starting new HTTP connection (1): vagrant-ubuntu-trusty-64log(info): Starting new HTTP connection (1): vagrant-ubuntu-trusty-64log(info): Starting new HTTP connection (1): vagrant-ubuntu-trusty-64log(info): Message from scheduler: Job already exists: www-data/devel/hello_worldlog(info): Message from scheduler: Job already exists: www-data/devel/hello_worldjob create failed because job not foundlog(info): Error executing command: Job not foundlog(info): Error executing command: Job not foundError executing command: Job not found{noformat}Referenced job name does not exist:{noformat}$ aurora2 job create -v devcluster/www-data/devel/not_here /vagrant/hello_world.auroralog(info): Error executing command: Error loading configuration: Could not find job devcluster/www-data/devel/not_hereCandidates are:  devcluster/www-data/devel/hello_worldlog(info): Error executing command: Error loading configuration: Could not find job devcluster/www-data/devel/not_hereCandidates are:  devcluster/www-data/devel/hello_worldError executing command: Error loading configuration: Could not find job devcluster/www-data/devel/not_hereCandidates are:  devcluster/www-data/devel/hello_world{noformat}Python error in job configuration:{noformat}$ aurora2 job create -v devcluster/www-data/devel/not_here /vagrant/hello_world.auroralog(info): Error executing command: Error loading configuration: [Errno 2] No such file or directory: '/vagrant/hello_world.py'log(info): Error executing command: Error loading configuration: [Errno 2] No such file or directory: '/vagrant/hello_world.py'Error executing command: Error loading configuration: [Errno 2] No such file or directory: '/vagrant/hello_world.py'{noformat},null,1,2,1,0,Zameer Manji,Bill Farner,Bill Farner,2,0,3,1,1,0,0,0
AURORA-248,Bug,52,Resolved,Use Mock with specs in client tests,While investigating AURORA-247 figured out that none of our tests is capable of catching unknown options due to spec-less way options are mocked. Use Mock(spec=['option1' 'option2' ...]) instead of Mock() everywhere in client tests to prevent issues like AURORA-247. ,null,2,4,1,0,David McLaughlin,Maxim Khutornenko,Maxim Khutornenko,4,0,0,0,0,0,0,0
AURORA-72,Story,52,Resolved,Improve root README.md,README.md is the first thing many prospective contributors will see when viewing the source code as well as the first thing many users will automatically jump to. Update it to be more helpful possibly merge with docs/README.md,null,3,2,1,0,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-825,Task,52,Resolved,Cron tasks don't check quota when launched,We don't check production quota when a cron task is launched by the CronJobManager. This leaves a potential to temporarily exceed allocated quota if prod consumption grew close to the limit _after_ a cron job was created. ,null,3,3,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,13,0,1,0,0,0,0,0
AURORA-886,Task,52,Resolved,aurora job create --wait-until should exit with error code if the job being waited on fails,If I invoke:aurora job create --wait-until=FINISHED ...and the job being waited on fails I think the aurora command should exit with an error code or should at least have the option to print something formatted that can be parsed.I'm not sure what the current thinking on exit codes is I would understand the argument that even if the job failed the aurora client did it's job without error. So I'd be happy with any way of detecting job failure (exit code or otherwise).,null,3,1,1,0,Mark Chu-Carroll,Mark Chu-Carroll,Mark Chu-Carroll,1,0,0,0,0,0,0,0
AURORA-865,Bug,52,Resolved,IOError on aurora job status,"{noformat}[jsmith@atla-bgy-37-sr2 ~]$ cat /var/lib/jenkins/.aurora/errors/None-1413508980.error-logERROR LOG: command arguments = ['job' 'status' 'atla/jenkins/test/flask_example']Traceback (most recent call last):  File ""dist/aurora2.pex/.deps/apache.aurora.clientv2-0.5.1_DEV1413507664-py2.7.egg/apache/aurora/client/cli/__init__.py"" line 406 in _execute    result = noun.execute(context)  File ""dist/aurora2.pex/.deps/apache.aurora.clientv2-0.5.1_DEV1413507664-py2.7.egg/apache/aurora/client/cli/__init__.py"" line 515 in execute    return self.verbs[context.options.verb].execute(context)  File ""dist/aurora2.pex/.deps/apache.aurora.clientv2-0.5.1_DEV1413507664-py2.7.egg/apache/aurora/client/cli/jobs.py"" line 637 in execute    context.print_out(result)  File ""dist/aurora2.pex/.deps/apache.aurora.clientv2-0.5.1_DEV1413507664-py2.7.egg/apache/aurora/client/cli/__init__.py"" line 145 in print_out    print(""%s%s"" % (indent_str line))IOError: [Errno 32] Broken pipe{noformat}",null,3,2,1,0,David McLaughlin,Joe Smith,Joe Smith,1,0,0,0,0,0,0,0
AURORA-859,Bug,52,Resolved,"""No tasks to kill"" message is not surfaced to user in v2",{noformat}vagrant@vagrant-ubuntu-trusty-64:~$ aurora2 job status devcluster/www-data/test/cron_hello_worldlog(info): Checking status of devcluster/www-data/test/cron_hello_worldlog(info): Starting new HTTP connection (1): vagrant-ubuntu-trusty-64log(info): Starting new HTTP connection (1): vagrant-ubuntu-trusty-64Active tasks (0):Inactive tasks (7):Task:  cpus: 0.1 ram: 128 MB disk: 128 MB  events:   2014-10-16 20:20:00 PENDING: None   2014-10-16 20:20:00 ASSIGNED: None   2014-10-16 20:20:01 STARTING: Initializing sandbox.   2014-10-16 20:20:02 RUNNING: None   2014-10-16 20:20:03 FINISHED: Task finished.Task:  cpus: 0.1 ram: 128 MB disk: 128 MB  events:   2014-10-16 20:50:00 PENDING: None   2014-10-16 20:50:00 ASSIGNED: None   2014-10-16 20:50:01 STARTING: Initializing sandbox.   2014-10-16 20:50:01 RUNNING: None   2014-10-16 20:50:02 FINISHED: Task finished.Task:  cpus: 0.1 ram: 128 MB disk: 128 MB  events:   2014-10-16 20:40:00 PENDING: None   2014-10-16 20:40:00 ASSIGNED: None   2014-10-16 20:40:00 STARTING: Initializing sandbox.   2014-10-16 20:40:01 RUNNING: None   2014-10-16 20:40:02 FINISHED: Task finished.Task:  cpus: 0.1 ram: 128 MB disk: 128 MB  events:   2014-10-16 20:25:00 PENDING: None   2014-10-16 20:25:00 ASSIGNED: None   2014-10-16 20:25:00 STARTING: Initializing sandbox.   2014-10-16 20:25:01 RUNNING: None   2014-10-16 20:25:02 FINISHED: Task finished.Task:  cpus: 0.1 ram: 128 MB disk: 128 MB  events:   2014-10-16 20:30:00 PENDING: None   2014-10-16 20:30:00 ASSIGNED: None   2014-10-16 20:30:01 STARTING: Initializing sandbox.   2014-10-16 20:30:01 RUNNING: None   2014-10-16 20:30:02 FINISHED: Task finished.Task:  cpus: 0.1 ram: 128 MB disk: 128 MB  events:   2014-10-16 20:35:00 PENDING: None   2014-10-16 20:35:00 ASSIGNED: None   2014-10-16 20:35:01 STARTING: Initializing sandbox.   2014-10-16 20:35:01 RUNNING: None   2014-10-16 20:35:03 FINISHED: Task finished.Task:  cpus: 0.1 ram: 128 MB disk: 128 MB  events:   2014-10-16 20:45:00 PENDING: None   2014-10-16 20:45:00 ASSIGNED: None   2014-10-16 20:45:01 STARTING: Initializing sandbox.   2014-10-16 20:45:01 RUNNING: None   2014-10-16 20:45:02 FINISHED: Task finished.log(info): Command terminated successfullyvagrant@vagrant-ubuntu-trusty-64:~$ aurora2 job killall devcluster/www-data/test/cron_hello_worldlog(info): Checking status of devcluster/www-data/test/cron_hello_worldlog(info): Starting new HTTP connection (1): vagrant-ubuntu-trusty-64log(info): Starting new HTTP connection (1): vagrant-ubuntu-trusty-64log(info): Killing tasks for job: devcluster/www-data/test/cron_hello_worldlog(info): Instances to be killed: [0]log(info): Starting new HTTP connection (1): vagrant-ubuntu-trusty-64log(info): Message from scheduler: No tasks to kill.log(info): Starting new HTTP connection (1): vagrant-ubuntu-trusty-64Successfully killed shards [0]job killall succeededlog(info): Command terminated successfullyvagrant@vagrant-ubuntu-trusty-64:~$ echo $?0{noformat},null,3,2,1,0,Bill Farner,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-854,Story,52,Resolved,v2 help for cron shows that deschedule takes a --bind-var option but deschedule does not accept a config file,We should remove this option,null,3,2,1,0,Zameer Manji,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-805,Bug,52,Resolved,cannot set verbosity from 'aurora job create',{noformat}mba=science=; aurora job create -v devcluster/wickman/test/hadoop-tst-job sandbox/users/wickman/hadoop/hadoop_tst_worker.aurora usage: aurora-client [-h]                     {taskdeployquotacronjobconfigslabeta-update} ...aurora-client: error: unrecognized arguments: -vmba=science=; aurora job -v create devcluster/wickman/test/hadoop-tst-job sandbox/users/wickman/hadoop/hadoop_tst_worker.aurora usage: aurora-client [-h]                     {taskdeployquotacronjobconfigslabeta-update} ...aurora-client: error: unrecognized arguments: -vmba=science=; aurora -v job create devcluster/wickman/test/hadoop-tst-job sandbox/users/wickman/hadoop/hadoop_tst_worker.aurora DEBUG] Enabling SOCKS monkey patch for module ftplib (<module 'ftplib' from '/Users/wickman/Python/CPython-2.7.6/lib/python2.7/ftplib.pyc'>)DEBUG] Enabling SOCKS monkey patch for module httplib (<module 'httplib' from '/Users/wickman/Python/CPython-2.7.6/lib/python2.7/httplib.pyc'>)DEBUG] Enabling SOCKS monkey patch for module twitter.packer.lib.packer_client (<module 'twitter.packer.lib.packer_client' from '/Users/wickman/.tools-cache/home/mesos/tools/client/libexec/aurora-client/twitter/packer/lib/packer_client.pyc'>)DEBUG] Enabling SOCKS monkey patch for module requests.packages.urllib3.connection (<module 'requests.packages.urllib3.connection' from '/Users/wickman/.tools-cache/home/mesos/tools/client/libexec/aurora-client/.deps/requests-2.3.0-py2.7.egg/requests/packages/urllib3/connection.pyc'>)DEBUG] Enabling SOCKS monkey patch for module twitter.common.rpc.transports.tsslsocket (<module 'twitter.common.rpc.transports.tsslsocket' from '/Users/wickman/.tools-cache/home/mesos/tools/client/libexec/aurora-client/.deps/twitter.common.rpc-0.3.0-py2.7.egg/twitter/common/rpc/transports/tsslsocket.pyc'>)DEBUG] Enabling SOCKS monkey patch for module urllib2 (<module 'urllib2' from '/Users/wickman/Python/CPython-2.7.6/lib/python2.7/urllib2.pyc'>)DEBUG] Enabling SOCKS monkey patch for module telnetlib (<module 'telnetlib' from '/Users/wickman/Python/CPython-2.7.6/lib/python2.7/telnetlib.pyc'>)DEBUG] Enabling SOCKS monkey patch for module thrift.transport.TSocket (<module 'thrift.transport.TSocket' from '/Users/wickman/.tools-cache/home/mesos/tools/client/libexec/aurora-client/.deps/thrift-0.9.1-py2.7-macosx-10.4-x86_64.egg/thrift/transport/TSocket.pyc'>)DEBUG] Enabling SOCKS monkey patch for module kazoo.handlers.threading (<module 'kazoo.handlers.threading' from '/Users/wickman/.tools-cache/home/mesos/tools/client/libexec/aurora-client/.deps/kazoo-1.3.1-py2.7.egg/kazoo/handlers/threading.pyc'>)Must supply one of the following commands: cancel_update create deployment diff get_quota help inspect kill killall list_jobs open package_add_version package_copy_version package_delete_version package_fetch package_get_version package_list package_quota_usage package_request_token package_set_live package_unlock package_unset_live package_versions restart role_list run runtask ssh start_cron status update versionmba=science=; mba=science=; mba=science=; mba=science=; mba=science=; aurora job create --logging-level=10 devcluster/wickman/test/hadoop-tst-job sandbox/users/wickman/hadoop/hadoop_tst_worker.aurora usage: aurora-client [-h]                     {taskdeployquotacronjobconfigslabeta-update} ...aurora-client: error: unrecognized arguments: --logging-level=10mba=science=; aurora job --logging-level=10 create devcluster/wickman/test/hadoop-tst-job sandbox/users/wickman/hadoop/hadoop_tst_worker.aurora usage: aurora-client [-h]                     {taskdeployquotacronjobconfigslabeta-update} ...aurora-client: error: unrecognized arguments: --logging-level=10mba=science=; aurora --logging-level=10 job create devcluster/wickman/test/hadoop-tst-job sandbox/users/wickman/hadoop/hadoop_tst_worker.aurora Usage: aurora client used to interact with the aurora scheduler.For questions contact aurora-team@twitter.com.Available commands:    cancel_update    create    deployment    diff    get_quota    help    inspect    kill    killall    list_jobs    open    package_add_version    package_copy_version    package_delete_version    package_fetch    package_get_version    package_list    package_quota_usage    package_request_token    package_set_live    package_unlock    package_unset_live    package_versions    restart    role_list    run    runtask    ssh    start_cron    status    update    versionFor more help on an individual command:    aurora help <command>aurora-client: error: no such option: --logging-levelmba=science=; {noformat},null,3,2,1,0,David McLaughlin,Brian Wickman,Brian Wickman,1,0,1,0,0,0,0,0
AURORA-857,Story,52,Resolved,aurora cron schedule should ouput url,The client should output the URL of the newly-created cron job as it did in v1,null,3,2,1,0,Zameer Manji,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-456,Story,52,Resolved,"""aurora version"" command raises KeyError: 'sha'","{noformat}    $ ./pants src/main/python/apache/aurora/client/bin/:aurora_client    Build operating on targets: OrderedSet([PythonBinary(src/main/python/apache/aurora/client/bin/BUILD:aurora_client)])    Building PythonBinary PythonBinary(src/main/python/apache/aurora/client/bin/BUILD:aurora_client):    Wrote /home/jaybuff/incubator-aurora/dist/aurora_client.pex    $ /home/jaybuff/incubator-aurora/dist/aurora_client.pex  version    Aurora client build info:    Traceback (most recent call last):      File ""/home/jaybuff/.pex/install/twitter.common.app-0.3.0-py26-none-any.whl.18b046f79e32f1c14a751fbd19fe7ac97546fb80/twitter.common.app-0.3.0-py26-none-any.whl/twitter/common/app/application.py"" line 738 in _wrap_method        return_code = method()      File ""/home/jaybuff/.pex/install/twitter.common.app-0.3.0-py26-none-any.whl.18b046f79e32f1c14a751fbd19fe7ac97546fb80/twitter.common.app-0.3.0-py26-none-any.whl/twitter/common/app/application.py"" line 760 in <lambda>        main = lambda: main_method(*args **kwargs)      File ""/home/jaybuff/incubator-aurora/dist/aurora_client.pex/apache/aurora/client/commands/core.py"" line 117 in version        print(""\tsha: %s"" % pex_info.build_properties['sha'])    KeyError: 'sha'{noformat}",null,3,4,1,0,Zameer Manji,Jay Buffington,Jay Buffington,1,1,1,0,0,0,0,0
AURORA-784,Bug,52,Resolved,"Client reports ""update has started"" for no-op update",When initiating a scheduler-driven update that is actually a no-op the client will print {noformat}Scheduler-driven update of job devcluster/www-data/devel/hello_world has started.{noformat}In this case the scheduler is returning a message indicating the no-op:{noformat}Job is unchanged by proposed update.{noformat},null,3,2,1,0,Maxim Khutornenko,Bill Farner,Bill Farner,3,0,1,1,1,0,0,0
AURORA-896,Task,52,Resolved,Remove client stack trace redirection,The Aurora Client currently redirects unhandled exceptions to a log file within the user's homedir. [Mailing List discussion|http://mail-archives.apache.org/mod_mbox/incubator-aurora-dev/201410.mbox/%3CCAFGkSCm%2B5jJZPXmEm1%3DWNz2tSh8Ld%2BEiO2KYE6Yco%3DpB_chekQ%40mail.gmail.com%3E]In practice this has led to a bit of confusion and the level of patching required to make this work seems to be rather high- yet still does not cover all the corner cases. When [attempting to test this|https://reviews.apache.org/r/26802/] I realized it'd be best to discard that review and instead remove this feature while we reconsider the approach in a way that won't interfere with our testing of the client or presenting helpful information to users.,null,3,2,1,0,Zameer Manji,Joe Smith,Joe Smith,1,0,1,0,0,0,0,0
AURORA-913,Story,52,Resolved,Replace MaintenanceMode field with HostAttributes in HostOffer,Address this TODO:{noformat}  /**   * Encapsulate an offer from a host and the host's maintenance mode.   */  class HostOffer {    private final Offer offer;    // TODO(wfarner): Replace this with HostAttributes for more use of this caching.    private final MaintenanceMode mode;{noformat}Success here will mean avoiding O(n) (n=num offers) fetching of host attributes associated with offers when scheduling a task.,null,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,3,0,0,0,0,0,0,0
AURORA-831,Bug,52,Resolved,cron deschedule help includes ambiguous options,"Highlights include: two instances of ""str"" as options random mention of aurora_cluster_config and PROXY_ADDR even though they're not listed anywhere in the help?{noformat}aurora help cron descheduleUsage for verb ""cron deschedule"":  deschedule [--bind=var=value] CLUSTER/ROLE/ENV/NAMEOptions:  var=value  Bind a pystachio variable name to a value. Multiple flags may be used to specify multiple values.  CLUSTER/ROLE/ENV/NAME  Fully specified job key in CLUSTER/ROLE/ENV/NAME format  aurora_cluster_config  Cluster config file  --no-no_socks_always_proxy  Always create a proxy if no proxies are supplied.  Proxies via --tunnel_host.  PROXY_ADDR  Attempt to proxy all connections through the socks proxy at PROXY_ADDR  --socks_resolve=['local' 'remote']  LOCATION to perform DNS resolution where LOCATION is one of ['local' 'remote']  str  Host to tunnel commands through (default: nest1.twitter.biz)  str  The jenkins URL to fetch jenkins artifacts (default=http://jvm-ci.twitter.biz).Remove the cron schedule for a job.{noformat}",null,4,2,1,0,null,Joshua Cohen,Joshua Cohen,1,0,0,0,0,0,0,0
AURORA-476,Story,52,Resolved,Run vagrant-based tests regularly,Our end-to-end tests offer a decent amount of integration test coverage and sometimes manage to catch issues that our unit test suites otherwise do not.  It would be awesome to run these in Jenkins perhaps on AWS.,null,3,2,1,0,null,Bill Farner,Bill Farner,0,0,1,0,0,0,0,0
AURORA-794,Bug,52,Resolved,"Client erroneously prints ""Job not found"" when job exists","In this case i'm trying to create a job that already exists.  The 'message from scheduler' lines have the correct error but the client goes on to claim ""Job not found"".  I'm not sure if there is really a good string for the client to make up in this case as the scheduler will have the real reason the request failed.{noformat}$ aurora2 job create -v devcluster/www-data/devel/hello_world /vagrant/hello_world.auroralog(info): Creating job hello_worldlog(info): Creating job hello_worldlog(info): Starting new HTTP connection (1): vagrant-ubuntu-trusty-64log(info): Starting new HTTP connection (1): vagrant-ubuntu-trusty-64log(info): Starting new HTTP connection (1): vagrant-ubuntu-trusty-64log(info): Starting new HTTP connection (1): vagrant-ubuntu-trusty-64log(info): Message from scheduler: Job already exists: www-data/devel/hello_worldlog(info): Message from scheduler: Job already exists: www-data/devel/hello_worldjob create failed because job not foundlog(info): Error executing command: Job not foundlog(info): Error executing command: Job not foundError executing command: Job not found{noformat}",null,3,2,1,0,Zameer Manji,Bill Farner,Bill Farner,1,0,2,1,1,0,0,0
AURORA-766,Task,52,Resolved,Client should show information for update details when starting an update.,When you launch a new async-update we should show:1) the URL to the scheduler UI for tracking progress of your update.2) the command you need to run to get the state from the CLI,null,3,1,1,0,David McLaughlin,David McLaughlin,David McLaughlin,1,0,0,0,0,0,0,0
AURORA-917,Bug,52,Resolved,"""aurora job create"" gives misleading error when used to create a cron job","When attempting to create a cron job via ""aurora job create"" the client errors out with a vague error code but the job is still created:{noformat}vagrant@192:~$ aurora2 job create devcluster/vagrant/test/cron_hello_world4 aurora/examples/jobs/cron_hello_world.auroralog(info): Creating job cron_hello_world4log(info): Checking status of devcluster/vagrant/test/cron_hello_world4Error occurred while creating job devcluster/vagrant/test/cron_hello_world4log(info): Command terminated with error code 4{noformat}The V2 job create syntax should fail fast when attempted with a cron job.",null,2,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-920,Bug,52,Resolved,Deadlock during scheduler startup,{noformat}'Lifecycle-0' Id=270 BLOCKEDWaiting for lock: org.apache.aurora.scheduler.storage.log.LogStorage$$EnhancerByGuice$$702c4587@6fca188cLock is currently held by thread: AsyncProcessor-0Wait time: 676461 ms.    org.apache.aurora.scheduler.storage.log.LogStorage.write(LogStorage.java:558)    org.apache.aurora.scheduler.storage.CallOrderEnforcingStorage.write(CallOrderEnforcingStorage.java:130)    org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.instanceChanged(JobUpdateControllerImpl.java:235)    org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.instanceDeleted(JobUpdateControllerImpl.java:231)    org.apache.aurora.scheduler.updater.JobUpdateEventSubscriber.tasksDeleted(JobUpdateEventSubscriber.java:68)    sun.reflect.GeneratedMethodAccessor94.invoke(Unknown Source)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    com.google.common.eventbus.EventSubscriber.handleEvent(EventSubscriber.java:74)    com.google.common.eventbus.SynchronizedEventSubscriber.handleEvent(SynchronizedEventSubscriber.java:47)    com.google.common.eventbus.EventBus.dispatch(EventBus.java:322)    com.google.common.eventbus.EventBus.dispatchQueuedEvents(EventBus.java:304)    com.google.common.eventbus.EventBus.post(EventBus.java:275)    org.apache.aurora.scheduler.events.PubsubEventModule$2.post(PubsubEventModule.java:68)    org.apache.aurora.scheduler.SchedulerLifecycle$7$2.run(SchedulerLifecycle.java:352)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)    java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)    java.lang.Thread.run(Thread.java:745)'AsyncProcessor-0' Id=269 BLOCKEDWaiting for lock: com.google.common.eventbus.SynchronizedEventSubscriber@5a8d3038Lock is currently held by thread: Lifecycle-0Wait time: 676615 ms.    com.google.common.eventbus.SynchronizedEventSubscriber.handleEvent(SynchronizedEventSubscriber.java:46)    com.google.common.eventbus.EventBus.dispatch(EventBus.java:322)    com.google.common.eventbus.EventBus.dispatchQueuedEvents(EventBus.java:304)    com.google.common.eventbus.EventBus.post(EventBus.java:275)    org.apache.aurora.scheduler.events.PubsubEventModule$2.post(PubsubEventModule.java:68)    org.apache.aurora.scheduler.state.StateManagerImpl.updateTaskAndExternalState(StateManagerImpl.java:442)    org.apache.aurora.scheduler.state.StateManagerImpl.access$100(StateManagerImpl.java:79)    org.apache.aurora.scheduler.state.StateManagerImpl$8.execute(StateManagerImpl.java:459)    org.apache.aurora.scheduler.storage.Storage$MutateWork$NoResult.apply(Storage.java:132)    org.apache.aurora.scheduler.storage.Storage$MutateWork$NoResult$Quiet.apply(Storage.java:149)    org.apache.aurora.scheduler.storage.log.LogStorage$7.apply(LogStorage.java:573)    org.apache.aurora.scheduler.storage.log.LogStorage$7.apply(LogStorage.java:570)    org.apache.aurora.scheduler.storage.mem.MemStorage.doWork(MemStorage.java:200)    org.apache.aurora.scheduler.storage.mem.MemStorage.access$400(MemStorage.java:61)    org.apache.aurora.scheduler.storage.mem.MemStorage$5.apply(MemStorage.java:225)    org.apache.aurora.scheduler.storage.mem.MemStorage$5.apply(MemStorage.java:222)    org.apache.aurora.scheduler.storage.db.DbStorage.write(DbStorage.java:150)    org.apache.aurora.scheduler.storage.db.DbStorage$$EnhancerByGuice$$4db2f244.CGLIB$write$4(<generated>)    org.apache.aurora.scheduler.storage.db.DbStorage$$EnhancerByGuice$$4db2f244$$FastClassByGuice$$b73a3503.invoke(<generated>)    com.google.inject.internal.cglib.proxy.$MethodProxy.invokeSuper(MethodProxy.java:228)    com.google.inject.internal.InterceptorStackCallback$InterceptedMethodInvocation.proceed(InterceptorStackCallback.java:72)    org.mybatis.guice.transactional.TransactionalMethodInterceptor.invoke(TransactionalMethodInterceptor.java:101)    com.google.inject.internal.InterceptorStackCallback$InterceptedMethodInvocation.proceed(InterceptorStackCallback.java:72)    com.google.inject.internal.InterceptorStackCallback.intercept(InterceptorStackCallback.java:52)    org.apache.aurora.scheduler.storage.db.DbStorage$$EnhancerByGuice$$4db2f244.write(<generated>)    org.apache.aurora.scheduler.storage.mem.MemStorage.write(MemStorage.java:222)    org.apache.aurora.scheduler.storage.log.LogStorage.write(LogStorage.java:570)    org.apache.aurora.scheduler.storage.CallOrderEnforcingStorage.write(CallOrderEnforcingStorage.java:130)    org.apache.aurora.scheduler.state.StateManagerImpl.deleteTasks(StateManagerImpl.java:450)    org.apache.aurora.scheduler.async.TaskHistoryPruner.deleteTasks(TaskHistoryPruner.java:126)    org.apache.aurora.scheduler.async.TaskHistoryPruner.access$500(TaskHistoryPruner.java:51)    org.apache.aurora.scheduler.async.TaskHistoryPruner$3.run(TaskHistoryPruner.java:164)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)    java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)    java.lang.Thread.run(Thread.java:745){noformat},null,1,3,1,0,Kevin Sweeney,Bill Farner,Bill Farner,2,0,1,1,1,0,0,0
AURORA-926,Bug,52,Resolved,Scheduler crashes due to JVM running out of memory on start,This is related to the recent changes in AURORA-920. When scheduler starts it goes through all tasks in the log and generates a multitude of events (e.g. TaskStateChange.initialized(task)). For the new AsyncEventBus we use a Executors.newCachedThreadPool() which does not have an upper bound on how many threads it can create when needed (well technically it's bounded by Integer.MAX_VALUE). That leads to an out of control thread creation and eventual out of memory JVM crash.Use ThreadPoolExecutor with a bounded {{maximumPoolSize}} to control the memory consumption. The AsyncEventBus uses a simple ConcurrentLinkedQueue to enqueue events so there is no risk in timing out due to slower event processing.,null,1,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-903,Story,52,Resolved,Allow the announcer to use ZooKeeper authentication,This is required to allow the announcer to talk to zookeeper clusters requiring authentication,null,3,3,0,0,null,Kevin Sweeney,Kevin Sweeney,1,0,1,0,0,0,0,0
AURORA-925,Task,53,Resolved,refactor build.gradle to extract thrift compilation as a separate task class,null,null,3,3,1,0,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-930,Story,53,Resolved,GC performance issues with snapshot deduplication on large clusters,We observed very long GC pauses in our production cluster we believe are caused by the extra heap pressure caused by SnapshotDeduplicatorImpl's extra deep copy of a Snapshot object.Also EntrySerializer fully buffers the full binary-encoded thrift Snapshot before writing it to the replicated log - it can avoid memory pressure by streaming instead.,null,3,3,1,0,Kevin Sweeney,Chris Lambert,Chris Lambert,4,0,2,0,0,0,0,0
AURORA-939,Bug,53,Resolved,Executor crashes when it receives an invalid task config,"Stacktrace:{noformat}Uncaught exception:Traceback (most recent call last):  File ""/root/.pex/install/twitter.common.exceptions-0.3.0-py2.7.egg.cf67f7016992e92b38deaf83dac4bb90d8677050/twitter.common.exceptions-0.3.0-py2.7.egg/twitter/common/exceptions/__init__.py"" line 126 in _excepting_run    self.__real_run(*args **kw)  File ""/root/.pex/install/twitter.common.concurrent-0.3.0-py2.7.egg.1f2389f41eaa34088db63ee54687f5429b09403c/twitter.common.concurrent-0.3.0-py2.7.egg/twitter/common/concurrent/deferred.py"" line 43 in run    self._closure()  File ""/root/.pex/install/apache.aurora.executor-0.6.1_DEV1415152524-py2.7.egg.eeaf32f22c2835b79901cfa268aed2775d327177/apache.aurora.executor-0.6.1_DEV1415152524-py2.7.egg/apache/aurora/executor/aurora_executor.py"" line 262 in     defer(lambda: self._run(driver assigned_task))  File ""/root/.pex/install/apache.aurora.executor-0.6.1_DEV1415152524-py2.7.egg.eeaf32f22c2835b79901cfa268aed2775d327177/apache.aurora.executor-0.6.1_DEV1415152524-py2.7.egg/apache/aurora/executor/aurora_executor.py"" line 100 in _run    if not self._initialize_sandbox(driver assigned_task):  File ""/root/.pex/install/apache.aurora.executor-0.6.1_DEV1415152524-py2.7.egg.eeaf32f22c2835b79901cfa268aed2775d327177/apache.aurora.executor-0.6.1_DEV1415152524-py2.7.egg/apache/aurora/executor/aurora_executor.py"" line 128 in _initialize_sandbox    self._sandbox = self._sandbox_provider.from_assigned_task(assigned_task)  File ""/var/lib/mesos/slaves/20141110-182528-1715086346-5050-57898-529/frameworks/201104070004-0000002563-0000/executors/thermos-1416416412289-mst-devel-xfactor-model-3-ba927208-f5a4-4dd1-9d6c-82bdd742a524/runs/0985cabb-5cb8-4ef0-8920-ba3c151ceb2b/thermos_executor/twitter/aurora/executor/bin_internal/thermos_executor_main.py"" line 36 in from_assigned_task  File ""/root/.pex/install/apache.aurora.executor-0.6.1_DEV1415152524-py2.7.egg.eeaf32f22c2835b79901cfa268aed2775d327177/apache.aurora.executor-0.6.1_DEV1415152524-py2.7.egg/apache/aurora/executor/common/task_info.py"" line 88 in mesos_task_instance_from_assigned_task    raise ValueError('Unexpected unbound refs: %s' % ' '.join(map(str refs)))ValueError: Unexpected unbound refs: {{dateRanges[3][1]}} {{thermos.ports[http]}} {{dateRanges[3][0]}}{noformat}This should instead cause a TASK_FAILED with a helpful version of this message.",null,3,2,1,0,Zameer Manji,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-949,Bug,53,Resolved,TRequestsTransport does not raise an exception on 5xx or 4xx responses,The TRequestsTransport used by the client silently accepts 5xx responses. Instead it should raise an exception so the request can be retried and the response body can be discarded since it may not be valid JSON.,null,4,1,1,0,Zameer Manji,Zameer Manji,Zameer Manji,1,0,0,0,0,0,0,0
AURORA-798,Bug,53,Resolved,investigate flaky test: LockManagerImplTest/testNoDeadlock,A test caused CI to fail on an unrelated Python change:See https://builds.apache.org/job/Aurora/618/testReport/junit/org.apache.aurora.scheduler.state/LockManagerImplTest/testNoDeadlock/{noformat}java.lang.RuntimeException: java.lang.AssertionError:   Expectation failure on verify:    Mutable.fetchLock(<LockKey job:JobKey(role:jim environment:devel name:myJob)>): expected: 2 actual: 1Stacktracejava.lang.RuntimeException: java.lang.AssertionError:   Expectation failure on verify:    Mutable.fetchLock(<LockKey job:JobKey(role:jim environment:devel name:myJob)>): expected: 2 actual: 1at com.google.common.testing.ClusterException.create(ClusterException.java:116)at com.google.common.testing.TearDownStack.runTearDown(TearDownStack.java:69)at com.google.common.testing.junit4.TearDownTestCase.tearDown(TearDownTestCase.java:113)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:47)at org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)at org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:44)at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:33)at org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:168)at org.junit.rules.RunRules.evaluate(RunRules.java:20)at org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:271)at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:70)at org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:50)at org.junit.runners.ParentRunner$3.run(ParentRunner.java:238)at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:63)at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:236)at org.junit.runners.ParentRunner.access$000(ParentRunner.java:53)at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:229)at org.junit.runners.ParentRunner.run(ParentRunner.java:309)at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)at org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:69)at org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:48)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)at org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)at org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)at com.sun.proxy.$Proxy2.processTestClass(Unknown Source)at org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:105)at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)at java.lang.reflect.Method.invoke(Method.java:606)at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)at org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)at org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:355)at org.gradle.internal.concurrent.DefaultExecutorFactory$StoppableExecutorImpl$1.run(DefaultExecutorFactory.java:64)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)at java.lang.Thread.run(Thread.java:724)Caused by: java.lang.AssertionError:   Expectation failure on verify:    Mutable.fetchLock(<LockKey job:JobKey(role:jim environment:devel name:myJob)>): expected: 2 actual: 1at org.easymock.internal.MocksControl.verify(MocksControl.java:226)at com.twitter.common.testing.easymock.EasyMockTest$1.tearDown(EasyMockTest.java:54)at com.google.common.testing.TearDownStack.runTearDown(TearDownStack.java:58)... 45 moreStandard ErrorOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:38 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:39 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:40 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:41 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:42 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waitingOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_jobOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_hostOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_by_idOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key task_queries_allOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key read_lock_wait_nanosOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key write_lock_wait_nanosOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_totalOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_eventsOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_total_per_secOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_events_per_secOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_consistent_read_operation_nanos_per_eventOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_totalOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_eventsOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_total_per_secOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_events_per_secOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key mem_storage_write_operation_nanos_per_eventOct 06 2014 6:27:43 PM com.twitter.common.stats.Stats exportWARNING: Re-using already registered variable for key storage_lock_threads_waiting{noformat},null,3,2,1,0,Maxim Khutornenko,Kevin Sweeney,Kevin Sweeney,2,0,0,0,0,0,0,0
AURORA-891,Task,53,Resolved,Drop argparse dependency,Now that we're on Python 2.7 we don't need to depend on argparse anymore - it's part of the standard library.,null,4,2,1,0,Joshua Cohen,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-914,Task,53,Resolved,Instrument task scheduling pipeline,"We need a better instrumentation of the task scheduling loop to helps us troubleshoot scheduling performance problems. Specifically:- Add {{@Timed}} in TaskScheduler.schedule() (inside the write lock)- Add {{@Timed}} in OfferQueue.launchFirst()- Add {{@Timed}} for every iteration of the OfferQueue.launchFirst() loop- Differentiate between ""static"" (e.g.: resource shortage) vs. ""dynamic"" (e.g.: constraint mismatch) Vetos and add a counter to track each Veto type.",null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,1,0,0,0,0,0
AURORA-946,Bug,53,Resolved,The replaceCronTemplate RPC does not check quota,Apparently the existing {{replaceCronTemplate}} RPC used exclusively by the client updater is not checking quota. This makes the AURORA-825 incomplete until the client updater is deprecated.,null,2,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-936,Bug,53,Resolved,Aurora admin query command is broken,Attempting to use {{admin query}} command results in error:{noformat}apache.aurora.client.api.ThriftInternalError: Error during thrift call getTasksStatus to devcluster: 'NoneType' object has no attribute 'thriftAPIVersion'{noformat}This is due to converting build_query in api.__init__.py to use JobKey instead of arbitrary name/role.,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-923,Bug,53,Resolved,Run verb does not return an exit code.,The run verb of the task noun does not return an exit code. This results in log messages like:{noformat}log(info): Command terminated with error code None{noformat},null,3,1,1,0,Zameer Manji,Zameer Manji,Zameer Manji,1,0,0,0,0,0,0,0
AURORA-928,Task,53,Resolved,Executor overhead cannot be dropped to zero,When executor overhead is set to zero (AURORA-830) Mesos fails resource validation[1]:{noformat}'Executor for task <task_id> uses invalid resources cpus(*):0'{noformat}This could actually be a Mesos rather than Aurora problem as executor CPU is expected to be positive [2].[1] - https://git-wip-us.apache.org/repos/asf?p=mesos.git;a=blob;f=src/common/resources.cpp#l678[2] - https://git-wip-us.apache.org/repos/asf?p=mesos.git;a=blob;f=src/master/master.cpp#l1966,null,3,2,1,0,Zameer Manji,Maxim Khutornenko,Maxim Khutornenko,3,0,0,0,0,0,0,0
AURORA-921,Bug,53,Resolved,"Fail fast for cron jobs in ""aurora beta-update start""","The beta-update start currently relies on a scheduler-driven message which suggests the use of an API that does not have a correspondent client command:{noformat}aurora2 beta-update start  devcluster/vagrant/test/cron_hello_world4 aurora/examples/jobs/cron_hello_world.auroraFailed to start scheduler-driven update due to error:Cron jobs may only be updated by calling replaceCronTemplate.Error executing command: Failed to start scheduler-driven update due to error:{noformat}Need to fail fast the ""aurora beta-update start"" for a cron job config.",null,2,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,3,0,0,0,0,0,0,0
AURORA-924,Task,53,Resolved,Improve cron error messages,"A message like ""No cron template found for..."" could be confusing on the client as it may be misinterpreted as coming from the .aurora config rather than from a server. Standardize all {{CronJobManagerImpl}} messages to use something like ""cron job"" when referring to a non-existent cron template.",null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-938,Bug,53,Resolved,TestVersionCommand::test_version_with_new_pants fails under py.test,"Command run:{noformat}(pycharm.venv)~aurora git aurora/. kts/shallow-copy    % PYTHONPATH=src/main/python py.test src/test/python -vx...___________________________ TestVersionCommand.test_version_with_new_pants ____________________________args = (<client.commands.test_version.TestVersionCommand testMethod=test_version_with_new_pants> <PropertyMock name='build_properties' id='139965496085648'> <MagicMock name='print' id='139964006033616'>)keywargs = {}extra_args = [<PropertyMock name='build_properties' id='139965496085648'> <MagicMock name='print' id='139964006033616'>]entered_patchers = [<mock._patch object at 0x7f4c444bd050> <mock._patch object at 0x7f4c444add50>]exc_info = (<class '_pytest.assertion.reinterpret.AssertionError'> AssertionError(u""assert 2 == 4\n +  where 2 = <MagicMock name='print' id='139964006033616'>.call_count"") <traceback object at 0x7f4c42ccfab8>)patching = <mock._patch object at 0x7f4c444bd050> arg = <MagicMock name='print' id='139964006033616'>>   ???build/bdist.linux-x86_64/egg/mock.py:1201: _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _self = <client.commands.test_version.TestVersionCommand testMethod=test_version_with_new_pants>mock_buildinfo = <PropertyMock name='build_properties' id='139965496085648'>mock_print = <MagicMock name='print' id='139964006033616'>    @patch('__builtin__.print')    @patch('twitter.common.python.pex.PexInfo.build_properties' new_callable=PropertyMock)    def test_version_with_new_pants(self mock_buildinfo mock_print):      # New versions of pants write out revision and datetime      mock_buildinfo.return_value = {'revision': 'bar' 'datetime': 'somedatetime'}      version([])>     assert mock_print.call_count == 4E     AssertionError: assert 2 == 4E      +  where 2 = <MagicMock name='print' id='139964006033616'>.call_countsrc/test/python/apache/aurora/client/commands/test_version.py:42: AssertionError!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!! Interrupted: stopping after 1 failures !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!========================== 1 failed 429 passed 2 warnings in 49.45 seconds =========================={noformat}",null,3,1,1,0,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-909,Story,59,Resolved,Differentiate between dynamic and static vetoes,We're making a decent effort at reducing the _cost_ of task scheduling operations abut have not yet invested in reducing the working set in a way that causes task scheduling to scale better.  Each scheduling attempt for each task is an O(n) operation where n is the number of offers.I would like to explore optimizations where we try to reduce the amount of redundant work performed in task scheduling.  Say for example we're trying to schedule a task that needs 2 CPUs and we only have offers with 1 CPU.  Each scheduling round will re-assess every offer despite the fact that the offers have not changed shape and will always be a mismatch (hereafter termed _static_ mismatches).  Instead we should try to skip over offers that are a static mismatch.  We could do this at the {{TaskGroup}} level since every element in a task group is by definition statically equivalent.  This means that jobs with a large number of instances could be scheduled very efficiently since the first task scheduling round could identify static mismatches reducing the working set in the next round.This is to contrast with _dynamic_ mismatches where a change in the tasks on a machine or other settings could make a previously-ineligible offer become a match.  The current sources of dynamic mismatches are limit constraints host maintenance modes and dedicated attributes.I propose we proceed in several steps re-evaluating after each:1. instrument the scheduler to better estimate the improvements2. avoid future (offer task group) evaluations when static mismatches are found3. avoid future (offer task group) evaluations when dynamic mismatches are found,8,3,3,1,0,Maxim Khutornenko,Bill Farner,Bill Farner,9,0,1,0,0,0,0,0
AURORA-823,Bug,59,Resolved,thermos pex GLIBC error when using py27/glibc 2.12/rhel6.4,"https://pypi.python.org/pypi/mesos.native/0.20.0Recently pants config in aurora build is modified to enforce python >= 2.7. With this change we can't use mesos.native library. The mesos.native egg in above pypi was built using py27/glibc 2.16. RHEL6 is still using glibc 2.12. The pex built using this library is not runnable unless glibc is upgraded to 2.16.Here is a sample traceback occur when running {{gc_executor}}. Same error occur with {{thermos_observer}} and {{thermos_executor}}:{code}$ /usr/local/bin/gc_executor Traceback (most recent call last):  File ""/usr/local/bin/gc_executor/.bootstrap/_pex/pex.py"" line 225 in execute    self.execute_entry(entry_point args)  File ""/usr/local/bin/gc_executor/.bootstrap/_pex/pex.py"" line 273 in execute_entry    runner(entry_point)  File ""/usr/local/bin/gc_executor/.bootstrap/_pex/pex.py"" line 295 in execute_pkg_resources    runner = entry.load(require=False)  # trust that the environment is sane  File ""/usr/local/bin/gc_executor/.bootstrap/pkg_resources.py"" line 2048 in load    entry = __import__(self.module_name globals()globals() ['__name__'])  File ""/usr/local/bin/gc_executor/apache/aurora/executor/bin/gc_executor_main.py"" line 22 in <module>  File ""/root/.pex/install/mesos.native-0.20.0-py2.7-linux-x86_64.egg.be6632b790cd03172f858e7f875cdab4ef415ca5/mesos.native-0.20.0-py2.7-linux-x86_64.egg/mesos/native/__init__.py"" line 17 in <module>    from ._mesos import MesosExecutorDriverImplImportError: /lib64/libc.so.6: version `GLIBC_2.16' not found (required by /root/.pex/install/mesos.native-0.20.0-py2.7-linux-x86_64.egg.be6632b790cd03172f858e7f875cdab4ef415ca5/mesos.native-0.20.0-py2.7-linux-x86_64.egg/mesos/native/_mesos.so){code}I think the fix is to recompile {{mesos.native}} egg to be compatible with glibc >= v2.12. Same is applicable for {{mesos.interface}} egg.",null,3,5,1,1,Brian Wickman,Bhuvaneswaran A,Bhuvaneswaran A,8,0,1,0,0,0,0,0
AURORA-934,Story,59,Resolved,client should set User-Agent,"This will allow easily disambiguating the ""official"" client from other potential API consumers in the scheduler log.",null,3,2,1,0,Joshua Cohen,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-617,Story,59,Resolved,Switch pants 3rdparty to use python_requirements,Move our thirdparty python requirements to a {{requirements.txt}} file using pants' new support for it.This makes improved IDE integration for python development more tractable and allows for interoperability with other tools like https://github.com/nvie/pip-tools to automatically check for upstream updates.,null,3,3,1,0,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,3,0,2,0,0,0,0,0
AURORA-469,Task,59,Resolved,quota check failures should specify how much under quota you are,If your create/update is under quota the client spits out a ton of information around requested allocated total quota but doesn't actually say how much quota you are short.  It would be helpful to instead show how much you fall short.,null,3,3,1,0,Maxim Khutornenko,Brian Wickman,Brian Wickman,1,0,0,0,0,0,0,0
AURORA-919,Task,59,Resolved,Aurora client should provide a --verbose flag and silence DEBUG level log output by default,Provide a --verbose flag to allow users to see verbose logging in the aurora client. By default they should only see INFO level and above. Debug output should only be visible with the --verbose flag.,null,3,2,1,0,Zameer Manji,Zameer Manji,Zameer Manji,5,0,3,1,1,0,0,0
AURORA-925,Task,59,Resolved,refactor build.gradle to extract thrift compilation as a separate task class,null,null,3,3,1,0,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-930,Story,59,Resolved,GC performance issues with snapshot deduplication on large clusters,We observed very long GC pauses in our production cluster we believe are caused by the extra heap pressure caused by SnapshotDeduplicatorImpl's extra deep copy of a Snapshot object.Also EntrySerializer fully buffers the full binary-encoded thrift Snapshot before writing it to the replicated log - it can avoid memory pressure by streaming instead.,null,3,3,1,0,Kevin Sweeney,Chris Lambert,Chris Lambert,4,0,2,0,0,0,0,0
AURORA-939,Bug,59,Resolved,Executor crashes when it receives an invalid task config,"Stacktrace:{noformat}Uncaught exception:Traceback (most recent call last):  File ""/root/.pex/install/twitter.common.exceptions-0.3.0-py2.7.egg.cf67f7016992e92b38deaf83dac4bb90d8677050/twitter.common.exceptions-0.3.0-py2.7.egg/twitter/common/exceptions/__init__.py"" line 126 in _excepting_run    self.__real_run(*args **kw)  File ""/root/.pex/install/twitter.common.concurrent-0.3.0-py2.7.egg.1f2389f41eaa34088db63ee54687f5429b09403c/twitter.common.concurrent-0.3.0-py2.7.egg/twitter/common/concurrent/deferred.py"" line 43 in run    self._closure()  File ""/root/.pex/install/apache.aurora.executor-0.6.1_DEV1415152524-py2.7.egg.eeaf32f22c2835b79901cfa268aed2775d327177/apache.aurora.executor-0.6.1_DEV1415152524-py2.7.egg/apache/aurora/executor/aurora_executor.py"" line 262 in     defer(lambda: self._run(driver assigned_task))  File ""/root/.pex/install/apache.aurora.executor-0.6.1_DEV1415152524-py2.7.egg.eeaf32f22c2835b79901cfa268aed2775d327177/apache.aurora.executor-0.6.1_DEV1415152524-py2.7.egg/apache/aurora/executor/aurora_executor.py"" line 100 in _run    if not self._initialize_sandbox(driver assigned_task):  File ""/root/.pex/install/apache.aurora.executor-0.6.1_DEV1415152524-py2.7.egg.eeaf32f22c2835b79901cfa268aed2775d327177/apache.aurora.executor-0.6.1_DEV1415152524-py2.7.egg/apache/aurora/executor/aurora_executor.py"" line 128 in _initialize_sandbox    self._sandbox = self._sandbox_provider.from_assigned_task(assigned_task)  File ""/var/lib/mesos/slaves/20141110-182528-1715086346-5050-57898-529/frameworks/201104070004-0000002563-0000/executors/thermos-1416416412289-mst-devel-xfactor-model-3-ba927208-f5a4-4dd1-9d6c-82bdd742a524/runs/0985cabb-5cb8-4ef0-8920-ba3c151ceb2b/thermos_executor/twitter/aurora/executor/bin_internal/thermos_executor_main.py"" line 36 in from_assigned_task  File ""/root/.pex/install/apache.aurora.executor-0.6.1_DEV1415152524-py2.7.egg.eeaf32f22c2835b79901cfa268aed2775d327177/apache.aurora.executor-0.6.1_DEV1415152524-py2.7.egg/apache/aurora/executor/common/task_info.py"" line 88 in mesos_task_instance_from_assigned_task    raise ValueError('Unexpected unbound refs: %s' % ' '.join(map(str refs)))ValueError: Unexpected unbound refs: {{dateRanges[3][1]}} {{thermos.ports[http]}} {{dateRanges[3][0]}}{noformat}This should instead cause a TASK_FAILED with a helpful version of this message.",null,3,2,1,0,Zameer Manji,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-949,Bug,59,Resolved,TRequestsTransport does not raise an exception on 5xx or 4xx responses,The TRequestsTransport used by the client silently accepts 5xx responses. Instead it should raise an exception so the request can be retried and the response body can be discarded since it may not be valid JSON.,null,4,1,1,0,Zameer Manji,Zameer Manji,Zameer Manji,1,0,0,0,0,0,0,0
AURORA-121,Story,59,Resolved,Make the preemptor more efficient,When {{TaskSchedulerImpl}} fails to find an open slot for a task it falls back to the preemptor:{code}if (!offerQueue.launchFirst(getAssignerFunction(taskId task))) {  // Task could not be scheduled.  maybePreemptFor(taskId);  return TaskSchedulerResult.TRY_AGAIN;}{code}This can be problematic when the task store is large (O(10k tasks)) and there is a steady supply of PENDING tasks not satisfied by open slots.  This will manifest as an overall degraded/slow scheduler and logs of slow queries used for preemption:{noformat}I0125 17:47:36.970 THREAD23 org.apache.aurora.scheduler.storage.mem.MemTaskStore.fetchTasks: Query took 107 ms: TaskQuery(owner:null environment:null jobName:nulltaskIds:null statuses:[KILLING ASSIGNED STARTING RUNNING RESTARTING] slaveHost:null instanceIds:null){noformat}Several approaches come to mind to improve this situation (not mutually exclusive):- (easy) More aggressively back off on tasks that cannot be satisfied- (easy) Fall back to preemption less frequently- (easy) Gather the list of slaves from {{AttributeStore}} rather than {{TaskStore}}.  This breaks the operation up into many smaller queries and reduces the amount of work in cases where a match is found.  However this would actually create more work when a match is not found so this approach is probably not helpful by itself.- (harder) Scan for preemption candidates asynchronously freeing up the TaskScheduler thread and the storage write lock.  Scans could be kicked off by the task scheduler ideally in a way that doesn't dogpile.  This could also be done in a weakly-consistent way to minimally contribute to storage contention.,null,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,4,0,0,0,0,0,0,0
AURORA-935,Task,59,Resolved,Improve logging in MaintenanceController,We have observed hosts occasionally stuck in {{DRAINING}} even after all their tasks moved into {{KILLED}}. There is not enough logging around setting maintenance status for further troubleshooting.,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-943,Task,59,Resolved,Improve messaging in admin host_drain command,"In case draining happens fast the admin prints a somewhat confusing message: ""Waiting for hosts to be in DRAINED: []"". Reorder logging with the host population loop to in HostMaintenance.check_if_drained() to avoid confusion.",null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-775,Story,59,Resolved,Remove v1 client build,The v1 client has been deprecated for some time.  Stop building it to shoehorn folks over to v2.,null,3,3,1,0,Bill Farner,Bill Farner,Bill Farner,2,0,6,2,2,0,0,0
AURORA-691,Task,59,Resolved,Remove populated field in PopulateJobResult struct,In api.thrift:PopulateJobResult the {{populated}} field (id 1) is deprecated in favor of {{taskConfig}} (id 2).,null,3,2,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,5,0,0,0,0,0,0,0
AURORA-832,Task,59,Resolved,Remove SANDBOX_DELETED state,Remove {{SANDBOX_DELETED}} state from {{ScheduleStatus}} thrift struct.,null,3,2,1,0,Bill Farner,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-952,Bug,59,Resolved,method interceptor is fatefully intercepting finalize() with null pointer,I1120 00:00:35.229 THREAD3 org.apache.aurora.scheduler.thrift.aop.LoggingInterceptor.invoke: finalize()W1120 00:00:35.229 THREAD3 org.apache.aurora.scheduler.thrift.aop.LoggingInterceptor.invoke: Uncaught exception while handling finalize()java.lang.NullPointerException   at org.apache.aurora.scheduler.thrift.aop.ServerInfoInterceptor.invoke(ServerInfoInterceptor.java:33)   at org.apache.aurora.scheduler.thrift.aop.ThriftStatsExporterInterceptor.invoke(ThriftStatsExporterInterceptor.java:47)   at org.apache.aurora.scheduler.thrift.aop.FeatureToggleInterceptor.invoke(FeatureToggleInterceptor.java:38)   at org.apache.aurora.scheduler.thrift.aop.LoggingInterceptor.invoke(LoggingInterceptor.java:88)   at java.lang.ref.Finalizer.invokeFinalizeMethod(Native Method)   at java.lang.ref.Finalizer.runFinalizer(Finalizer.java:101)   at java.lang.ref.Finalizer.access$100(Finalizer.java:32)   at java.lang.ref.Finalizer$FinalizerThread.run(Finalizer.java:190),null,4,2,1,2,Kevin Sweeney,alexius ludeman,alexius ludeman,1,0,0,0,0,0,0,0
AURORA-956,Bug,59,Resolved,The Scheduler can allocate Mesos Tasks with 0 Disk.,It is possible for the scheduler to send a task of 0 disk resources to the scheduler because of the following variable:{noformat}    static final Resources MIN_TASK_RESOURCES = new Resources(        0.01        Amount.of(1L Data.MB)        Amount.of(0L Data.MB) // Disk        0);{noformat}This issue was never triggered before because Aurora omitted the disk resource instead of setting it to 0. ,null,1,1,1,0,Zameer Manji,Zameer Manji,Zameer Manji,1,0,1,0,0,0,0,0
AURORA-466,Task,59,Resolved,Remove message string in Response struct,In {{api.thrift}} the 'message' field (id 2) is deprecated in favor of a structure that allows multiple messages.,null,4,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-143,Task,59,Resolved,Remove the getVersion RPC,Once getVersion API is deprecated remove it from the code.,null,3,2,1,0,Bill Farner,Suman Karumuri,Suman Karumuri,1,0,3,0,0,0,0,0
AURORA-467,Task,59,Resolved,Remove version field in Response struct,In {{api.thrift}} the 'version' field (id 4) is deprecated in favor of {{serverInfo}}.,null,4,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-947,Task,59,Resolved,Use thrift's built-in doc generator,We currently have a custom API documentation generator in {{src/main/python/apache/aurora/tools/java/thrift_wrapper_codegen.py}}.  As it turns out thrift has built-in support for this when invoked with {{--gen html}}.  From a quick glance it picks up ~all of our javadoc-style docstrings and displays them nicely in the generated output.  My attempts to find documentation for the doc syntax in thrift failed (the irony) but it appears at least javadoc-style comment blocks are captured.We should consider our doc generator deprecated and switch to this as soon as it is practical.,null,4,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-965,Bug,59,Resolved,Aurora client prints ambiguous trailing error message,"Client v2 prints redundant and confusing ""Error executing command"" error message at the end of failed command run:{noformat}Update failed due to error:Unable to start job update: Response from scheduler: INVALID_REQUEST (message: Failed quota check.)Error executing command: Update failed due to error:{noformat}",null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-967,Task,59,Resolved,Explore adding a PMD rule for validating @Timed attribute placement,Bugs like AURORA-966 could be easily prevented with a custom PMD rule checking the placement method visibility. Consider adding an XPath-based configuration. More on syntax: http://pmd.sourceforge.net/pmd-4.2.6/xpathruletutorial.html,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-782,Story,59,Resolved,Remove command bridging from client,The v2 client will resolve v1 commands.  Remove this to stop supporting old command syntax.,null,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,1,2,1,1,0,0,0
AURORA-961,Task,59,Resolved,Set default --batch-size in client v2 to 1,The default {{--batch-size}} value in client v2 is set to 5 [1] which may be too high for a small job to keep up with its SLA. The default of 1 should be a sane alternative.[1] - https://github.com/apache/incubator-aurora/blob/master/src/main/python/apache/aurora/client/cli/options.py#L199-L200,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-969,Task,62,Resolved,Create scheduler performance benchmark framework,We need to have a reliable way to measure scheduler performance in a contained local environment where various real life scenarios could be simulated without the need to run end-to-end cluster components. The benchmarks will be built with jmh harness added earlier in https://reviews.apache.org/r/28710/.,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,1,0,0,0,0,0
AURORA-823,Bug,62,Resolved,thermos pex GLIBC error when using py27/glibc 2.12/rhel6.4,"https://pypi.python.org/pypi/mesos.native/0.20.0Recently pants config in aurora build is modified to enforce python >= 2.7. With this change we can't use mesos.native library. The mesos.native egg in above pypi was built using py27/glibc 2.16. RHEL6 is still using glibc 2.12. The pex built using this library is not runnable unless glibc is upgraded to 2.16.Here is a sample traceback occur when running {{gc_executor}}. Same error occur with {{thermos_observer}} and {{thermos_executor}}:{code}$ /usr/local/bin/gc_executor Traceback (most recent call last):  File ""/usr/local/bin/gc_executor/.bootstrap/_pex/pex.py"" line 225 in execute    self.execute_entry(entry_point args)  File ""/usr/local/bin/gc_executor/.bootstrap/_pex/pex.py"" line 273 in execute_entry    runner(entry_point)  File ""/usr/local/bin/gc_executor/.bootstrap/_pex/pex.py"" line 295 in execute_pkg_resources    runner = entry.load(require=False)  # trust that the environment is sane  File ""/usr/local/bin/gc_executor/.bootstrap/pkg_resources.py"" line 2048 in load    entry = __import__(self.module_name globals()globals() ['__name__'])  File ""/usr/local/bin/gc_executor/apache/aurora/executor/bin/gc_executor_main.py"" line 22 in <module>  File ""/root/.pex/install/mesos.native-0.20.0-py2.7-linux-x86_64.egg.be6632b790cd03172f858e7f875cdab4ef415ca5/mesos.native-0.20.0-py2.7-linux-x86_64.egg/mesos/native/__init__.py"" line 17 in <module>    from ._mesos import MesosExecutorDriverImplImportError: /lib64/libc.so.6: version `GLIBC_2.16' not found (required by /root/.pex/install/mesos.native-0.20.0-py2.7-linux-x86_64.egg.be6632b790cd03172f858e7f875cdab4ef415ca5/mesos.native-0.20.0-py2.7-linux-x86_64.egg/mesos/native/_mesos.so){code}I think the fix is to recompile {{mesos.native}} egg to be compatible with glibc >= v2.12. Same is applicable for {{mesos.interface}} egg.",null,3,5,1,1,Brian Wickman,Bhuvaneswaran A,Bhuvaneswaran A,8,0,1,0,0,0,0,0
AURORA-973,Task,62,Resolved,Add a document describing thrift deprecation procedure,We need to document a thrift deprecation policy to help us ensure we are always backwards compatible.,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-934,Story,62,Resolved,client should set User-Agent,"This will allow easily disambiguating the ""official"" client from other potential API consumers in the scheduler log.",null,3,2,1,0,Joshua Cohen,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-617,Story,62,Resolved,Switch pants 3rdparty to use python_requirements,Move our thirdparty python requirements to a {{requirements.txt}} file using pants' new support for it.This makes improved IDE integration for python development more tractable and allows for interoperability with other tools like https://github.com/nvie/pip-tools to automatically check for upstream updates.,null,3,3,1,0,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,3,0,2,0,0,0,0,0
AURORA-968,Bug,62,Resolved,Client logs duplicate error messages,There are quite a few places (e.g. [1]) in the client where stderr logging is duplicated due to {{print_err()}} followed up by a correspondent {{raise context.CommandError()}}.[1] - https://github.com/apache/incubator-aurora/blob/master/src/main/python/apache/aurora/client/cli/jobs.py#L342-L344,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-469,Task,62,Resolved,quota check failures should specify how much under quota you are,If your create/update is under quota the client spits out a ton of information around requested allocated total quota but doesn't actually say how much quota you are short.  It would be helpful to instead show how much you fall short.,null,3,3,1,0,Maxim Khutornenko,Brian Wickman,Brian Wickman,1,0,0,0,0,0,0,0
AURORA-919,Task,62,Resolved,Aurora client should provide a --verbose flag and silence DEBUG level log output by default,Provide a --verbose flag to allow users to see verbose logging in the aurora client. By default they should only see INFO level and above. Debug output should only be visible with the --verbose flag.,null,3,2,1,0,Zameer Manji,Zameer Manji,Zameer Manji,5,0,3,1,1,0,0,0
AURORA-989,Bug,62,Resolved,"aurora client v2 dont have ""version"" command",aurora v2 client should include this command. there's no way to find version of client running.{code}[bhuvan@build ~/projects/mesos/incubator-aurora]$ ./dist/aurora2.pex versionusage: aurora2.pex [-h] {taskquotacronjobconfigslabeta-update} ...aurora2.pex: error: argument noun: invalid choice: 'version' (choose from 'task' 'quota' 'cron' 'job' 'config' 'sla' 'beta-update'){code}{code}[bhuvan@build ~/projects/mesos/incubator-aurora]$ ./dist/aurora_client.pex versionAurora client build info:sha: 6c71b72e5b5f4da3346ea4036e39096a4eb9cd97date: Tuesday Jan 06 2015 21:42:55Aurora API version: APIVersion(major=3){code},null,3,4,1,1,Joshua Cohen,Bhuvaneswaran A,Bhuvaneswaran A,3,0,2,1,1,0,0,0
AURORA-970,Task,62,Resolved,Include aurora version (from .auroraversion) in the client help output,It would be useful to have the actual aurora version as well as the git sha/build date in the client help output.,null,3,2,1,0,Joshua Cohen,Joshua Cohen,Joshua Cohen,1,0,1,0,0,0,0,0
AURORA-1043,Bug,73,Resolved,/logconfig does not work when the scheduler is behind SSL,When the /logconfig endpoint is behind SSL the JavaScript console is filled with the following errors:{noformat} Mixed Content: The page at 'https://localhost/logconfig' was loaded over HTTPS but requested an insecure script 'http://ajax.googleapis.com/ajax/libs/jquery/1.10.1/jquery.min.js'. This request has been blocked; the content must be served over HTTPS.logconfig:4402 Uncaught ReferenceError: $ is not defined{noformat}As a result the endpoint does not work.,null,3,2,1,0,null,Zameer Manji,Zameer Manji,2,0,0,0,0,0,0,0
AURORA-723,Task,73,Resolved,Create design document for security code refactor,null,2,3,1,1,1,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-1010,Task,73,Resolved,Modify updater state machine to support heartbeat-driven pause/resume,The scheduler updater needs to react to a lack of heartbeat events by pausing an active heartbeat-enabled update. Likewise it should resume a previously blocked update on a fresh heartbeat call.See [1] for more details.[1] - https://github.com/maxim111333/incubator-aurora/blob/hb_doc/docs/update-heartbeat.md,5,3,2,1,0,Maxim Khutornenko,Chris Lambert,Chris Lambert,1,0,0,0,0,0,0,0
AURORA-330,Bug,73,Resolved,aurora update should fail gracefully if job is not a service,"14:31 < bhuvan> a quick note on aurora. when we update a job and if the job is finished before update command the update command fail. is it a known issue?14:32 < wickman> i think updates require that the job is a Service() which means there is no such thing as ""finished""14:32 < wickman> since on completion they will just be restarted14:34 -!- dlester [~dlester@apache/committer/dlester] has joined #aurora14:34 < bhuvan> does it mean we can't update a job that is running with service=False?14:35 < wickman> i believe so (somebody else correct me if i'm wrong)14:35 < wickman> i think the reason it's that way is because kill/create has the same semantics for something with service=False14:40 < mkhutornenko> bhuvan: thanks for brining this up. I think the updater should do a pre-check and bail out gracefully if the job is not a service14:40 < bhuvan> mkhutornenko: ok. i'll file a bug.14:40 < mkhutornenko> bhuvan: thanks I was just typing to suggest it :)",2,2,3,1,1,Bill Farner,Bhuvaneswaran A,Bhuvaneswaran A,2,0,2,0,0,0,0,0
AURORA-1009,Task,73,Resolved,Implement pulseJobUpdates RPC,Implement pulseJobUpdates RPC to support external service heartbeats.See [1] for more details.[1] - https://github.com/maxim111333/incubator-aurora/blob/hb_doc/docs/update-heartbeat.md,2,3,2,1,0,Maxim Khutornenko,Chris Lambert,Chris Lambert,1,0,0,0,0,0,0,0
AURORA-969,Task,73,Resolved,Create scheduler performance benchmark framework,We need to have a reliable way to measure scheduler performance in a contained local environment where various real life scenarios could be simulated without the need to run end-to-end cluster components. The benchmarks will be built with jmh harness added earlier in https://reviews.apache.org/r/28710/.,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,1,0,0,0,0,0
AURORA-1024,Story,73,Resolved,Implement API for dual reading Thermos checkpoints,TBD by @wickman,8,3,2,1,0,Brian Wickman,Chris Lambert,Chris Lambert,2,0,5,1,1,0,0,0
AURORA-1023,Bug,73,Resolved,Releasing the update lock trips off scheduler updater,"Here is the faulty sequence:- User starts a scheduler job update and pauses while it's still in progress- User runs ""aurora job cancel-update"" command thus releasing the update lock- User starts a new scheduler job updateAt this point any attempt to abort or pause an active update results in the following error [1]:{noformat}vagrant@vagrant-ubuntu-trusty-64:~$ aurora beta-update abort devcluster/www-data/prod/hello INFO] Aborting update for: devcluster/www-data/prod/helloFailed to abort update due to error:expected one element but was: <JobUpdateSummary(updateId:4b7fdc14-428f-44e4-9261-908b606f47e2 jobKey:JobKey(role:www-data environment:prod name:hello) user:UNSECURE state:JobUpdateState(status:ROLLING_FORWARD createdTimestampMs:1421450382234 lastModifiedTimestampMs:1421450382234)) JobUpdateSummary(updateId:3c9c2fa2-8e51-4c13-8440-94364205a37b jobKey:JobKey(role:www-data environment:prod name:hello) user:UNSECURE state:JobUpdateState(status:ROLL_FORWARD_PAUSED createdTimestampMs:1421450304935 lastModifiedTimestampMs:1421450324055))>{noformat}The only way to recover from this state is either wait for the active job update to reach terminal state or force it to it by running another cancel-update.While the ""cancel-update"" will eventually go away with the client updater we do have a problem during the migration period. A possible (though ugly) short-term workaround could be calling ""abortJobUpdate"" from the ""releaseLock"" RPC.[1] - https://github.com/apache/incubator-aurora/blob/master/src/main/java/org/apache/aurora/scheduler/updater/JobUpdateControllerImpl.java#L295-L296",5,2,2,1,0,Bill Farner,Maxim Khutornenko,Maxim Khutornenko,2,0,0,0,0,0,0,0
AURORA-1008,Bug,73,Resolved,Pystachio section variables don't seem to work as described in the documentation,"At https://github.com/apache/incubator-aurora/blob/master/docs/configuration-tutorial.md#user-content-templating-1-binding-in-pystachio is described that you can use{code}{{#x}} Testing... {{/x}}{code}or{code}{ ""x"": [ { ""name"" : ""tic"" } { ""name"" : ""tac"" } { ""name"" : ""toe"" } ] }{{#x}} {{name}} {{/x}}{code}Example:{code}hello = Process(  name = 'hello'  cmdline = """"""    while true; do      echo hello world  {{#x}} if-statement {{/x}}      sleep 100    done  """""").bind(x = 1)task = SequentialTask(  processes = [hello]  resources = Resources(cpu = 1.0 ram = 128*MB disk = 128*MB))jobs = [Service( task = task cluster = 'gf-office' role = 'derfloh' environment = 'test' name = 'hello')]{code}If I try to upload a config that uses the above syntax I get a ""Error loading configuration: #x""(I'm using 0.6.0-incubating but the documentation for 0.6.0 and master is the same at that part so that shouldn't matter?)",null,3,2,1,0,Kevin Sweeney,Florian Pfeiffer,Florian Pfeiffer,1,0,1,0,0,0,0,0
AURORA-1028,Story,73,Resolved,Export TASK_LOST source stats from Scheduler,Use the source and reason fields that are included in status updates (circa mesos 0.21) to produce log messages and exported counters.http://mesos.apache.org/blog/mesos-0-21-0-released/,5,3,2,1,0,Bill Farner,Chris Lambert,Chris Lambert,1,0,1,1,1,0,0,0
AURORA-1053,Bug,73,Resolved,StorageBackupImpl doesn't use streaming,StorageBackupImpl doesn't appear to use streaming [1]. This appears to correlate to a large GC event in one of our bigger clusters.[1] https://github.com/apache/incubator-aurora/blob/d1d089afc81cffdf4d43be42b2a5fa5b86821223/src/main/java/org/apache/aurora/scheduler/storage/backup/StorageBackup.java#L157-L159,null,3,2,1,0,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-1029,Task,73,Resolved,Remove client YAML support (drop pyaml dependency),Drop this undocumented feature to reduce native dependencies.,null,4,2,1,0,Bill Farner,Chris Lambert,Chris Lambert,1,0,0,0,0,0,0,0
AURORA-950,Bug,73,Resolved,aurora job inspect --raw is broken,"Stack trace:{noformat}Fatal error running command:Traceback (most recent call last):  File ""/home/ksweeney/.tools-cache/home/aurora/tools/client/libexec/aurora-client/.deps/apache.aurora.clientv2-0.6.1_DEV1415815971-py2.7.egg/apache/aurora/client/cli/__init__.py"" line 394 in _execute    result = noun.execute(context)  File ""/home/ksweeney/.tools-cache/home/aurora/tools/client/libexec/aurora-client/.deps/apache.aurora.clientv2-0.6.1_DEV1415815971-py2.7.egg/apache/aurora/client/cli/__init__.py"" line 481 in execute    return self.verbs[context.options.verb].execute(context)  File ""/home/ksweeney/.tools-cache/home/aurora/tools/client/libexec/aurora-client/.deps/apache.aurora.clientv2-0.6.1_DEV1415815971-py2.7.egg/apache/aurora/client/cli/jobs.py"" line 243 in execute    context.print_out(config.job())  File ""/home/ksweeney/.tools-cache/home/aurora/tools/client/libexec/aurora-client/.deps/apache.aurora.clientv2-0.6.1_DEV1415815971-py2.7.egg/apache/aurora/client/cli/__init__.py"" line 131 in print_out    lines = msg.split(""\n"")AttributeError: 'JobConfiguration' object has no attribute 'split'{noformat}",null,3,1,1,0,Bill Farner,Kevin Sweeney,Kevin Sweeney,0,0,1,0,0,0,0,0
AURORA-964,Bug,73,Resolved,Scheduler updater successfully updates a non-existent job,As it's currently implemented the scheduler updater ({{aurora beta-update start}}) creates a new job when an attempt is made to update a non-existent job. We should either prevent this from happening or fully embrace the idea of creating a job via server updater deprecate {{createJob}} RPC and update related client commands.,null,3,3,1,0,Bill Farner,Maxim Khutornenko,Maxim Khutornenko,3,0,2,0,0,0,0,0
AURORA-1045,Bug,73,Resolved,Scheduler should avoid performing authentication while holding the write lock,Several RPCs interact with {{sessionValidator}} while holding the write lock.  This is unnecessary and causes undue write lock contention when the authentication system in use is slow.,null,1,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-1050,Bug,73,Resolved,test_end_to_end.sh is failing on master,A task is going lost with the following message:{noformat}LOST : Task uses more resources cpus(*):0.75; disk(*):64; mem(*):257; ports(*):[31281-31281] than available cpus(*):3.97; disk(*):19997; mem(*):256; ports(*):[31000-32000]{noformat}I suspect this was caused by the fix for AURORA-1021 will git-bisect and confirm.,null,1,2,1,0,Bill Farner,Bill Farner,Bill Farner,2,0,1,1,1,0,0,0
AURORA-1076,Bug,73,Resolved,Docker patch created incompatible ExeuctorInfo changes for GC executor,The [docker patch| https://reviews.apache.org/r/28920/diff/] changed the ExecutorInfo of the GC executor. This causes the mesos slave to fail to launch the GC task with the following error:{noformat}I0130 21:50:05.373389 50869 master.cpp:3441] Sending status update TASK_LOST (UUID: 82ef615c-0d59-4427-95d5-80cf0e52b3fc) for task system-gc-c89c0c05-200c-462e-958a-ecd7b9a76831 of framework 201103282247-0000000019-0000 'Task has invalid ExecutorInfo (existing ExecutorInfo with same ExecutorID is not compatible).{noformat}The root of this appears to be setting the shell attribute in the ExecutorInfo to be true when it was unset before.,1,1,1,1,0,Zameer Manji,Zameer Manji,Zameer Manji,2,0,1,0,0,0,0,0
AURORA-1043,Bug,76,Resolved,/logconfig does not work when the scheduler is behind SSL,When the /logconfig endpoint is behind SSL the JavaScript console is filled with the following errors:{noformat} Mixed Content: The page at 'https://localhost/logconfig' was loaded over HTTPS but requested an insecure script 'http://ajax.googleapis.com/ajax/libs/jquery/1.10.1/jquery.min.js'. This request has been blocked; the content must be served over HTTPS.logconfig:4402 Uncaught ReferenceError: $ is not defined{noformat}As a result the endpoint does not work.,null,3,2,1,0,null,Zameer Manji,Zameer Manji,2,0,0,0,0,0,0,0
AURORA-723,Task,76,Resolved,Create design document for security code refactor,null,2,3,1,1,1,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-1026,Story,76,Resolved,Update observer to read checkpoint stream from sandbox,See AURORA-2014.,5,3,2,1,0,Brian Wickman,Chris Lambert,Chris Lambert,4,0,2,1,1,0,0,0
AURORA-909,Story,76,Resolved,Differentiate between dynamic and static vetoes,We're making a decent effort at reducing the _cost_ of task scheduling operations abut have not yet invested in reducing the working set in a way that causes task scheduling to scale better.  Each scheduling attempt for each task is an O(n) operation where n is the number of offers.I would like to explore optimizations where we try to reduce the amount of redundant work performed in task scheduling.  Say for example we're trying to schedule a task that needs 2 CPUs and we only have offers with 1 CPU.  Each scheduling round will re-assess every offer despite the fact that the offers have not changed shape and will always be a mismatch (hereafter termed _static_ mismatches).  Instead we should try to skip over offers that are a static mismatch.  We could do this at the {{TaskGroup}} level since every element in a task group is by definition statically equivalent.  This means that jobs with a large number of instances could be scheduled very efficiently since the first task scheduling round could identify static mismatches reducing the working set in the next round.This is to contrast with _dynamic_ mismatches where a change in the tasks on a machine or other settings could make a previously-ineligible offer become a match.  The current sources of dynamic mismatches are limit constraints host maintenance modes and dedicated attributes.I propose we proceed in several steps re-evaluating after each:1. instrument the scheduler to better estimate the improvements2. avoid future (offer task group) evaluations when static mismatches are found3. avoid future (offer task group) evaluations when dynamic mismatches are found,8,3,3,1,0,Maxim Khutornenko,Bill Farner,Bill Farner,9,0,1,0,0,0,0,0
AURORA-1062,Task,76,Resolved,apache.aurora.executor.common.HealthChecker should export stats,Right now the HealthChecker status checker exports no stats.  It would be useful for things like number of consecutive health failures and most recent health check latency to be exported on a per task basis so that they could be monitored.,1,3,4,1,0,Brian Wickman,Brian Wickman,Brian Wickman,6,0,1,0,0,0,0,0
AURORA-1012,Task,76,Resolved,Update documentation to explain the scheduler heartbeat mechanism,TBD [~maximk],1,3,3,1,0,Maxim Khutornenko,Chris Lambert,Chris Lambert,1,0,0,0,0,0,0,0
AURORA-1093,Story,76,Resolved,Scheduler updates should be uniquely identified by jobKey + updateId,We should generalize the approach of dealing with scheduler updates by always uniquely identifying them by a new composite key that includes both jobKey and the updateId e.g.:{noformat}struct JobUpdateKey {  1: JobKey jobKey  2: string updateId}{noformat}The above approach would benefit us long term when it comes to implementing a fully functional REST API. Having both job key and update ID components in the URL will help us logically split authorization and application data layers. E.g.: in {{/api/updates/role/env/name/updateId}} the {{/role/env/name}} may be used for authorization whereas the {{updateId}} will remove the ambiguity from the data lookup.,8,3,2,1,0,Bill Farner,Maxim Khutornenko,Maxim Khutornenko,5,0,4,0,0,0,0,0
AURORA-1025,Story,76,Resolved,Update gc executor to read checkpoint stream from sandbox,This is an intermediate step necessary to retire the gc executor.  See AURORA-1024.,3,3,3,1,0,Brian Wickman,Chris Lambert,Chris Lambert,2,0,1,0,0,0,0,0
AURORA-1010,Task,76,Resolved,Modify updater state machine to support heartbeat-driven pause/resume,The scheduler updater needs to react to a lack of heartbeat events by pausing an active heartbeat-enabled update. Likewise it should resume a previously blocked update on a fresh heartbeat call.See [1] for more details.[1] - https://github.com/maxim111333/incubator-aurora/blob/hb_doc/docs/update-heartbeat.md,5,3,2,1,0,Maxim Khutornenko,Chris Lambert,Chris Lambert,1,0,0,0,0,0,0,0
AURORA-330,Bug,76,Resolved,aurora update should fail gracefully if job is not a service,"14:31 < bhuvan> a quick note on aurora. when we update a job and if the job is finished before update command the update command fail. is it a known issue?14:32 < wickman> i think updates require that the job is a Service() which means there is no such thing as ""finished""14:32 < wickman> since on completion they will just be restarted14:34 -!- dlester [~dlester@apache/committer/dlester] has joined #aurora14:34 < bhuvan> does it mean we can't update a job that is running with service=False?14:35 < wickman> i believe so (somebody else correct me if i'm wrong)14:35 < wickman> i think the reason it's that way is because kill/create has the same semantics for something with service=False14:40 < mkhutornenko> bhuvan: thanks for brining this up. I think the updater should do a pre-check and bail out gracefully if the job is not a service14:40 < bhuvan> mkhutornenko: ok. i'll file a bug.14:40 < mkhutornenko> bhuvan: thanks I was just typing to suggest it :)",2,2,3,1,1,Bill Farner,Bhuvaneswaran A,Bhuvaneswaran A,2,0,2,0,0,0,0,0
AURORA-1009,Task,76,Resolved,Implement pulseJobUpdates RPC,Implement pulseJobUpdates RPC to support external service heartbeats.See [1] for more details.[1] - https://github.com/maxim111333/incubator-aurora/blob/hb_doc/docs/update-heartbeat.md,2,3,2,1,0,Maxim Khutornenko,Chris Lambert,Chris Lambert,1,0,0,0,0,0,0,0
AURORA-969,Task,76,Resolved,Create scheduler performance benchmark framework,We need to have a reliable way to measure scheduler performance in a contained local environment where various real life scenarios could be simulated without the need to run end-to-end cluster components. The benchmarks will be built with jmh harness added earlier in https://reviews.apache.org/r/28710/.,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,1,0,0,0,0,0
AURORA-1024,Story,76,Resolved,Implement API for dual reading Thermos checkpoints,TBD by @wickman,8,3,2,1,0,Brian Wickman,Chris Lambert,Chris Lambert,2,0,5,1,1,0,0,0
AURORA-1088,Task,76,Resolved,Expose blockIfNoPulseAfterMs setting in updateSettings.html,The update UI needs to expose the coordinated update settings. ,1,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-1071,Task,76,Resolved,Modify UpdateConfig schema to support heartbeats,Expose {{pulse_interval_secs}} in the UpdateConfig schema to support user configuration of coordinated updates.Discussion thread here: http://mail-archives.apache.org/mod_mbox/incubator-aurora-dev/201501.mbox/%3CCAOTkfX6%2BmKNryWEdDc9e0N_Chz_mQbB20Cyj_xdj6k2%3DsxJ-LQ%40mail.gmail.com%3E,2,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-1023,Bug,76,Resolved,Releasing the update lock trips off scheduler updater,"Here is the faulty sequence:- User starts a scheduler job update and pauses while it's still in progress- User runs ""aurora job cancel-update"" command thus releasing the update lock- User starts a new scheduler job updateAt this point any attempt to abort or pause an active update results in the following error [1]:{noformat}vagrant@vagrant-ubuntu-trusty-64:~$ aurora beta-update abort devcluster/www-data/prod/hello INFO] Aborting update for: devcluster/www-data/prod/helloFailed to abort update due to error:expected one element but was: <JobUpdateSummary(updateId:4b7fdc14-428f-44e4-9261-908b606f47e2 jobKey:JobKey(role:www-data environment:prod name:hello) user:UNSECURE state:JobUpdateState(status:ROLLING_FORWARD createdTimestampMs:1421450382234 lastModifiedTimestampMs:1421450382234)) JobUpdateSummary(updateId:3c9c2fa2-8e51-4c13-8440-94364205a37b jobKey:JobKey(role:www-data environment:prod name:hello) user:UNSECURE state:JobUpdateState(status:ROLL_FORWARD_PAUSED createdTimestampMs:1421450304935 lastModifiedTimestampMs:1421450324055))>{noformat}The only way to recover from this state is either wait for the active job update to reach terminal state or force it to it by running another cancel-update.While the ""cancel-update"" will eventually go away with the client updater we do have a problem during the migration period. A possible (though ugly) short-term workaround could be calling ""abortJobUpdate"" from the ""releaseLock"" RPC.[1] - https://github.com/apache/incubator-aurora/blob/master/src/main/java/org/apache/aurora/scheduler/updater/JobUpdateControllerImpl.java#L295-L296",5,2,2,1,0,Bill Farner,Maxim Khutornenko,Maxim Khutornenko,2,0,0,0,0,0,0,0
AURORA-872,Story,76,Resolved,0.7.0 Release Candidate,null,3,3,5,1,0,Maxim Khutornenko,Bill Farner,Bill Farner,2,0,17,16,16,0,0,0
AURORA-1008,Bug,76,Resolved,Pystachio section variables don't seem to work as described in the documentation,"At https://github.com/apache/incubator-aurora/blob/master/docs/configuration-tutorial.md#user-content-templating-1-binding-in-pystachio is described that you can use{code}{{#x}} Testing... {{/x}}{code}or{code}{ ""x"": [ { ""name"" : ""tic"" } { ""name"" : ""tac"" } { ""name"" : ""toe"" } ] }{{#x}} {{name}} {{/x}}{code}Example:{code}hello = Process(  name = 'hello'  cmdline = """"""    while true; do      echo hello world  {{#x}} if-statement {{/x}}      sleep 100    done  """""").bind(x = 1)task = SequentialTask(  processes = [hello]  resources = Resources(cpu = 1.0 ram = 128*MB disk = 128*MB))jobs = [Service( task = task cluster = 'gf-office' role = 'derfloh' environment = 'test' name = 'hello')]{code}If I try to upload a config that uses the above syntax I get a ""Error loading configuration: #x""(I'm using 0.6.0-incubating but the documentation for 0.6.0 and master is the same at that part so that shouldn't matter?)",null,3,2,1,0,Kevin Sweeney,Florian Pfeiffer,Florian Pfeiffer,1,0,1,0,0,0,0,0
AURORA-1090,Task,76,Resolved,Optimize or remove shard uniqueness check from StorageBackfill,We have noticed that during scheduler startup the operation there can be a significant amount of time spent between the following log lines:{noformat}Performing shard uniqueness sanity check.storage state machine transition PREPARED -> READY{noformat}Looking at what happens in the scheduler between those points the expensive operation seems to be {{guaranteeShardUniqueness}}.This operation aims to validate the integrity of the storage but its value is dubious.  There are many other things that could be done to validate integrity but they should probably not be done every time the scheduler loads its database.If the operation is kept it can be dramatically optimized.  It currently performs an O(n^2) scan of tasks and this could trivially be reduced to O\(n\).,2,2,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-1124,Bug,76,Resolved,Aurora beta-update status command is broken,"{noformat}$ aurora beta-update status devcluster/www-data/prod/helloCommand failure:Fatal error running command:Traceback (most recent call last):  File ""/usr/local/bin/aurora/apache/aurora/client/cli/__init__.py"" line 312 in _execute    result = noun.execute(context)  File ""/usr/local/bin/aurora/apache/aurora/client/cli/__init__.py"" line 390 in execute    return self.verbs[context.options.verb].execute(context)  File ""apache/aurora/client/cli/update.py"" line 253 in execute    context.log_response_and_raise(response)  File ""/usr/local/bin/aurora/apache/aurora/client/cli/context.py"" line 135 in log_response_and_raise    self.print_err(""\t%s"" % combine_messages(resp))  File ""/usr/local/bin/aurora/apache/aurora/client/base.py"" line 50 in combine_messages    return ' '.join([d.message for d in (response.details or [])])TypeError: sequence item 0: expected string NoneType found{noformat}The above happens due to this line [1] that attempts to match AuroraJobKey against thrift JobKey and results in a subsequent RPC call [2] failing with NPE.[1] - https://github.com/apache/incubator-aurora/blob/master/src/main/python/apache/aurora/client/cli/update.py#L243[2] - https://github.com/apache/incubator-aurora/blob/master/src/main/python/apache/aurora/client/cli/update.py#L252",null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-1094,Bug,76,Resolved,aurora cron start --open-browser fails with stacktrace,"Running {{aurora cron start <jobkey> --open-browser}} always fails with the following stack trace:{noformat} INFO]Fatal error running command:Traceback (most recent call last):  File ""/Users/zmanji/.tools-cache/home/aurora/tools/client/libexec/aurora-client/apache/aurora/client/cli/__init__.py"" line 312 in _execute    result = noun.execute(context)  File ""/Users/zmanji/.tools-cache/home/aurora/tools/client/libexec/aurora-client/apache/aurora/client/cli/__init__.py"" line 390 in execute    return self.verbs[context.options.verb].execute(context)  File ""/Users/zmanji/.tools-cache/home/aurora/tools/client/libexec/aurora-client/apache/aurora/client/cli/cron.py"" line 114 in execute    context.open_job_page(api context.options.job_spec)AttributeError: 'Namespace' object has no attribute 'job_spec'{noformat}",1,3,1,1,0,Zameer Manji,Zameer Manji,Zameer Manji,1,0,0,0,0,0,0,0
AURORA-1120,Task,76,Resolved,Add the ability to optionally create an unhooked version of the Aurora client api,In some cases it might be desirable for clients to explicitly ignore hooks (e.g. if hooks are managed out of band). To enable these use cases the client API factory should expose a parameter that controls whether a hooked or non-hooked API is returned.,2,3,1,1,0,Joshua Cohen,Joshua Cohen,Joshua Cohen,1,0,0,0,0,0,0,0
AURORA-1043,Bug,85,Resolved,/logconfig does not work when the scheduler is behind SSL,When the /logconfig endpoint is behind SSL the JavaScript console is filled with the following errors:{noformat} Mixed Content: The page at 'https://localhost/logconfig' was loaded over HTTPS but requested an insecure script 'http://ajax.googleapis.com/ajax/libs/jquery/1.10.1/jquery.min.js'. This request has been blocked; the content must be served over HTTPS.logconfig:4402 Uncaught ReferenceError: $ is not defined{noformat}As a result the endpoint does not work.,null,3,2,1,0,null,Zameer Manji,Zameer Manji,2,0,0,0,0,0,0,0
AURORA-810,Task,85,Resolved,Add an end-to-end test case for http basic auth,* Simple netrc-based* Including end-to-end tests,1,3,2,1,0,Kevin Sweeney,Chris Lambert,Chris Lambert,1,0,2,2,2,0,0,0
AURORA-723,Task,85,Resolved,Create design document for security code refactor,null,2,3,1,1,1,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-1026,Story,85,Resolved,Update observer to read checkpoint stream from sandbox,See AURORA-2014.,5,3,2,1,0,Brian Wickman,Chris Lambert,Chris Lambert,4,0,2,1,1,0,0,0
AURORA-1027,Story,85,Resolved,Update thermos cli to read checkpoint stream from sandbox,See AURORA-1024.,5,3,2,1,0,Brian Wickman,Chris Lambert,Chris Lambert,2,0,1,0,0,0,0,0
AURORA-809,Task,85,Resolved,Use Apache Shiro for HTTP authentication,* Wire in ShiroWebModule behind optional flag add ability to use shiro.ini + HTTP Basic Authentication* Create a ShiroAuthModule as an alternative to UnsecureAuthModule* Add a ShiroCapabilityValidator that delegates to Shiro (keeping compatibility with the existing CapabilityValidator API)* Expose flag for custom Realm implementation.,5,3,4,1,0,Kevin Sweeney,Chris Lambert,Chris Lambert,2,0,2,1,1,0,0,0
AURORA-808,Task,85,Resolved,Refactor the scheduler to allow authenticated subject-per-request,* Make SchedulerThriftInterface @RequestScoped* Make CapabilityValidator @RequestScoped* Move creation of all servlets into the GuiceServletContextListener Injector,2,3,2,1,0,Kevin Sweeney,Chris Lambert,Chris Lambert,3,0,0,0,0,0,0,0
AURORA-909,Story,85,Resolved,Differentiate between dynamic and static vetoes,We're making a decent effort at reducing the _cost_ of task scheduling operations abut have not yet invested in reducing the working set in a way that causes task scheduling to scale better.  Each scheduling attempt for each task is an O(n) operation where n is the number of offers.I would like to explore optimizations where we try to reduce the amount of redundant work performed in task scheduling.  Say for example we're trying to schedule a task that needs 2 CPUs and we only have offers with 1 CPU.  Each scheduling round will re-assess every offer despite the fact that the offers have not changed shape and will always be a mismatch (hereafter termed _static_ mismatches).  Instead we should try to skip over offers that are a static mismatch.  We could do this at the {{TaskGroup}} level since every element in a task group is by definition statically equivalent.  This means that jobs with a large number of instances could be scheduled very efficiently since the first task scheduling round could identify static mismatches reducing the working set in the next round.This is to contrast with _dynamic_ mismatches where a change in the tasks on a machine or other settings could make a previously-ineligible offer become a match.  The current sources of dynamic mismatches are limit constraints host maintenance modes and dedicated attributes.I propose we proceed in several steps re-evaluating after each:1. instrument the scheduler to better estimate the improvements2. avoid future (offer task group) evaluations when static mismatches are found3. avoid future (offer task group) evaluations when dynamic mismatches are found,8,3,3,1,0,Maxim Khutornenko,Bill Farner,Bill Farner,9,0,1,0,0,0,0,0
AURORA-1062,Task,85,Resolved,apache.aurora.executor.common.HealthChecker should export stats,Right now the HealthChecker status checker exports no stats.  It would be useful for things like number of consecutive health failures and most recent health check latency to be exported on a per task basis so that they could be monitored.,1,3,4,1,0,Brian Wickman,Brian Wickman,Brian Wickman,6,0,1,0,0,0,0,0
AURORA-1012,Task,85,Resolved,Update documentation to explain the scheduler heartbeat mechanism,TBD [~maximk],1,3,3,1,0,Maxim Khutornenko,Chris Lambert,Chris Lambert,1,0,0,0,0,0,0,0
AURORA-1093,Story,85,Resolved,Scheduler updates should be uniquely identified by jobKey + updateId,We should generalize the approach of dealing with scheduler updates by always uniquely identifying them by a new composite key that includes both jobKey and the updateId e.g.:{noformat}struct JobUpdateKey {  1: JobKey jobKey  2: string updateId}{noformat}The above approach would benefit us long term when it comes to implementing a fully functional REST API. Having both job key and update ID components in the URL will help us logically split authorization and application data layers. E.g.: in {{/api/updates/role/env/name/updateId}} the {{/role/env/name}} may be used for authorization whereas the {{updateId}} will remove the ambiguity from the data lookup.,8,3,2,1,0,Bill Farner,Maxim Khutornenko,Maxim Khutornenko,5,0,4,0,0,0,0,0
AURORA-1025,Story,85,Resolved,Update gc executor to read checkpoint stream from sandbox,This is an intermediate step necessary to retire the gc executor.  See AURORA-1024.,3,3,3,1,0,Brian Wickman,Chris Lambert,Chris Lambert,2,0,1,0,0,0,0,0
AURORA-1028,Story,85,Resolved,Export TASK_LOST source stats from Scheduler,Use the source and reason fields that are included in status updates (circa mesos 0.21) to produce log messages and exported counters.http://mesos.apache.org/blog/mesos-0-21-0-released/,5,3,2,1,0,Bill Farner,Chris Lambert,Chris Lambert,1,0,1,1,1,0,0,0
AURORA-1108,Bug,85,Resolved,The scheduler synchronously writes a backup while writing a snapshot to the replicated log,In the course of writing a snapshot to the replicated log the scheduler may block while writing a snapshot to the disk.  There is no need for this activity to be done synchronously and doing so causes the write lock to be unnecessarily held for an additional period of time.From StorageBackup.java:{code}    @Override    public Snapshot createSnapshot() {      Snapshot snapshot = delegate.createSnapshot();      if (clock.nowMillis() >= (lastBackupMs + backupIntervalMs)) {        save(snapshot);      }      return snapshot;    }{code}{{StorageBackup}} happens to be the unqualified binding to {{SnapshotStore<Snapshot>}} that is used in {{LogStorage}}.,3,2,2,1,0,Maxim Khutornenko,Bill Farner,Bill Farner,2,0,0,0,0,0,0,0
AURORA-1055,Task,85,Resolved,Remove LiveClusterState,It should be fully replaced by CachedClusterState now.,1,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-524,Story,85,Resolved,Preemptor should export more detailed statistics,Right now the scheduler exports general counters for preemption attempts that don't break out production vs. non-production attempts. Since the preemptor currently has no action available when asked to preempt a nonproduction task it will show a 100% failure rate. Export counters for preemptions attempted in favor of production tasks and their successes and failures.,3,3,2,1,0,Bill Farner,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-1134,Bug,85,Resolved,Quota checks are inaccurate for cron schedule updates,Cron job resources are treated as an addition rather than a replacement during cron schedule update. This leads to double counting of the updated schedule which creates a problem when a role is hovering around its quota limit. We need a new API in the QuotaManager to properly handle this case. Something like {{QuotaManager.checkCronUpdate()}} that would properly subtract existing cron schedule consumption before comparing against quota.,3,3,2,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,2,0,0,0,0,0,0,0
AURORA-1020,Bug,85,Resolved,"The --rollback-on-failure option is meaningless for ""aurora job restart""","The ""aurora job restart -h"" currently lists {{\--rollback-on-failure}} as supported option. It is not wired and has no meaning for the restarter.",null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-1001,Story,85,Resolved,Support Mesos TASK_ERROR state,0.21.0 introduced a TASK_ERROR state. Support this in the scheduler code (either by aliasing it to the existing TASK_LOST state or creating a new state machine entry).,2,2,3,1,0,Bill Farner,Kevin Sweeney,Kevin Sweeney,2,0,2,0,0,0,0,0
AURORA-1155,Bug,85,Resolved,GC executor broken / Insufficient automated testing,"Last week we deployed git revision e0e3f2e (https://github.com/apache/incubator-aurora/tree/e0e3f2e) onto our test cluster. For this revision all GC executor runs are failing:{code}WARNING: Logging before InitGoogleLogging() is written to STDERRI0224 15:00:23.165495 26402 fetcher.cpp:76] Fetching URI '/opt/thermos/bin/gc_executor.pex'I0224 15:00:23.165679 26402 fetcher.cpp:179] Copying resource from '/opt/thermos/bin/gc_executor.pex' to '/var/lib/mesos/slaves/20150218-102226-1985259712-5050-12423-S6/frameworks/20140919-174559-16842879-5050-27194-0000/executors/aurora.gc/runs/3f1813a3-76f7-4716-bd75-261d6187a2fc'Traceback (most recent call last):  File ""/var/lib/mesos/slaves/20150218-102226-1985259712-5050-12423-S6/frameworks/20140919-174559-16842879-5050-27194-0000/executors/aurora.gc/runs/3f1813a3-76f7-4716-bd75-261d6187a2fc/gc_executor.pex/.bootstrap/_pex/pex.py"" line 272 in execute    self.execute_entry(entry_point args)  File ""/var/lib/mesos/slaves/20150218-102226-1985259712-5050-12423-S6/frameworks/20140919-174559-16842879-5050-27194-0000/executors/aurora.gc/runs/3f1813a3-76f7-4716-bd75-261d6187a2fc/gc_executor.pex/.bootstrap/_pex/pex.py"" line 320 in execute_entry    runner(entry_point)  File ""/var/lib/mesos/slaves/20150218-102226-1985259712-5050-12423-S6/frameworks/20140919-174559-16842879-5050-27194-0000/executors/aurora.gc/runs/3f1813a3-76f7-4716-bd75-261d6187a2fc/gc_executor.pex/.bootstrap/_pex/pex.py"" line 342 in execute_pkg_resources    runner = entry.load(require=False)  # trust that the environment is sane  File ""/var/lib/mesos/slaves/20150218-102226-1985259712-5050-12423-S6/frameworks/20140919-174559-16842879-5050-27194-0000/executors/aurora.gc/runs/3f1813a3-76f7-4716-bd75-261d6187a2fc/gc_executor.pex/.bootstrap/pkg_resources.py"" line 2048 in load    entry = __import__(self.module_name globals()globals() ['__name__'])  File ""/var/lib/mesos/slaves/20150218-102226-1985259712-5050-12423-S6/frameworks/20140919-174559-16842879-5050-27194-0000/executors/aurora.gc/runs/3f1813a3-76f7-4716-bd75-261d6187a2fc/gc_executor.pex/apache/aurora/executor/bin/gc_executor_main.py"" line 27 in <module>ImportError: No module named executor_detector{code}For me this is an indication that the test infrastructure is missing an integration or end to end tests which thoroughly tests the GC executor.",null,2,3,1,0,Brian Wickman,Stephan Erb,Stephan Erb,8,0,0,0,0,0,0,0
AURORA-1043,Bug,92,Resolved,/logconfig does not work when the scheduler is behind SSL,When the /logconfig endpoint is behind SSL the JavaScript console is filled with the following errors:{noformat} Mixed Content: The page at 'https://localhost/logconfig' was loaded over HTTPS but requested an insecure script 'http://ajax.googleapis.com/ajax/libs/jquery/1.10.1/jquery.min.js'. This request has been blocked; the content must be served over HTTPS.logconfig:4402 Uncaught ReferenceError: $ is not defined{noformat}As a result the endpoint does not work.,null,3,2,1,0,null,Zameer Manji,Zameer Manji,2,0,0,0,0,0,0,0
AURORA-810,Task,92,Resolved,Add an end-to-end test case for http basic auth,* Simple netrc-based* Including end-to-end tests,1,3,2,1,0,Kevin Sweeney,Chris Lambert,Chris Lambert,1,0,2,2,2,0,0,0
AURORA-1158,Task,92,Resolved,Consider finding preemption slots asynchronously ,"The current Preemptor implementation performs synchronous preemption victim search. This isn't necessary as resource swap cannot be performed within the same scheduling loop due to victims taking time to vacate their premises (being killed). Consider asynchronous victim search/killing instead. That will move the heavy lifting out of the critical scheduling loop and remove ""flat"" preemptor perf tax applied on every failed task scheduling/assignment.  ",5,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,5,0,0,0,0,0,0,0
AURORA-1077,Task,92,Resolved,Allow message to be stored with update write events,It would be helpful to allow people to pass simple messages to updater actions such as pause and abort so that the update event log would be more useful. This would require modifying the RPC to take an extra message parameter wiring it into the DB schema and then exposing it to the client/UI. ,3,3,4,1,0,Bill Farner,David McLaughlin,David McLaughlin,7,1,1,0,0,0,0,0
AURORA-723,Task,92,Resolved,Create design document for security code refactor,null,2,3,1,1,1,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-1026,Story,92,Resolved,Update observer to read checkpoint stream from sandbox,See AURORA-2014.,5,3,2,1,0,Brian Wickman,Chris Lambert,Chris Lambert,4,0,2,1,1,0,0,0
AURORA-1097,Task,92,Resolved,Scheduler updater should suppress instance events on resume,Scheduler updater does not attempt to suppress redundant instance events in case an update is paused/blocked and is subsequently resumed/pulsed. This leads to a useless sequence of no-op instance events which may quickly consume the allocated event cap (tracked in AURORA-1096). For example an update paused/resumed 2 times after instance 1 is updated will generate the following instance sequence:1=[INSTANCE_UPDATING INSTANCE_UPDATED INSTANCE_UPDATING INSTANCE_UPDATED INSTANCE_UPDATING INSTANCE_UPDATED],2,4,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,1,0,0,0,0,0
AURORA-1027,Story,92,Resolved,Update thermos cli to read checkpoint stream from sandbox,See AURORA-1024.,5,3,2,1,0,Brian Wickman,Chris Lambert,Chris Lambert,2,0,1,0,0,0,0,0
AURORA-1156,Task,92,Resolved,Preemptor perf improvements,"There are two minor algorithm changes that should result in overall preemptor perf improvements:1. There seems to be a redundant scheduling attempt here: \[1\]. The preemptor loop is triggered within the same storage write lock right after a failed {{OfferManager.launchFirst()}} run that has already attempted to match all available offers. There is no reason to attempt another match given the same system conditions especially considering that a positive scheduling result from this loop is discarded anyway \[2\].2. Instead of running an expensive scheduling loop \[3\] for every task victim it's possible to ""size up"" victim resources and call scheduling filter only when rough resource estimates are sufficient. Something like:{noformat}if (totalResource.greaterOrEqualThan(ResourceSlot.from(pendingTask))) {  // call schedulingFilter}{noformat}\[1\] - https://github.com/apache/incubator-aurora/blob/master/src/main/java/org/apache/aurora/scheduler/async/preemptor/PreemptorImpl.java#L220-L237\[2\] - https://github.com/apache/incubator-aurora/blob/master/src/main/java/org/apache/aurora/scheduler/async/preemptor/PreemptorImpl.java#L338\[3\] - https://github.com/apache/incubator-aurora/blob/master/src/main/java/org/apache/aurora/scheduler/async/preemptor/PreemptorImpl.java#L263-L265",2,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-809,Task,92,Resolved,Use Apache Shiro for HTTP authentication,* Wire in ShiroWebModule behind optional flag add ability to use shiro.ini + HTTP Basic Authentication* Create a ShiroAuthModule as an alternative to UnsecureAuthModule* Add a ShiroCapabilityValidator that delegates to Shiro (keeping compatibility with the existing CapabilityValidator API)* Expose flag for custom Realm implementation.,5,3,4,1,0,Kevin Sweeney,Chris Lambert,Chris Lambert,2,0,2,1,1,0,0,0
AURORA-911,Story,92,Resolved,Scheduling vetos are only displayed for the first task in a TaskGroup,"When a task fails to schedule due not passing a resource or constraint {{Veto}} the entire {{TaskGroup}} is penalized but only the first task gets Veto reasons set. That leads to the UI displaying something like ""Insufficient disk"" veto reason only for one instance out of the similar pool of PENDING tasks. Consider sharing a {{Veto}} reason for all tasks in a group for improved troubleshooting and visibility. ",3,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,1,0,0,0,0,0
AURORA-1157,Task,92,Resolved,Add end-to-end test coverage for async updates,Our end-to-end test doesn't exercise scheduler-orchestrated job updates at all.,3,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-1173,Bug,92,Resolved,JobUpdateController.systemResume() is not called on scheduler startup anymore,I can reproduce this in Vagrant. The {{JobUpdateController.systemResume}} is not called on scheduler startup. This leads to all in-flight updates to getting stuck.,null,1,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,2,0,0,0,0,0,0,0
AURORA-1159,Task,92,Resolved,NearestFix does not account for certain veto types,Most of the current Veto types are scored with the same fixed MAX_SCORE value that prevents NearestFit to give proper attention to maintenance and constraint limit vetoes. Improved veto scoring should improve the pending reason quality reporting.,3,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-1170,Task,92,Resolved,Add more logging in MaintenanceController,Getting the following error occasionally when draining hosts for maintenance:{noformat}Failed to move all hosts into DRAINED within 5 mins{noformat}Need more logging around host attribute processing in MaintenanceController to help troubleshooting these types of issues.,null,3,2,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-1133,Bug,92,Resolved,Thermos Observer does not export stats via /vars,"The observer should be exporting executor stats via vars but this fails on Vagrant.{noformat}vagrant@aurora:~$ curl localhost:1338/vars    <!DOCTYPE HTML PUBLIC ""-//IETF//DTD HTML 2.0//EN"">    <html>        <head>            <title>Error: 404 Not Found</title>            <style type=""text/css"">              html {background-color: #eee; font-family: sans;}              body {background-color: #fff; border: 1px solid #ddd;                    padding: 15px; margin: 15px;}              pre {background-color: #eee; border: 1px solid #ddd; padding: 5px;}            </style>        </head>        <body>            <h1>Error: 404 Not Found</h1>            <p>Sorry the requested URL <tt>&#039;http://localhost:1338/vars&#039;</tt>               caused an error:</p>            <pre>Not found: &#039;/vars&#039;</pre>        </body>    </html>{noformat}I don't see any code that should be doing this.",null,3,4,1,0,Brian Wickman,Zameer Manji,Zameer Manji,5,0,1,0,0,0,0,0
AURORA-1043,Bug,100,Resolved,/logconfig does not work when the scheduler is behind SSL,When the /logconfig endpoint is behind SSL the JavaScript console is filled with the following errors:{noformat} Mixed Content: The page at 'https://localhost/logconfig' was loaded over HTTPS but requested an insecure script 'http://ajax.googleapis.com/ajax/libs/jquery/1.10.1/jquery.min.js'. This request has been blocked; the content must be served over HTTPS.logconfig:4402 Uncaught ReferenceError: $ is not defined{noformat}As a result the endpoint does not work.,null,3,2,1,0,null,Zameer Manji,Zameer Manji,2,0,0,0,0,0,0,0
AURORA-810,Task,100,Resolved,Add an end-to-end test case for http basic auth,* Simple netrc-based* Including end-to-end tests,1,3,2,1,0,Kevin Sweeney,Chris Lambert,Chris Lambert,1,0,2,2,2,0,0,0
AURORA-812,Task,100,Resolved,Wire in SPNEGO HTTP module,Wire in SPNEGO HTTP module expose as flags in ShiroAuthModule.,5,3,3,1,0,Kevin Sweeney,Chris Lambert,Chris Lambert,1,0,1,0,0,0,0,0
AURORA-813,Task,100,Resolved,Add ability to configure client to use Kerberos,Add ability to configure client to use Kerberos (depends on AURORA-812 can be developed in parallel).,3,3,3,1,0,Maxim Khutornenko,Chris Lambert,Chris Lambert,1,0,1,0,0,0,0,0
AURORA-1158,Task,100,Resolved,Consider finding preemption slots asynchronously ,"The current Preemptor implementation performs synchronous preemption victim search. This isn't necessary as resource swap cannot be performed within the same scheduling loop due to victims taking time to vacate their premises (being killed). Consider asynchronous victim search/killing instead. That will move the heavy lifting out of the critical scheduling loop and remove ""flat"" preemptor perf tax applied on every failed task scheduling/assignment.  ",5,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,5,0,0,0,0,0,0,0
AURORA-1187,Story,100,Resolved,Create JobKey-scoped Permissions and apply to AuroraSchedulerManager,https://reviews.apache.org/r/31820/ added support for coarse-grained permissions based on the thrift API method name. Support finer-grained permissions scoped down to the jobFor example calls to{code}auroraSchedulerManager.descheduleCronJob(JobKey(role='ksweeney' environment='prod' name='download_lunch_menu') None None){code}currently check for the {{thrift.AuroraSchedulerManager:descheduleCronJob}} Permission when they should check for the {{thrift.AuroraSchedulerManager:descheduleCronJob:ksweeney:prod:download_lunch_menu}} Permission.,5,3,2,1,0,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,3,0,1,1,1,0,0,0
AURORA-1160,Task,100,Resolved,Rename beta-update to update,Graduate the server-side job update orchestration out of beta by removing 'beta-' from the subcommand name.,2,3,3,1,0,Bill Farner,Bill Farner,Bill Farner,3,0,1,1,1,0,0,0
AURORA-1201,Bug,100,Resolved,auth_module is not installed in child injector,"The recent patch to enable HTTP Basic Authentication moved construction of ThriftAuthModule to the Jetty child injector but the user-supplied module was still installed in the parent injector. This leads to a stack trace for anyone using their own {{auth_module}}:{noformat}INFO: Connecting to master using authentication (principal: TwitterScheduler).Exception in thread ""main"" com.google.inject.CreationException: Guice creation errors:1) No implementation for java.util.Map<org.apache.aurora.auth.CapabilityValidator$Capability java.lang.String> was bound.  while locating java.util.Map<org.apache.aurora.auth.CapabilityValidator$Capability java.lang.String>    for parameter 1 at com.twitter.aurora.internal.auth.TwitterCapabilityValidator.<init>(TwitterCapabilityValidator.java:28)  at com.twitter.aurora.internal.auth.TwitterAuthModule.configure(TwitterAuthModule.java:97)2) No implementation for java.util.Map<org.apache.aurora.auth.CapabilityValidator$Capability java.lang.String> was bound.  at com.twitter.aurora.internal.auth.TwitterAuthModule.configure(TwitterAuthModule.java:94)2 errors        at com.google.inject.internal.Errors.throwCreationExceptionIfErrorsExist(Errors.java:435)        at com.google.inject.internal.InternalInjectorCreator.initializeStatically(InternalInjectorCreator.java:154)        at com.google.inject.internal.InternalInjectorCreator.build(InternalInjectorCreator.java:106)        at com.google.inject.Guice.createInjector(Guice.java:95)        at com.google.inject.Guice.createInjector(Guice.java:83)        at com.twitter.common.application.AppLauncher.configureInjection(AppLauncher.java:120)        at com.twitter.common.application.AppLauncher.run(AppLauncher.java:87)        at com.twitter.common.application.AppLauncher.launch(AppLauncher.java:181)        at com.twitter.common.application.AppLauncher.launch(AppLauncher.java:142)        at org.apache.aurora.scheduler.app.SchedulerMain.main(SchedulerMain.java:279){noformat}",2,1,1,1,0,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,1,0,1,1,1,0,0,0
AURORA-811,Task,100,Resolved,Add ShiroAopModule shiro AOP @RequiresPermissions annotations,Also:* Deprecate CapabilityValidator and its annotations and interceptors* Deprecate UnsecureAuthModule. * Deprecate SessionKey arguments in Thrift API.,3,3,3,1,0,Kevin Sweeney,Chris Lambert,Chris Lambert,2,0,0,0,0,0,0,0
AURORA-1174,Bug,100,Resolved,make-python-sdists failing on master,Commit 9791efc0a88dd0917dc45cb38d78255e3949e886 broke building the thermos client in make-python-sdists:{code}               Executing tasks in goals: setup-py17:01:03 00:00   [setup-py]17:01:03 00:00     [setup-py]                   /home/vagrant/aurora/dist/apache.thermos.z8KZGZ/src/apache/thermos/cli/common.py is source but does not belong to a package.                   /home/vagrant/aurora/dist/apache.thermos.z8KZGZ/src/apache/thermos/cli/main.py is source but does not belong to a package.                   /home/vagrant/aurora/dist/apache.thermos.z8KZGZ/src/apache/thermos/cli/commands/read.py is source but does not belong to a package.                   /home/vagrant/aurora/dist/apache.thermos.z8KZGZ/src/apache/thermos/cli/commands/inspect.py is source but does not belong to a package.                   /home/vagrant/aurora/dist/apache.thermos.z8KZGZ/src/apache/thermos/cli/commands/help.py is source but does not belong to a package.                   /home/vagrant/aurora/dist/apache.thermos.z8KZGZ/src/apache/thermos/cli/commands/simplerun.py is source but does not belong to a package.                   /home/vagrant/aurora/dist/apache.thermos.z8KZGZ/src/apache/thermos/cli/commands/kill.py is source but does not belong to a package.                   /home/vagrant/aurora/dist/apache.thermos.z8KZGZ/src/apache/thermos/cli/commands/run.py is source but does not belong to a package.                   /home/vagrant/aurora/dist/apache.thermos.z8KZGZ/src/apache/thermos/cli/commands/gc.py is source but does not belong to a package.                   /home/vagrant/aurora/dist/apache.thermos.z8KZGZ/src/apache/thermos/cli/commands/status.py is source but does not belong to a package.                   /home/vagrant/aurora/dist/apache.thermos.z8KZGZ/src/apache/thermos/cli/commands/tail.py is source but does not belong to a package.                   /home/vagrant/aurora/dist/apache.thermos.z8KZGZ/src/apache/thermos/cli/bin/thermos.py is source but does not belong to a package.               FAILUREException message: Invalid target PythonLibrary(BuildFileAddress(/home/vagrant/aurora/src/main/python/apache/thermos/BUILD thermos)): Cannot add a binary to a PythonArtifact if it does not contain an entry_point.{code},1,3,3,1,0,Zameer Manji,Steve Niemitz,Steve Niemitz,4,0,1,1,1,0,0,0
AURORA-1168,Task,100,Resolved,beta-update list should use a hierarchy for query specifications,{noformat}$ aurora beta-update list -husage: aurora beta-update list [-h] [--job CLUSTER/ROLE/ENV/NAME]                               [--role ROLENAME] [--user username]                               [--status {ROLLED_BACKROLL_FORWARD_PAUSEDROLL_FORWARD_AWAITING_PULSEERRORROLLING_BACKROLLING_FORWARDROLLED_FORWARDROLL_BACK_PAUSEDFAILEDABORTEDROLL_BACK_AWAITING_PULSE}]                               [--write-json] [--verbose]                               [--skip-hooks hookhook...]                               clustername{noformat}This means that to query for updates for a specific job one must use a command like this:{noformat}$ aurora beta-update list --job devcluster/vagrant/test/http_example devcluster{noformat}In addition to being redundant this is less user-friendly than the hierarchical syntax we use in other places.I suggest we change the client to drop the job and role options and instead support commands like:{noformat}aurora beta-update list clusteraurora beta-update list cluster/roleaurora beta-update list cluster/role/envaurora beta-update list cluster/role/env/job{noformat},3,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,1,1,1,1,0,0,0
AURORA-1031,Task,100,Resolved,Replace libmesos w/ Pesos,Replace the libmesos native dependency with [Pesos|https://github.com/wickman/pesos] to simplify the build and reduce memory footprint.,13,4,2,0,0,null,Chris Lambert,Chris Lambert,1,0,1,0,0,0,0,0
AURORA-1190,Story,100,Resolved,Add a deprecation warning when the client-side updater is used,This feature is being deprecated in 0.8.0 removed in 0.9.0,2,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-1206,Story,100,Resolved,Make update status command more versatile,The {{aurora update status}} command is rather restrictive only showing information about in-flight updates.  This command would be more useful if it could allow the same output for arbitrary updates (which can be discovered through {{aurora update list}}.To make the name match the new behavior i propose we name this command {{info}}.,2,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-1043,Bug,105,Resolved,/logconfig does not work when the scheduler is behind SSL,When the /logconfig endpoint is behind SSL the JavaScript console is filled with the following errors:{noformat} Mixed Content: The page at 'https://localhost/logconfig' was loaded over HTTPS but requested an insecure script 'http://ajax.googleapis.com/ajax/libs/jquery/1.10.1/jquery.min.js'. This request has been blocked; the content must be served over HTTPS.logconfig:4402 Uncaught ReferenceError: $ is not defined{noformat}As a result the endpoint does not work.,null,3,2,1,0,null,Zameer Manji,Zameer Manji,2,0,0,0,0,0,0,0
AURORA-810,Task,105,Resolved,Add an end-to-end test case for http basic auth,* Simple netrc-based* Including end-to-end tests,1,3,2,1,0,Kevin Sweeney,Chris Lambert,Chris Lambert,1,0,2,2,2,0,0,0
AURORA-812,Task,105,Resolved,Wire in SPNEGO HTTP module,Wire in SPNEGO HTTP module expose as flags in ShiroAuthModule.,5,3,3,1,0,Kevin Sweeney,Chris Lambert,Chris Lambert,1,0,1,0,0,0,0,0
AURORA-813,Task,105,Resolved,Add ability to configure client to use Kerberos,Add ability to configure client to use Kerberos (depends on AURORA-812 can be developed in parallel).,3,3,3,1,0,Maxim Khutornenko,Chris Lambert,Chris Lambert,1,0,1,0,0,0,0,0
AURORA-1158,Task,105,Resolved,Consider finding preemption slots asynchronously ,"The current Preemptor implementation performs synchronous preemption victim search. This isn't necessary as resource swap cannot be performed within the same scheduling loop due to victims taking time to vacate their premises (being killed). Consider asynchronous victim search/killing instead. That will move the heavy lifting out of the critical scheduling loop and remove ""flat"" preemptor perf tax applied on every failed task scheduling/assignment.  ",5,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,5,0,0,0,0,0,0,0
AURORA-1187,Story,105,Resolved,Create JobKey-scoped Permissions and apply to AuroraSchedulerManager,https://reviews.apache.org/r/31820/ added support for coarse-grained permissions based on the thrift API method name. Support finer-grained permissions scoped down to the jobFor example calls to{code}auroraSchedulerManager.descheduleCronJob(JobKey(role='ksweeney' environment='prod' name='download_lunch_menu') None None){code}currently check for the {{thrift.AuroraSchedulerManager:descheduleCronJob}} Permission when they should check for the {{thrift.AuroraSchedulerManager:descheduleCronJob:ksweeney:prod:download_lunch_menu}} Permission.,5,3,2,1,0,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,3,0,1,1,1,0,0,0
AURORA-1043,Bug,112,Resolved,/logconfig does not work when the scheduler is behind SSL,When the /logconfig endpoint is behind SSL the JavaScript console is filled with the following errors:{noformat} Mixed Content: The page at 'https://localhost/logconfig' was loaded over HTTPS but requested an insecure script 'http://ajax.googleapis.com/ajax/libs/jquery/1.10.1/jquery.min.js'. This request has been blocked; the content must be served over HTTPS.logconfig:4402 Uncaught ReferenceError: $ is not defined{noformat}As a result the endpoint does not work.,null,3,2,1,0,null,Zameer Manji,Zameer Manji,2,0,0,0,0,0,0,0
AURORA-1231,Story,112,Resolved,Blocked updates missing from cluster-wide in progress view,In the /updates endpoint updates that are in ROLL_FORWARD_AWAITING_PULSE state are not included under in progress updates. ,2,3,2,1,0,Bill Farner,David McLaughlin,David McLaughlin,1,0,0,0,0,0,0,0
AURORA-817,Task,112,Resolved,Add documentation for HTTP basic and kerberos authentication,Add a new markdown page linked from {{deploying-aurora-scheduler.md}} that offers instructions for using HTTP basic authentication for the web UI and API as well as an example for integrating with kerberos.,2,3,4,1,0,Kevin Sweeney,Bill Farner,Bill Farner,1,1,2,2,2,0,0,0
AURORA-556,Task,112,Resolved,H2-backed implementation of TaskStore,This tracks behavior matching but not necessarily performance.,null,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,2,0,1,0,0,0,0,0
AURORA-1214,Task,112,Resolved,"Reevaluate ""max_schedule_attempts_per_sec"" with asynchronous preemptor",With step 2 of AURORA-1158 completed the preemptor is removed from the critical scheduling loop making scheduling much faster (perf comparison is available here: https://reviews.apache.org/r/32225/)Reevaluate what the {{max_schedule_attempts_per_sec}} should be now. ,2,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-1219,Task,112,Resolved,Improve preemptor efficiency,While AURORA-1158 makes the preemptor asynchronous and helps scheduling loop performance it loses some preemption efficiency due to adapting the original algorithm to work asynchronously:- Preemptor repeatedly searches for preemption slots with the same ClusterState increasing the probability of victim collisions. - Slave/offer/resource mappings are redundantly recomputed for every pending task slot search.- Pending tasks are repeatedly sized up against every slave (as opposed to the other way around) making internal loop optimizations more expensive (i.e. pending task count is expected to be << slave count under normal conditions).,5,3,2,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,2,0,0,0,0,0,0,0
AURORA-1043,Bug,117,Resolved,/logconfig does not work when the scheduler is behind SSL,When the /logconfig endpoint is behind SSL the JavaScript console is filled with the following errors:{noformat} Mixed Content: The page at 'https://localhost/logconfig' was loaded over HTTPS but requested an insecure script 'http://ajax.googleapis.com/ajax/libs/jquery/1.10.1/jquery.min.js'. This request has been blocked; the content must be served over HTTPS.logconfig:4402 Uncaught ReferenceError: $ is not defined{noformat}As a result the endpoint does not work.,null,3,2,1,0,null,Zameer Manji,Zameer Manji,2,0,0,0,0,0,0,0
AURORA-1311,Task,117,Resolved,Upgrade to latest h2 version,We have been holding back on upgrading h2 since the latest release are labeled as beta.  As it turns out the beta marker only applies to the new default MVCC storage implementation and the developers consider the builds stable when MV_STORE is disabled \[1\].\[1\] https://groups.google.com/forum/#!topic/h2-database/3CDRKex_EgA,1,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,1,1,1,0,0,0
AURORA-1277,Task,117,Resolved,Create a design document for Health Checks for Updates,null,5,3,2,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,2,0,0,0,0,0,0,0
AURORA-1231,Story,117,Resolved,Blocked updates missing from cluster-wide in progress view,In the /updates endpoint updates that are in ROLL_FORWARD_AWAITING_PULSE state are not included under in progress updates. ,2,3,2,1,0,Bill Farner,David McLaughlin,David McLaughlin,1,0,0,0,0,0,0,0
AURORA-817,Task,117,Resolved,Add documentation for HTTP basic and kerberos authentication,Add a new markdown page linked from {{deploying-aurora-scheduler.md}} that offers instructions for using HTTP basic authentication for the web UI and API as well as an example for integrating with kerberos.,2,3,4,1,0,Kevin Sweeney,Bill Farner,Bill Farner,1,1,2,2,2,0,0,0
AURORA-1307,Bug,117,Resolved,API hooks no longer supported for certain client commands,Certain client commands (e.g. job kill job killall update start) no longer passing aurora config to their correspondent api calls. This makes it impossible to use API level hooks. ,3,3,2,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-1291,Story,117,Resolved,Replace enable_api_security arg with a value for http_authentication_mechanism,Enabling API security involves minimally setting 2 args:{noformat}-enable_api_security=true-http_authentication_mechanism=BASIC{noformat}This could open the possibility of confusing combinations of arguments that may behave in unexpected ways or not work at all.  Remove {{enable_api_security}} in favor of {{-http_authentication_mechanism=NONE}} to be the default value.,1,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,2,0,1,0,0,0,0,0
AURORA-1290,Story,117,Resolved,"Allow specifying a shorthand for ""well-known"" Module FQCNs",Right now you have to type some pretty verbose stuff to setup security.{noformat}-shiro_realm_modules=org.apache.aurora.scheduler.http.api.security.Kerberos5ShiroRealmModuleorg.apache.aurora.scheduler.http.api.security.IniShiroRealmModulecom.example.CustomRealmModule{noformat}This is ugly and not very refactor-safe. Consider adding mappings for well-known names with fallback to FQCNs.Thus the previous example could become{noformat}-shiro_realm_modules=KERBEROS5_AUTHNINI_AUTHNZcom.example.CustomRealmModule{noformat}This points out one possible weird misconfiguration:{noformat}-shiro_realm_modules=KERBEROS5_AUTHNINI_AUTHNZ-http_authentication_mechanism=BASIC{noformat}will leave the Kerberos code completely dark and pass the Basic auth credentials to IniRealm. Thus as a followup we should probably create separate INI_AUTHN and INI_AUTHZ realms that will only participate in one phase.,1,3,2,1,0,Bill Farner,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-1248,Bug,117,Resolved,Client retries 4xx errors,Looks like the client currently retries all client errors including 4xx ones. For example using a client against a scheduler that requires Kerberos there's a series of lines like:{noformat} WARN] Connection error with scheduler: Unknown error talking to http://192.168.33.7:8081/api: 401 Client Error: Unauthorized reconnecting... WARN] Connection error with scheduler: Unknown error talking to http://192.168.33.7:8081/api: 401 Client Error: Unauthorized reconnecting... WARN] Connection error with scheduler: Unknown error talking to http://192.168.33.7:8081/api: 401 Client Error: Unauthorized reconnecting......{noformat},3,3,2,1,0,Bill Farner,Kevin Sweeney,Kevin Sweeney,2,0,0,0,0,0,0,0
AURORA-716,Story,117,Resolved,Reconsider default for -require_slave_checkpoint,Given that slave recovery has been stable in mesos for a very long time it's worth reassessing the default value of this flag [1] (or maybe removing it altogether).https://github.com/apache/incubator-aurora/blob/master/src/main/java/org/apache/aurora/scheduler/DriverFactory.java#L75-L101,1,2,3,1,0,Bill Farner,Kevin Sweeney,Kevin Sweeney,4,0,2,1,1,0,0,0
AURORA-195,Task,117,Resolved,"remove legacy remnants of ""aurora"" executor",e.g. in {{src/main/python/apache/aurora/client/api/command_runner.py}} - {{aurora_sandbox}} {{substitute_aurora}} etc,1,4,3,1,0,Bill Farner,Jonathan Boulle,Jonathan Boulle,1,0,0,0,0,0,0,0
AURORA-1299,Story,117,Resolved,UpdateConfigError results in stack trace,"{noformat}$ aurora update start devcluster/vagrant/test/http_example /vagrant/src/test/sh/org/apache/aurora/e2e/http/http_example.auroraFatal error running command: Pulse interval seconds must be at least 60 seconds.Traceback (most recent call last):  File ""/usr/local/bin/aurora/apache/aurora/client/cli/__init__.py"" line 307 in _execute    result = noun.execute(context)  File ""/usr/local/bin/aurora/apache/aurora/client/cli/__init__.py"" line 383 in execute    return self.verbs[context.options.verb].execute(context)  File ""/usr/local/bin/aurora/apache/aurora/client/cli/update.py"" line 158 in execute    resp = api.start_job_update(config context.options.message instances)  File ""/usr/local/bin/aurora/apache/aurora/client/hooks/hooked_api.py"" line 190 in start_job_update    config message instances=instances))  File ""/usr/local/bin/aurora/apache/aurora/client/hooks/hooked_api.py"" line 145 in _hooked_call    resp = api_call()  File ""/usr/local/bin/aurora/apache/aurora/client/api/__init__.py"" line 165 in start_job_update    raise self.UpdateConfigError(str(e))UpdateConfigError: Pulse interval seconds must be at least 60 seconds.{noformat}",2,4,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-1301,Bug,117,Resolved,Tests inheriting from AuroraClientCommandTest always pass,The test case below should fail but it always passes.{noformat}$ git diffdiff --git a/src/test/python/apache/aurora/client/cli/test_supdate.py b/src/test/python/apache/aurora/client/cli/test_supdate.pyindex ccbcae6..e76681f 100644--- a/src/test/python/apache/aurora/client/cli/test_supdate.py+++ b/src/test/python/apache/aurora/client/cli/test_supdate.py@@ -1116 +1119 @@ class TestStartUpdate(AuroraClientCommandTest):     ]     self.assert_lock_message(self._fake_context) +  def test_always_passes(self):+    assert 1 == 0+   def test_update_cron_job_fails(self):     mock_config = self.create_mock_config(is_cron=True)     self._fake_context.get_job_config = Mock(return_value=mock_config){noformat}{noformat}$ ./pants test.pytest --no-fast --options='-v' src/test/python/apache/aurora/client/cli:supdate | tail -n1               SUCCESS{noformat},1,2,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-1259,Task,117,Resolved,Add metrics for scheduler update states,It would be nice to expose metrics to track the terminal states of updates. E.g. update_status_FAILED update_status_ROLLED_BACK update_status_ROLLED_FORWARD etc. ,2,3,2,1,0,Bill Farner,David McLaughlin,David McLaughlin,1,0,0,0,0,0,0,0
AURORA-1204,Story,117,Resolved,Update upstart configurations when syncing sources,In the vagrant environment we perform a step where we copy the upstart configurations to /etc/init \[1\].  The way this is done makes it challenging to change the upstart configurations later the easiest way being to destroy and re-create the environment.  Consider updating these files that their definitions are updated by rsync along with other code.\[1\] https://github.com/apache/incubator-aurora/blob/ad211da2f2490722a10cce95a2bb4fb55fd1c16f/examples/vagrant/provision-dev-cluster.sh#L60-L61,2,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-1305,Story,117,Resolved,MemTaskStore: items are not removed from secondary index,An updated PMD flagged this bug (see output below).This line:{code}index.remove(key task);{code}should be:{code}index.remove(key Tasks.id(task));{code}{noformat}CodeWarningGCorg.apache.aurora.scheduler.storage.entities.IScheduledTask is incompatible with expected argument type String in org.apache.aurora.scheduler.storage.mem.MemTaskStore$SecondaryIndex.remove(IScheduledTask)Bug type GC_UNRELATED_TYPES (click for details) In class org.apache.aurora.scheduler.storage.mem.MemTaskStore$SecondaryIndexIn method org.apache.aurora.scheduler.storage.mem.MemTaskStore$SecondaryIndex.remove(IScheduledTask)Actual type org.apache.aurora.scheduler.storage.entities.IScheduledTaskExpected StringCalled method com.google.common.collect.Multimap.remove(Object Object)Invoked on org.apache.aurora.scheduler.storage.mem.MemTaskStore$SecondaryIndex.indextask passed as argumentorg.apache.aurora.scheduler.storage.entities.IScheduledTask.equals(Object) used to determine equalityAt MemTaskStore.java:[line 399]{noformat},2,4,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,1,1,1,0,0,0
AURORA-1306,Story,117,Resolved,Upgrade to gradle 2.4,Gradle 2.4 is out.  Among other things it claims to offer improved performance:http://gradle.org/docs/2.4/release-notes,2,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,1,1,1,0,0,0
AURORA-1239,Task,117,Resolved,Add a way to watch a scheduler-driven update until it's complete,It would be nice for scripts that coordinate updates to have the ability to watch a scheduler-driven update until it has completed. This is currently possible by scripting the client e.g. https://github.com/apache/aurora/blob/master/src/test/sh/org/apache/aurora/e2e/test_end_to_end.sh#L149-L166 however given this is likely a common requirement we should encapsulate this functionality within the client itself.Two suggestions are adding {{aurora update watch ...}} or {{aurora update status --watch ...}}.The command should periodically poll the scheduler for the status of the update and exit 0 for successful updates and 1 for failed updates.,3,3,4,1,0,Bill Farner,Joshua Cohen,Joshua Cohen,3,1,0,0,0,0,0,0
AURORA-1309,Bug,117,Resolved,Build can fail if repo directory absolute path is too long,See https://github.com/pypa/pip/issues/1773This manifests as pip failing:{noformat}/home/wfarner/code/aurora/apache-aurora-0.8.0-rc0-verify/apache-aurora-0.8.0-rc0/build-support/python/isort: /home/wfarner/code/aurora/apache-aurora-0.8.0-rc0-verify/apache-aurora-0.8.0-rc0/build-support/python/isort.venv/bin/pip: /home/wfarner/code/aurora/apache-aurora-0.8.0-rc0-verify/apache-aurora-0.8.0-: bad interpreter: No such file or directory{noformat},2,5,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-1310,Story,117,Resolved,Remove blanket 'Error executing command: ' prefix from client output,When `CommandError` is caught in the client it prints a generic error prefix which is not helpful.  We should strive to make our error messages contextual and stand on their own.,1,5,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-1315,Bug,117,Resolved,UpdateStoreBenchmarks broken,Broken by AURORA-1305 as DbModule now requires a StatsProvider binding which UpdateStoreBenchmarks lacks.,1,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,1,1,1,0,0,0
AURORA-1298,Story,117,Resolved,Make DbTaskStore suitable for use in production,The DbTaskStore implementation has so far only targeted behavioral compliance with InMemTaskStore.  Use benchmarks to determine areas that require perf improvements and address them.  Also address relevant TODOs that should be production showstoppers.,5,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,4,0,0,0,0,0,0,0
AURORA-556,Task,117,Resolved,H2-backed implementation of TaskStore,This tracks behavior matching but not necessarily performance.,null,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,2,0,1,0,0,0,0,0
AURORA-1043,Bug,127,Resolved,/logconfig does not work when the scheduler is behind SSL,When the /logconfig endpoint is behind SSL the JavaScript console is filled with the following errors:{noformat} Mixed Content: The page at 'https://localhost/logconfig' was loaded over HTTPS but requested an insecure script 'http://ajax.googleapis.com/ajax/libs/jquery/1.10.1/jquery.min.js'. This request has been blocked; the content must be served over HTTPS.logconfig:4402 Uncaught ReferenceError: $ is not defined{noformat}As a result the endpoint does not work.,null,3,2,1,0,null,Zameer Manji,Zameer Manji,2,0,0,0,0,0,0,0
AURORA-1322,Bug,127,Resolved,DB task store is enabled by default when staging a recovery,The new DB task store implementation is turned on by default for the TemporaryStorage since it uses a unit test DB init path (1). This makes recovery from backup impossible if there is any task data triggering constraint violations during staging a recovery from backup file. (1) - https://github.com/apache/aurora/blob/65df91bfd7e3a2ada38a5fe4d620e6373d0f59bf/src/main/java/org/apache/aurora/scheduler/storage/backup/TemporaryStorage.java#L69,2,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-1311,Task,127,Resolved,Upgrade to latest h2 version,We have been holding back on upgrading h2 since the latest release are labeled as beta.  As it turns out the beta marker only applies to the new default MVCC storage implementation and the developers consider the builds stable when MV_STORE is disabled \[1\].\[1\] https://groups.google.com/forum/#!topic/h2-database/3CDRKex_EgA,1,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,1,1,1,0,0,0
AURORA-698,Bug,127,Resolved,aurora executor _shutdown deadline calls should be daemonized,In the aurora executor shutdown method we have deadline() calls:{noformat}  def _shutdown(self status_result):    runner_status = self._runner.status    try:      deadline(self._runner.stop timeout=self.STOP_TIMEOUT)    except Timeout:      log.error('Failed to stop runner within deadline.')    try:      deadline(self._chained_checker.stop timeout=self.STOP_TIMEOUT)    except Timeout:      log.error('Failed to stop all checkers within deadline.')    # If the runner was alive when _shutdown was called defer to the status_result    # otherwise the runner's terminal state is the preferred state.    exit_status = runner_status or status_result    self.send_update(        self._driver        self._task_id        exit_status.status        status_result.reason)    self.terminated.set()    defer(self._driver.stop delay=self.PERSISTENCE_WAIT){noformat}However if runner.stop fails with a Timeout exception the spawned AnonymousThread is not daemonized and causes the executor to fail to exit.  This means that the cgroup will not be torn down and if the runner.stop actually failed the process can stay alive even if TASK_KILLED was delivered.,1,3,2,1,0,Brian Wickman,Brian Wickman,Brian Wickman,1,0,0,0,0,0,0,0
AURORA-1318,Task,127,Resolved,Benchmark snapshot restore,Details TBD by [~kevints],3,3,2,1,0,Kevin Sweeney,Chris Lambert,Chris Lambert,1,0,0,0,0,0,0,0
AURORA-1047,Task,127,Resolved,Implement state reconciliation within the scheduler,null,8,3,5,1,0,Maxim Khutornenko,Brian Wickman,Brian Wickman,10,0,4,4,4,0,0,0
AURORA-556,Task,127,Resolved,H2-backed implementation of TaskStore,This tracks behavior matching but not necessarily performance.,null,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,2,0,1,0,0,0,0,0
AURORA-1228,Task,127,Resolved,Use explicit status update acknowledgements to improve driver throughput.,Mesos 0.22.0 is released and includes the ability for schedulers to perform explicit acknowledgments of status updates.This allows schedulers to process status updates asynchronously from the driver thread. Updates can then be processed in batches to reduce the per-update processing overhead. These should help provide substantial improvements to the schedulers update processing throughput.I've placed this under the GC executor retirement effort per AURORA-1047.,null,3,3,1,0,Benjamin Mahler,Benjamin Mahler,Benjamin Mahler,4,0,3,3,3,0,0,0
AURORA-1321,Bug,127,Resolved,Create bulk version of the saveJobInstanceUpdateEvent db store method,Perf analysis revealed unsatisfactory performance of the job update instance insertion implementation during snapshot recovery. It may take up to 5 minutes to process a total of ~100K instance events during scheduler restart. Implement and benchmark the bulk insert version of this api: https://github.com/apache/aurora/blob/b436ec52101cfd5d6f65075a5f7a857ed5a41b5f/src/main/java/org/apache/aurora/scheduler/storage/JobUpdateStore.java#L152,5,3,2,0,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,4,0,1,0,0,0,0,0
AURORA-274,Story,127,Resolved,Use JDK8 features in scheduler development,null,2,4,2,1,0,Bill Farner,Kevin Sweeney,Kevin Sweeney,2,0,1,0,0,0,0,0
AURORA-1296,Bug,127,Resolved,INSTANCES_SPEC_ARGUMENT client option does not validate instance range,"An of order instance range (e.g. ""/10-2"") results in empty list of instances. In case of a scheduler updater this leads to updating the entire job instead of specific instances.The offending line: https://github.com/apache/aurora/blob/439a168f9cdd6fe58a12009b51bedad4ac152948/src/main/python/apache/aurora/client/cli/options.py#L74",2,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,2,0,0,0,0,0,0,0
AURORA-1267,Task,127,Resolved,Investigate upgrading pants to 0.0.32+,"A naive upgrade to pants 0.0.32 from 0.0.28 results in the following stack trace:{noformat}Exception caught:  File ""/Users/zmanji/workspace/gh-aurora/build-support/pants.venv/bin/pants"" line 9 in <module>    load_entry_point('pantsbuild.pants==0.0.28' 'console_scripts' 'pants')()  File ""/Users/zmanji/workspace/gh-aurora/build-support/pants.venv/lib/python2.7/site-packages/pants/bin/pants_exe.py"" line 66 in main    _run()  File ""/Users/zmanji/workspace/gh-aurora/build-support/pants.venv/lib/python2.7/site-packages/pants/bin/pants_exe.py"" line 61 in _run    result = goal_runner.run()  File ""/Users/zmanji/workspace/gh-aurora/build-support/pants.venv/lib/python2.7/site-packages/pants/bin/goal_runner.py"" line 168 in run    result = self._do_run()  File ""/Users/zmanji/workspace/gh-aurora/build-support/pants.venv/lib/python2.7/site-packages/pants/bin/goal_runner.py"" line 251 in _do_run    return engine.execute(context self.goals)  File ""/Users/zmanji/workspace/gh-aurora/build-support/pants.venv/lib/python2.7/site-packages/pants/engine/engine.py"" line 27 in execute    self.attempt(context goals)  File ""/Users/zmanji/workspace/gh-aurora/build-support/pants.venv/lib/python2.7/site-packages/pants/engine/round_engine.py"" line 212 in attempt    goal_executor.attempt(explain)  File ""/Users/zmanji/workspace/gh-aurora/build-support/pants.venv/lib/python2.7/site-packages/pants/engine/round_engine.py"" line 45 in attempt    task.execute()  File ""/Users/zmanji/workspace/gh-aurora/build-support/pants.venv/lib/python2.7/site-packages/pants/backend/codegen/tasks/code_gen.py"" line 117 in execute    self.genlang(lang invalid_lang_tgts)  File ""/Users/zmanji/workspace/gh-aurora/build-support/pants.venv/lib/python2.7/site-packages/pants/backend/codegen/tasks/apache_thrift_gen.py"" line 152 in genlang    gen = self.gen_python.gen  File ""/Users/zmanji/workspace/gh-aurora/build-support/pants.venv/lib/python2.7/site-packages/pants/backend/codegen/tasks/apache_thrift_gen.py"" line 127 in gen_python    self._gen_python = self.create_geninfo('python')  File ""/Users/zmanji/workspace/gh-aurora/build-support/pants.venv/lib/python2.7/site-packages/pants/backend/codegen/tasks/apache_thrift_gen.py"" line 101 in create_geninfo    gen = gen_info['gen']Exception message: 'NoneType' object has no attribute '__getitem__'{noformat}The root cause of this is pants 0.0.32 expects a differently formatted {{pants.ini}} than the one we have now. Pants 0.0.32 ships with a migration tool that informs us of changes required. With a 0.0.32 pants source we can run:{noformat} PANTS_DEV=1 ./pants run src/python/pants/option:migrate_config -- <pants.ini path>{noformat}This gives us:{noformat}Found java in section [thrift-gen]. Should be java in section [gen.thrift].Found extra_jvm_test_paths in section [ide]. Should be extra_jvm_test_paths in section [idea].  Note: extra_jvm_test_paths now must be specified separately for idea and eclipse goals.Found python_test_paths in section [ide]. Should be python_test_paths in section [idea].  Note: python_test_path now must be specified separately for idea and eclipse goals.Found python_lib_paths in section [ide]. Should be python_lib_paths in section [idea].  Note: python_lib_path now must be specified separately for idea and eclipse goals.Found python in section [thrift-gen]. Should be python in section [gen.thrift].Found strict in section [thrift-gen]. Should be strict in section [gen.thrift].Found supportdir in section [thrift-gen]. Should be supportdir in section [gen.thrift].Found python_source_paths in section [ide]. Should be python_source_paths in section [idea].Found version in section [thrift-gen]. Should be version in section [gen.thrift].Found requirements in section [python-ipython]. Should be ipython_requirements in section [repl.py].Found indices in section [python-repos]. Should be indexes in section [python-repos].Found extra_jvm_source_paths in section [ide]. Should be extra_jvm_source_paths in section [idea].  Note: extra_jvm_source_paths now must be specified separately for idea and eclipse goals.{noformat}Making the above changes to {{pants.ini}} results in some commands failing with {{Unable to detect a suitable interpreter}}. It isn't clear what needs to be done to fix that error. I suspect it has to do with some of the constraints in our {{pants.ini}} but I cannot determine which ones are at fault.",null,3,2,1,0,Kevin Sweeney,Zameer Manji,Zameer Manji,1,0,1,0,0,0,0,0
AURORA-1325,Bug,127,Resolved,`src/test/python/apache/aurora/api_util.py` is not apart of any pants targets,There is no pants target which lists `src/test/python/apache/aurora/api_util.py` as a source file. `src/test/python/apache/aurora/BUILD` just contains:{noformat}python_test_suite(  name = 'all'  dependencies = [    'src/test/python/apache/aurora/admin:all'    'src/test/python/apache/aurora/client:all'    'src/test/python/apache/aurora/common:all'    'src/test/python/apache/aurora/config:all'    'src/test/python/apache/aurora/executor:all'  ]){noformat}Improper source dependency specification can cause us some trouble if we are not careful it is probably best to move this file closer to where it is used.,1,4,1,1,0,Zameer Manji,Zameer Manji,Zameer Manji,1,0,0,0,0,0,0,0
AURORA-1043,Bug,131,Resolved,/logconfig does not work when the scheduler is behind SSL,When the /logconfig endpoint is behind SSL the JavaScript console is filled with the following errors:{noformat} Mixed Content: The page at 'https://localhost/logconfig' was loaded over HTTPS but requested an insecure script 'http://ajax.googleapis.com/ajax/libs/jquery/1.10.1/jquery.min.js'. This request has been blocked; the content must be served over HTTPS.logconfig:4402 Uncaught ReferenceError: $ is not defined{noformat}As a result the endpoint does not work.,null,3,2,1,0,null,Zameer Manji,Zameer Manji,2,0,0,0,0,0,0,0
AURORA-1337,Task,131,Resolved,aurora executor should write checkpoints into sandbox,The thermos observer dual reads from /var/run/thermos and from the sandbox.  The executor should start writing checkpoints to the sandbox by default now that 0.8.0 has been released.,5,3,2,1,0,Maxim Khutornenko,Brian Wickman,Brian Wickman,1,0,0,0,0,0,0,0
AURORA-1287,Task,131,Resolved,Scheduler in-memory DB needs a direct console access,We need a direct way of getting to scheduler SQL data for troubleshooting and ad-hoc analysis purposes. Consider adding support for H2 web console: http://www.h2database.com/html/quickstart.html. The ideal solution should have a way to expose data in read-only and read-write mode depending on the connection/credential settings.,5,3,2,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-1322,Bug,131,Resolved,DB task store is enabled by default when staging a recovery,The new DB task store implementation is turned on by default for the TemporaryStorage since it uses a unit test DB init path (1). This makes recovery from backup impossible if there is any task data triggering constraint violations during staging a recovery from backup file. (1) - https://github.com/apache/aurora/blob/65df91bfd7e3a2ada38a5fe4d620e6373d0f59bf/src/main/java/org/apache/aurora/scheduler/storage/backup/TemporaryStorage.java#L69,2,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-1341,Task,131,Resolved,Use TaskStatus reason field to populate the memory limit exceeded field in UserTaskLauncher,Now that MESOS-343 is complete the reason field can be used to determine if the memory limit exceeded message should be displayed to the user.,null,4,1,1,0,Zameer Manji,Zameer Manji,Zameer Manji,1,0,0,0,0,0,0,0
AURORA-1352,Story,139,Resolved,Audit log doesn't capture Shiro subject principal,Scheduler RPCs that were authenticated by Shiro show UNSECURE in their audit messages.,3,3,1,1,0,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,5,0,2,1,1,0,0,0
AURORA-1139,Task,139,Resolved,Remove backwards compatibility shims from JobUpdateKey introduction,AURORA-1093 introduced several shims to support data migration across the 0.8.0 barrier.  These should be removed.- Remove JobUpdateSummary.updateId and jobKey- Remove JobUpdateQuery.updateId- Remove recovery-time update id -> update key lookup in LogStorage- Remove JobUpdateStore.fetchUpdateKey- Remove JobUpdateDetailsMapper.selectUpdateKey- Remove SaveJobUpdateEvent.updateId- Change {{UNIQUE(update_id)}} constraint to {{UNIQUE(job_key_id update_id)}},3,3,2,1,0,Maxim Khutornenko,Bill Farner,Bill Farner,1,0,1,0,0,0,0,0
AURORA-1351,Task,139,Resolved,Make observer POLLING_INTERVAL configurable,Observer should have a command line option to override the default {{POLLING_INTERVAL}}: https://github.com/apache/aurora/blob/827b9abea48babe53ad5b2c521757c60f04c6dfc/src/main/python/apache/thermos/observer/task_observer.py#L55,2,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-1361,Bug,139,Resolved,Explicit reconciliation must use SLAVE_ASSIGNED_STATES,TaskReconciler is currently using ACTIVE_STATES filter when fetching tasks for explicit reconciliation. Since Mesos does not know anything about non-assigned tasks this results in log messages like this:{noformat}allowed)E0619 00:09:35.219 THREAD175 org.apache.aurora.scheduler.state.TaskStateMachine$5.execute: Illegal state transition attempted: PENDING -> LOST (not allowed)I0619 00:09:35.220 THREAD13437 org.apache.aurora.scheduler.mesos.MesosSchedulerImpl.logStatusUpdate: Received status update for task 1371518881594-mesos-pending-resources-100-77-fbbd6074-0896-495f-9a88-1d0ff48495fe in state TASK_LOST from SOURCE_MASTER with REASON_RECONCILIATION: Reconciliation: Task is unknown{noformat}While there is no harm to PENDING or THROTTLED tasks the above messages pollute logs and should be suppressed. Use SLAVE_ASSIGNED_STATES filter instead of ACTIVE_STATES.,2,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-1344,Task,139,Resolved,Create Aurora oversubscription design summary,null,5,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-1346,Task,139,Resolved,Upgrade requests-kerberos to 0.7.0,This fixes an issue where the client can infinitely recurse when it gets a 401 but does not have a Kerberos TGT in its cache.,1,3,1,1,0,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-1353,Bug,139,Resolved,MesosPathDetector double-counts checkpoint roots,This manifests itself in the observer ballooning in resource usage.  The TaskDetector finds two copies of every task because of the 'latest' symlink being a duplicate of the actual directory so we get race conditions in on_active/on_finished inside src/main/python/apache/thermos/observer/task_observer.py that cause it to hold onto TaskResourceMonitors which tend to be pretty expensive to run.,2,3,2,1,0,Brian Wickman,Brian Wickman,Brian Wickman,2,0,0,0,0,0,0,0
AURORA-1379,Bug,151,Resolved,Referential integrity violation when replaying storage,"At startup in the Vagrant environment I observed:{noformat}E0630 20:45:54.427 THREAD1 org.apache.aurora.scheduler.SchedulerLifecycle$9.execute: Caught unchecked exception: org.apache.aurora.scheduler.storage.Storage$StorageException: ### Error updating database.  Cause: org.h2.jdbc.JdbcSQLException: Referential integrity constraint violation: ""CONSTRAINT_4BE: PUBLIC.TASKS FOREIGN KEY(SLAVE_ROW_ID) REFERENCES PUBLIC.HOST_ATTRIBUTES(ID) (1)""; SQL statement:DELETE FROM host_attributes    WHERE host = ? [23503-187]### The error may involve defaultParameterMap### The error occurred while setting parameters### SQL: DELETE FROM host_attributes     WHERE host = ?### Cause: org.h2.jdbc.JdbcSQLException: Referential integrity constraint violation: ""CONSTRAINT_4BE: PUBLIC.TASKS FOREIGN KEY(SLAVE_ROW_ID) REFERENCES PUBLIC.HOST_ATTRIBUTES(ID) (1)""; SQL statement:DELETE FROM host_attributes    WHERE host = ? [23503-187]org.apache.aurora.scheduler.storage.Storage$StorageException: ### Error updating database.  Cause: org.h2.jdbc.JdbcSQLException: Referential integrity constraint violation: ""CONSTRAINT_4BE: PUBLIC.TASKS FOREIGN KEY(SLAVE_ROW_ID) REFERENCES PUBLIC.HOST_ATTRIBUTES(ID) (1)""; SQL statement:DELETE FROM host_attributes    WHERE host = ? [23503-187]### The error may involve defaultParameterMap### The error occurred while setting parameters### SQL: DELETE FROM host_attributes     WHERE host = ?### Cause: org.h2.jdbc.JdbcSQLException: Referential integrity constraint violation: ""CONSTRAINT_4BE: PUBLIC.TASKS FOREIGN KEY(SLAVE_ROW_ID) REFERENCES PUBLIC.HOST_ATTRIBUTES(ID) (1)""; SQL statement:DELETE FROM host_attributes    WHERE host = ? [23503-187]        at org.apache.aurora.scheduler.storage.db.DbStorage.write(DbStorage.java:144)        at org.mybatis.guice.transactional.TransactionalMethodInterceptor.invoke(TransactionalMethodInterceptor.java:101)        at com.twitter.common.inject.TimedInterceptor.invoke(TimedInterceptor.java:87)        at org.apache.aurora.scheduler.storage.log.LogStorage.write(LogStorage.java:632)        at org.apache.aurora.scheduler.storage.log.LogStorage$3.execute(LogStorage.java:316)        at org.apache.aurora.scheduler.storage.log.LogStorage$3.execute(LogStorage.java:313)        at org.apache.aurora.scheduler.storage.log.LogStorage.replay(LogStorage.java:525)        at org.apache.aurora.scheduler.storage.log.LogStorage.access$1200(LogStorage.java:116)        at org.apache.aurora.scheduler.storage.log.LogStorage$21$1.execute(LogStorage.java:503)        at org.apache.aurora.scheduler.storage.log.LogStorage$21$1.execute(LogStorage.java:500)        at org.apache.aurora.scheduler.storage.log.StreamManagerImpl.readFromBeginning(StreamManagerImpl.java:127)        at org.apache.aurora.scheduler.storage.log.LogStorage$21.execute(LogStorage.java:500)        at org.apache.aurora.scheduler.storage.Storage$MutateWork$NoResult.apply(Storage.java:131)        at org.apache.aurora.scheduler.storage.db.DbStorage.bulkLoad(DbStorage.java:165)        at com.twitter.common.inject.TimedInterceptor.invoke(TimedInterceptor.java:87)        at org.apache.aurora.scheduler.storage.log.LogStorage.recover(LogStorage.java:496)        at com.twitter.common.inject.TimedInterceptor.invoke(TimedInterceptor.java:87)        at org.apache.aurora.scheduler.storage.log.LogStorage$20.execute(LogStorage.java:477)        at org.apache.aurora.scheduler.storage.Storage$MutateWork$NoResult.apply(Storage.java:131)        at org.apache.aurora.scheduler.storage.Storage$MutateWork$NoResult$Quiet.apply(Storage.java:148)        at org.apache.aurora.scheduler.storage.db.DbStorage.write(DbStorage.java:142)        at org.mybatis.guice.transactional.TransactionalMethodInterceptor.invoke(TransactionalMethodInterceptor.java:101)        at com.twitter.common.inject.TimedInterceptor.invoke(TimedInterceptor.java:87)        at org.apache.aurora.scheduler.storage.log.LogStorage.write(LogStorage.java:632)        at org.apache.aurora.scheduler.storage.log.LogStorage.start(LogStorage.java:471)        at org.apache.aurora.scheduler.storage.CallOrderEnforcingStorage.start(CallOrderEnforcingStorage.java:92)        at org.apache.aurora.scheduler.SchedulerLifecycle$6.execute(SchedulerLifecycle.java:252){noformat}",2,3,2,1,0,Bill Farner,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-1298,Story,151,Resolved,Make DbTaskStore suitable for use in production,The DbTaskStore implementation has so far only targeted behavioral compliance with InMemTaskStore.  Use benchmarks to determine areas that require perf improvements and address them.  Also address relevant TODOs that should be production showstoppers.,5,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,4,0,0,0,0,0,0,0
AURORA-698,Bug,151,Resolved,aurora executor _shutdown deadline calls should be daemonized,In the aurora executor shutdown method we have deadline() calls:{noformat}  def _shutdown(self status_result):    runner_status = self._runner.status    try:      deadline(self._runner.stop timeout=self.STOP_TIMEOUT)    except Timeout:      log.error('Failed to stop runner within deadline.')    try:      deadline(self._chained_checker.stop timeout=self.STOP_TIMEOUT)    except Timeout:      log.error('Failed to stop all checkers within deadline.')    # If the runner was alive when _shutdown was called defer to the status_result    # otherwise the runner's terminal state is the preferred state.    exit_status = runner_status or status_result    self.send_update(        self._driver        self._task_id        exit_status.status        status_result.reason)    self.terminated.set()    defer(self._driver.stop delay=self.PERSISTENCE_WAIT){noformat}However if runner.stop fails with a Timeout exception the spawned AnonymousThread is not daemonized and causes the executor to fail to exit.  This means that the cgroup will not be torn down and if the runner.stop actually failed the process can stay alive even if TASK_KILLED was delivered.,1,3,2,1,0,Brian Wickman,Brian Wickman,Brian Wickman,1,0,0,0,0,0,0,0
AURORA-1333,Task,151,Resolved,Remove GC executor code,null,4,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-1334,Task,151,Resolved,Remove GCExecutorLauncher code,null,3,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,2,0,0,0,0,0,0,0
AURORA-1074,Bug,151,Resolved,"Remove the ""enable_legacy_constraints"" flag.","As a part of AURORA-184 we added a flag called ""enable_legacy_constraints"" which enables behaviour that injects a host and rack limit into every job.We should deprecate and remove this flag in some future release.",2,3,1,1,0,Zameer Manji,Zameer Manji,Zameer Manji,2,0,1,1,1,0,0,0
AURORA-1368,Task,151,Resolved,shutdown_endpoint fields should be in the aurora schema,Commit ea2c9ad24ce adds graceful_shutdown_endpoint and shutdown_endpoint onto the thermos Task object but Thermos is completely unaware of the http lifecycle.  This should either go onto the Job or HealthCheck objects or be added as a separate enumeration on the Job.,2,1,1,1,0,Brian Wickman,Brian Wickman,Brian Wickman,1,0,1,1,1,0,0,0
AURORA-415,Task,151,Resolved,H2-backed implementation of JobStore,null,3,3,2,1,0,Bill Farner,Chris Lambert,Chris Lambert,1,0,0,0,0,0,0,0
AURORA-1327,Task,151,Resolved,MesosSchedulerImpl should check if reason is present when posting status updates,We export stats based on task statuses however since protobuf enums default to a value when unset the reason stats we generate may not be correct. c.f https://github.com/apache/aurora/blob/998993dd802cf5e94a995aefd7a6c4ec90a1d3af/src/main/java/org/apache/aurora/scheduler/mesos/MesosSchedulerImpl.java#L228. If reason is unset it will default to the first enum value ({{REASON_COMMAND_EXECUTOR_FAILED}}).We should call {{status.hasReason()}} first and if it's not set do not use the value of {{status.getReason()}}.,2,3,4,1,0,Bill Farner,Joshua Cohen,Joshua Cohen,4,0,0,0,0,0,0,0
AURORA-1375,Story,151,Resolved,When setting quota the scheduler should prevent setting below current usage,Initially I thought this check should live in the admin client but after discussing with [~zmanji] we believe the scheduler would be the right place to enforce this.,2,3,2,1,0,Zameer Manji,Joe Smith,Joe Smith,4,0,0,0,0,0,0,0
AURORA-1395,Bug,156,Resolved,RescheduleCalculator precondition fails when using DbTaskStore,When enabling the DB task store i frequently encounter this exception due to a precondition check fail in RescheduleCalculator:{noformat}E0710 22:33:48.688 THREAD138 org.apache.aurora.scheduler.events.PubsubEventModule$1.handleException: Failed to dispatch event to public void org.apache.aurora.scheduler.async.TaskThrottler.taskChangedState(org.apache.aurora.scheduler.events.PubsubEvent$TaskStateChange): java.lang.IllegalStateExceptionjava.lang.IllegalStateException        at com.google.common.base.Preconditions.checkState(Preconditions.java:161)        at org.apache.aurora.scheduler.async.RescheduleCalculator$RescheduleCalculatorImpl$1.apply(RescheduleCalculator.java:103)        at org.apache.aurora.scheduler.async.RescheduleCalculator$RescheduleCalculatorImpl$1.apply(RescheduleCalculator.java:85)        at org.apache.aurora.scheduler.async.RescheduleCalculator$RescheduleCalculatorImpl.getFlappingPenaltyMs(RescheduleCalculator.java:159)        at org.apache.aurora.scheduler.async.TaskThrottler.taskChangedState(TaskThrottler.java:72)        at sun.reflect.GeneratedMethodAccessor89.invoke(Unknown Source)        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)        at java.lang.reflect.Method.invoke(Method.java:497)        at com.google.common.eventbus.EventSubscriber.handleEvent(EventSubscriber.java:74)        at com.google.common.eventbus.SynchronizedEventSubscriber.handleEvent(SynchronizedEventSubscriber.java:47)        at com.google.common.eventbus.EventBus.dispatch(EventBus.java:322)        at com.google.common.eventbus.AsyncEventBus.access$001(AsyncEventBus.java:34)        at com.google.common.eventbus.AsyncEventBus$1.run(AsyncEventBus.java:117)        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)        at java.lang.Thread.run(Thread.java:745){noformat},5,2,1,1,0,Bill Farner,Bill Farner,Bill Farner,9,0,3,0,0,0,0,0
AURORA-1379,Bug,156,Resolved,Referential integrity violation when replaying storage,"At startup in the Vagrant environment I observed:{noformat}E0630 20:45:54.427 THREAD1 org.apache.aurora.scheduler.SchedulerLifecycle$9.execute: Caught unchecked exception: org.apache.aurora.scheduler.storage.Storage$StorageException: ### Error updating database.  Cause: org.h2.jdbc.JdbcSQLException: Referential integrity constraint violation: ""CONSTRAINT_4BE: PUBLIC.TASKS FOREIGN KEY(SLAVE_ROW_ID) REFERENCES PUBLIC.HOST_ATTRIBUTES(ID) (1)""; SQL statement:DELETE FROM host_attributes    WHERE host = ? [23503-187]### The error may involve defaultParameterMap### The error occurred while setting parameters### SQL: DELETE FROM host_attributes     WHERE host = ?### Cause: org.h2.jdbc.JdbcSQLException: Referential integrity constraint violation: ""CONSTRAINT_4BE: PUBLIC.TASKS FOREIGN KEY(SLAVE_ROW_ID) REFERENCES PUBLIC.HOST_ATTRIBUTES(ID) (1)""; SQL statement:DELETE FROM host_attributes    WHERE host = ? [23503-187]org.apache.aurora.scheduler.storage.Storage$StorageException: ### Error updating database.  Cause: org.h2.jdbc.JdbcSQLException: Referential integrity constraint violation: ""CONSTRAINT_4BE: PUBLIC.TASKS FOREIGN KEY(SLAVE_ROW_ID) REFERENCES PUBLIC.HOST_ATTRIBUTES(ID) (1)""; SQL statement:DELETE FROM host_attributes    WHERE host = ? [23503-187]### The error may involve defaultParameterMap### The error occurred while setting parameters### SQL: DELETE FROM host_attributes     WHERE host = ?### Cause: org.h2.jdbc.JdbcSQLException: Referential integrity constraint violation: ""CONSTRAINT_4BE: PUBLIC.TASKS FOREIGN KEY(SLAVE_ROW_ID) REFERENCES PUBLIC.HOST_ATTRIBUTES(ID) (1)""; SQL statement:DELETE FROM host_attributes    WHERE host = ? [23503-187]        at org.apache.aurora.scheduler.storage.db.DbStorage.write(DbStorage.java:144)        at org.mybatis.guice.transactional.TransactionalMethodInterceptor.invoke(TransactionalMethodInterceptor.java:101)        at com.twitter.common.inject.TimedInterceptor.invoke(TimedInterceptor.java:87)        at org.apache.aurora.scheduler.storage.log.LogStorage.write(LogStorage.java:632)        at org.apache.aurora.scheduler.storage.log.LogStorage$3.execute(LogStorage.java:316)        at org.apache.aurora.scheduler.storage.log.LogStorage$3.execute(LogStorage.java:313)        at org.apache.aurora.scheduler.storage.log.LogStorage.replay(LogStorage.java:525)        at org.apache.aurora.scheduler.storage.log.LogStorage.access$1200(LogStorage.java:116)        at org.apache.aurora.scheduler.storage.log.LogStorage$21$1.execute(LogStorage.java:503)        at org.apache.aurora.scheduler.storage.log.LogStorage$21$1.execute(LogStorage.java:500)        at org.apache.aurora.scheduler.storage.log.StreamManagerImpl.readFromBeginning(StreamManagerImpl.java:127)        at org.apache.aurora.scheduler.storage.log.LogStorage$21.execute(LogStorage.java:500)        at org.apache.aurora.scheduler.storage.Storage$MutateWork$NoResult.apply(Storage.java:131)        at org.apache.aurora.scheduler.storage.db.DbStorage.bulkLoad(DbStorage.java:165)        at com.twitter.common.inject.TimedInterceptor.invoke(TimedInterceptor.java:87)        at org.apache.aurora.scheduler.storage.log.LogStorage.recover(LogStorage.java:496)        at com.twitter.common.inject.TimedInterceptor.invoke(TimedInterceptor.java:87)        at org.apache.aurora.scheduler.storage.log.LogStorage$20.execute(LogStorage.java:477)        at org.apache.aurora.scheduler.storage.Storage$MutateWork$NoResult.apply(Storage.java:131)        at org.apache.aurora.scheduler.storage.Storage$MutateWork$NoResult$Quiet.apply(Storage.java:148)        at org.apache.aurora.scheduler.storage.db.DbStorage.write(DbStorage.java:142)        at org.mybatis.guice.transactional.TransactionalMethodInterceptor.invoke(TransactionalMethodInterceptor.java:101)        at com.twitter.common.inject.TimedInterceptor.invoke(TimedInterceptor.java:87)        at org.apache.aurora.scheduler.storage.log.LogStorage.write(LogStorage.java:632)        at org.apache.aurora.scheduler.storage.log.LogStorage.start(LogStorage.java:471)        at org.apache.aurora.scheduler.storage.CallOrderEnforcingStorage.start(CallOrderEnforcingStorage.java:92)        at org.apache.aurora.scheduler.SchedulerLifecycle$6.execute(SchedulerLifecycle.java:252){noformat}",2,3,2,1,0,Bill Farner,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-1096,Story,156,Resolved,Scheduler updater should limit the number of job/instance events,Large/flapping scheduler job updates may generate too many events in the update store. The update settings are fully controlled by the user and there is a potential for a misconfigured job update to completely overwhelm our in-memory DB storage with job update instance events. For example a large flapping update with {{max_per_shard_failures}} and {{max_total_failures}} set to max INT when left unattended can quickly consume all available RAM and kill the scheduler. A manual cleanup of the scheduler log would be needed to bring the scheduler up.This can be especially relevant with the introduction of update heartbeats  (AURORA-690) that can further exacerbate the problem (e.g. when {{blockIfNoPulseAfterMs}} set too low wrt the external service pulse rate).We need to cap the max per-job lifetime count of {{JobUpdateEvent}} and {{JobInstanceUpdateEvent}} instances. A nice bonus would be providing a hint in the UI when the event sequence is cut off.,5,3,3,1,0,Joe Smith,Maxim Khutornenko,Maxim Khutornenko,7,0,1,0,0,0,0,0
AURORA-1352,Story,156,Resolved,Audit log doesn't capture Shiro subject principal,Scheduler RPCs that were authenticated by Shiro show UNSECURE in their audit messages.,3,3,1,1,0,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,5,0,2,1,1,0,0,0
AURORA-1332,Bug,156,Resolved,Updater does not skip already updated instances with /INSTANCES option.,"The new updater is too restrictive when processing /INSTANCES option. E.g. if instance 0 is already updated but the client sends /0-3 range the entire request is rejected with: ""updateOnlyTheseInstances contains instances irrelevant to the update: [0]"".https://github.com/apache/aurora/blob/2dc1d59f1e772e220b3bfb26480c3b90c688800f/src/main/java/org/apache/aurora/scheduler/thrift/SchedulerThriftInterface.java#L1175-L1181",2,3,3,1,0,Bill Farner,Maxim Khutornenko,Maxim Khutornenko,2,0,0,0,0,0,0,0
AURORA-1383,Bug,156,Resolved,Unique constraint on task_config_metadata.key should be removed,Task config metadata is pairs not a mapping.  This constraint prevents valid configurations.,2,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-1386,Bug,156,Resolved,Transaction isolation on DB stores is too strict,The transaction isolation used in the scheduler's DB-based storage is too strict.  This results in inconsistent data when work in a transaction forks asynchronous work on a different thread which is implicitly done for messages on the event bus.  In cases like {{TaskThrottler}} which has some preconditions around expected state we encounter exceptions related to the ancestor state not yet being shown as terminated as we try to calculate the reschedule delay.,2,2,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,1,0,0,0,0,0
AURORA-1390,Bug,156,Resolved,Primary key violation when modifying cron jobs with DbCronJobStore,CronJobStore supports mutation via {{saveAcceptedJob}} which acts as a put.  The implementation of DbCronJobStore implements this as an {{INSERT}} which fails on a primary key uniqueness violation.,2,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-1392,Bug,156,Resolved,DbCronJobStore does not go through TaskConfig de-dupe code breaking uniqueness assumptions elsewhere,The result is a stack trace like this:{noformat}        at com.google.common.collect.ImmutableMap.checkNoConflict(ImmutableMap.java:150)        at com.google.common.collect.RegularImmutableMap.checkNoConflictInBucket(RegularImmutableMap.java:104)        at com.google.common.collect.RegularImmutableMap.<init>(RegularImmutableMap.java:70)        at com.google.common.collect.ImmutableMap$Builder.build(ImmutableMap.java:254)        at com.google.common.collect.Maps.uniqueIndex(Maps.java:1166)        at com.google.common.collect.Maps.uniqueIndex(Maps.java:1140)        at com.google.common.collect.FluentIterable.uniqueIndex(FluentIterable.java:424)        at org.apache.aurora.scheduler.storage.db.DbTaskStore.getTaskConfigRows(DbTaskStore.java:142)        at org.apache.aurora.scheduler.storage.db.DbTaskStore.saveTasks(DbTaskStore.java:170)        at com.twitter.common.inject.TimedInterceptor.invoke(TimedInterceptor.java:87)        at org.apache.aurora.scheduler.storage.db.DbTaskStore.mutateTasks(DbTaskStore.java:234)        at com.twitter.common.inject.TimedInterceptor.invoke(TimedInterceptor.java:87)        at org.apache.aurora.scheduler.storage.log.WriteAheadStorage.mutateTasks(WriteAheadStorage.java:195)        at org.apache.aurora.scheduler.state.StateManagerImpl.updateTaskAndExternalState(StateManagerImpl.java:326)        at org.apache.aurora.scheduler.state.StateManagerImpl.updateTaskAndExternalState(StateManagerImpl.java:246)        at org.apache.aurora.scheduler.state.StateManagerImpl.changeState(StateManagerImpl.java:161)        at org.apache.aurora.scheduler.cron.quartz.AuroraCronJob$2.execute(AuroraCronJob.java:184)        at org.apache.aurora.scheduler.storage.Storage$MutateWork$NoResult.apply(Storage.java:131)        at org.apache.aurora.scheduler.storage.Storage$MutateWork$NoResult$Quiet.apply(Storage.java:148)        at org.apache.aurora.scheduler.storage.log.LogStorage$24.apply(LogStorage.java:605)        at org.apache.aurora.scheduler.storage.log.LogStorage$24.apply(LogStorage.java:602)        at org.apache.aurora.scheduler.storage.db.DbStorage.write(DbStorage.java:143)        at org.mybatis.guice.transactional.TransactionalMethodInterceptor.invoke(TransactionalMethodInterceptor.java:101)        at com.twitter.common.inject.TimedInterceptor.invoke(TimedInterceptor.java:87)        at org.apache.aurora.scheduler.storage.log.LogStorage.doInTransaction(LogStorage.java:602)        at org.apache.aurora.scheduler.storage.log.LogStorage.write(LogStorage.java:635)        at org.apache.aurora.scheduler.storage.CallOrderEnforcingStorage.write(CallOrderEnforcingStorage.java:130)        at org.apache.aurora.scheduler.cron.quartz.AuroraCronJob.doExecute(AuroraCronJob.java:180)        at org.apache.aurora.scheduler.cron.quartz.AuroraCronJob.execute(AuroraCronJob.java:108)        at org.quartz.core.JobRunShell.run(JobRunShell.java:202)        ... 1 more{noformat},5,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-1397,Story,156,Resolved,Python style checker should only report errors,When running our top-level build script (./build-support/jenkins/build.sh) style check results are reported for python files.  This output is too verbose as it reports {{SUCCESS}} for all files that pass style check.  Change this output to only report errors.In particular this will make for more direct build result messages from build bot.  A counter-example is the current state as seen in https://reviews.apache.org/r/36392/,2,4,1,1,0,Bill Farner,Bill Farner,Bill Farner,3,0,0,0,0,0,0,0
AURORA-1399,Bug,156,Resolved,update start --wait should exit non-zero when the update was non-successful,A client command {{update start --wait}} will always return zero as long as the update terminated.  It would be much more script-friendly if the update exited zero only if the update ended in {{ROLLED_FORWARD}} and ideally using different exit codes for other identifiable exit conditions.,null,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-1401,Bug,156,Resolved,DB deadlock caused stuck job update,"We observed the symptom of a job update that was stuck in ROLLING_FORWARD but was not active.  Looking in scheduler logs revealed a DB-level deadlock:{noformat}E0715 19:04:53.085 THREAD1471 org.apache.aurora.scheduler.updater.JobUpdateEventSubscriber.startUp: Failed to resume job updates: org.apache.aurora.scheduler.storage.Storage$StorageException: ### Error querying database.  Cause: org.h2.jdbc.JdbcSQLException: Deadlock detected. The current transaction was rolled back. Details: ""Session #3 (user: ) on thread RowGarbageCollector RUNNING is waiting to lock PUBLIC.LOCKS (shared) while locking PUBLIC.JOB_KEYS (exclusive).Session #2 (user: ) on thread JobUpdateEventSubscriber STARTING is waiting to lock PUBLIC.JOB_KEYS (shared) while locking PUBLIC.JOB_INSTANCE_UPDATE_EVENTS (exclusive) PUBLIC.JOB_UPDATE_EVENTS (exclusive) PUBLIC.LOCKS (exclusive) PUBLIC.JOB_UPDATE_LOCKS (exclusive).""; SQL statement:SELECT      lock_token    FROM job_update_locks AS l    INNER JOIN job_updates u ON l.update_row_id = u.id         INNER JOIN job_keys AS j ON j.id = u.job_key_id       WHERE      u.update_id = ?    AND j.role = ?    AND j.environment = ?    AND j.name = ? [40001-187]### The error may exist in org/apache/aurora/scheduler/storage/db/JobUpdateDetailsMapper.xml### The error may involve defaultParameterMap### The error occurred while setting parameters### SQL: SELECT       lock_token     FROM job_update_locks AS l     INNER JOIN job_updates u ON l.update_row_id = u.id           INNER JOIN job_keys AS j ON j.id = u.job_key_id         WHERE       u.update_id = ?     AND j.role = ?     AND j.environment = ?     AND j.name = ?### Cause: org.h2.jdbc.JdbcSQLException: Deadlock detected. The current transaction was rolled back. Details: ""Session #3 (user: ) on thread RowGarbageCollector RUNNING is waiting to lock PUBLIC.LOCKS (shared) while locking PUBLIC.JOB_KEYS (exclusive).Session #2 (user: ) on thread JobUpdateEventSubscriber STARTING is waiting to lock PUBLIC.JOB_KEYS (shared) while locking PUBLIC.JOB_INSTANCE_UPDATE_EVENTS (exclusive) PUBLIC.JOB_UPDATE_EVENTS (exclusive) PUBLIC.LOCKS (exclusive) PUBLIC.JOB_UPDATE_LOCKS (exclusive).""; SQL statement:SELECT      lock_token    FROM job_update_locks AS l    INNER JOIN job_updates u ON l.update_row_id = u.id         INNER JOIN job_keys AS j ON j.id = u.job_key_id       WHERE      u.update_id = ?    AND j.role = ?    AND j.environment = ?    AND j.name = ? [40001-187]org.apache.aurora.scheduler.storage.Storage$StorageException: ### Error querying database.  Cause: org.h2.jdbc.JdbcSQLException: Deadlock detected. The current transaction was rolled back. Details: ""Session #3 (user: ) on thread RowGarbageCollector RUNNING is waiting to lock PUBLIC.LOCKS (shared) while locking PUBLIC.JOB_KEYS (exclusive).Session #2 (user: ) on thread JobUpdateEventSubscriber STARTING is waiting to lock PUBLIC.JOB_KEYS (shared) while locking PUBLIC.JOB_INSTANCE_UPDATE_EVENTS (exclusive) PUBLIC.JOB_UPDATE_EVENTS (exclusive) PUBLIC.LOCKS (exclusive) PUBLIC.JOB_UPDATE_LOCKS (exclusive).""; SQL statement:SELECT      lock_token    FROM job_update_locks AS l    INNER JOIN job_updates u ON l.update_row_id = u.id         INNER JOIN job_keys AS j ON j.id = u.job_key_id       WHERE      u.update_id = ?    AND j.role = ?    AND j.environment = ?    AND j.name = ? [40001-187]### The error may exist in org/apache/aurora/scheduler/storage/db/JobUpdateDetailsMapper.xml### The error may involve defaultParameterMap### The error occurred while setting parameters### SQL: SELECT       lock_token     FROM job_update_locks AS l     INNER JOIN job_updates u ON l.update_row_id = u.id           INNER JOIN job_keys AS j ON j.id = u.job_key_id         WHERE       u.update_id = ?     AND j.role = ?     AND j.environment = ?     AND j.name = ?### Cause: org.h2.jdbc.JdbcSQLException: Deadlock detected. The current transaction was rolled back. Details: ""Session #3 (user: ) on thread RowGarbageCollector RUNNING is waiting to lock PUBLIC.LOCKS (shared) while locking PUBLIC.JOB_KEYS (exclusive).Session #2 (user: ) on thread JobUpdateEventSubscriber STARTING is waiting to lock PUBLIC.JOB_KEYS (shared) while locking PUBLIC.JOB_INSTANCE_UPDATE_EVENTS (exclusive) PUBLIC.JOB_UPDATE_EVENTS (exclusive) PUBLIC.LOCKS (exclusive) PUBLIC.JOB_UPDATE_LOCKS (exclusive).""; SQL statement:SELECT      lock_token    FROM job_update_locks AS l    INNER JOIN job_updates u ON l.update_row_id = u.id         INNER JOIN job_keys AS j ON j.id = u.job_key_id       WHERE      u.update_id = ?    AND j.role = ?    AND j.environment = ?    AND j.name = ? [40001-187]        at org.apache.aurora.scheduler.storage.db.DbStorage.write(DbStorage.java:145)        at org.mybatis.guice.transactional.TransactionalMethodInterceptor.invoke(TransactionalMethodInterceptor.java:101)        at com.twitter.common.inject.TimedInterceptor.invoke(TimedInterceptor.java:87)        at org.apache.aurora.scheduler.storage.log.LogStorage.doInTransaction(LogStorage.java:602)        at org.apache.aurora.scheduler.storage.log.LogStorage.write(LogStorage.java:635)        at org.apache.aurora.scheduler.storage.CallOrderEnforcingStorage.write(CallOrderEnforcingStorage.java:130)        at org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.systemResume(JobUpdateControllerImpl.java:263)        at org.apache.aurora.scheduler.updater.JobUpdateEventSubscriber.startUp(JobUpdateEventSubscriber.java:85)        at com.google.common.util.concurrent.AbstractIdleService$2$1.run(AbstractIdleService.java:54)        at com.google.common.util.concurrent.Callables$3.run(Callables.java:93)        at java.lang.Thread.run(Thread.java:745)Caused by: org.apache.ibatis.exceptions.PersistenceException: ### Error querying database.  Cause: org.h2.jdbc.JdbcSQLException: Deadlock detected. The current transaction was rolled back. Details: ""Session #3 (user: ) on thread RowGarbageCollector RUNNING is waiting to lock PUBLIC.LOCKS (shared) while locking PUBLIC.JOB_KEYS (exclusive).Session #2 (user: ) on thread JobUpdateEventSubscriber STARTING is waiting to lock PUBLIC.JOB_KEYS (shared) while locking PUBLIC.JOB_INSTANCE_UPDATE_EVENTS (exclusive) PUBLIC.JOB_UPDATE_EVENTS (exclusive) PUBLIC.LOCKS (exclusive) PUBLIC.JOB_UPDATE_LOCKS (exclusive).""; SQL statement:SELECT      lock_token    FROM job_update_locks AS l    INNER JOIN job_updates u ON l.update_row_id = u.id         INNER JOIN job_keys AS j ON j.id = u.job_key_id       WHERE      u.update_id = ?    AND j.role = ?    AND j.environment = ?    AND j.name = ? [40001-187]### The error may exist in org/apache/aurora/scheduler/storage/db/JobUpdateDetailsMapper.xml### The error may involve defaultParameterMap### The error occurred while setting parameters### SQL: SELECT       lock_token     FROM job_update_locks AS l     INNER JOIN job_updates u ON l.update_row_id = u.id           INNER JOIN job_keys AS j ON j.id = u.job_key_id         WHERE       u.update_id = ?     AND j.role = ?     AND j.environment = ?     AND j.name = ?### Cause: org.h2.jdbc.JdbcSQLException: Deadlock detected. The current transaction was rolled back. Details: ""Session #3 (user: ) on thread RowGarbageCollector RUNNING is waiting to lock PUBLIC.LOCKS (shared) while locking PUBLIC.JOB_KEYS (exclusive).Session #2 (user: ) on thread JobUpdateEventSubscriber STARTING is waiting to lock PUBLIC.JOB_KEYS (shared) while locking PUBLIC.JOB_INSTANCE_UPDATE_EVENTS (exclusive) PUBLIC.JOB_UPDATE_EVENTS (exclusive) PUBLIC.LOCKS (exclusive) PUBLIC.JOB_UPDATE_LOCKS (exclusive).""; SQL statement:SELECT      lock_token    FROM job_update_locks AS l    INNER JOIN job_updates u ON l.update_row_id = u.id         INNER JOIN job_keys AS j ON j.id = u.job_key_id       WHERE      u.update_id = ?    AND j.role = ?    AND j.environment = ?    AND j.name = ? [40001-187]        at org.apache.ibatis.exceptions.ExceptionFactory.wrapException(ExceptionFactory.java:30)        at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:122)        at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:113)        at org.apache.ibatis.session.defaults.DefaultSqlSession.selectOne(DefaultSqlSession.java:73)        at sun.reflect.GeneratedMethodAccessor29.invoke(Unknown Source)        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)        at java.lang.reflect.Method.invoke(Method.java:497)        at org.apache.ibatis.session.SqlSessionManager$SqlSessionInterceptor.invoke(SqlSessionManager.java:334)        at com.sun.proxy.$Proxy57.selectOne(Unknown Source)        at org.apache.ibatis.session.SqlSessionManager.selectOne(SqlSessionManager.java:165)        at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:69)        at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:53)        at org.apache.aurora.scheduler.storage.db.$Proxy64.selectLockToken(Unknown Source)        at org.apache.aurora.scheduler.storage.db.DbJobUpdateStore.getLockToken(DbJobUpdateStore.java:257)        at com.twitter.common.inject.TimedInterceptor.invoke(TimedInterceptor.java:87)        at org.apache.aurora.scheduler.storage.ForwardingStore.getLockToken(ForwardingStore.java:178)        at org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.changeJobUpdateStatus(JobUpdateControllerImpl.java:454)        at org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.access$1000(JobUpdateControllerImpl.java:108)        at org.apache.aurora.scheduler.updater.JobUpdateControllerImpl$4.execute(JobUpdateControllerImpl.java:283)        at org.apache.aurora.scheduler.storage.Storage$MutateWork$NoResult.apply(Storage.java:131)        at org.apache.aurora.scheduler.storage.Storage$MutateWork$NoResult$Quiet.apply(Storage.java:148)        at org.apache.aurora.scheduler.storage.log.LogStorage$24.apply(LogStorage.java:605)        at org.apache.aurora.scheduler.storage.log.LogStorage$24.apply(LogStorage.java:602)        at org.apache.aurora.scheduler.storage.db.DbStorage.write(DbStorage.java:143)        ... 10 moreCaused by: org.h2.jdbc.JdbcSQLException: Deadlock detected. The current transaction was rolled back. Details: ""Session #3 (user: ) on thread RowGarbageCollector RUNNING is waiting to lock PUBLIC.LOCKS (shared) while locking PUBLIC.JOB_KEYS (exclusive).Session #2 (user: ) on thread JobUpdateEventSubscriber STARTING is waiting to lock PUBLIC.JOB_KEYS (shared) while locking PUBLIC.JOB_INSTANCE_UPDATE_EVENTS (exclusive) PUBLIC.JOB_UPDATE_EVENTS (exclusive) PUBLIC.LOCKS (exclusive) PUBLIC.JOB_UPDATE_LOCKS (exclusive).""; SQL statement:SELECT      lock_token    FROM job_update_locks AS l    INNER JOIN job_updates u ON l.update_row_id = u.id         INNER JOIN job_keys AS j ON j.id = u.job_key_id       WHERE      u.update_id = ?    AND j.role = ?    AND j.environment = ?    AND j.name = ? [40001-187]        at org.h2.message.DbException.getJdbcSQLException(DbException.java:345)        at org.h2.message.DbException.get(DbException.java:179)        at org.h2.message.DbException.get(DbException.java:155)        at org.h2.table.RegularTable.doLock1(RegularTable.java:496)        at org.h2.table.RegularTable.lock(RegularTable.java:472)        at org.h2.table.TableFilter.lock(TableFilter.java:146)        at org.h2.command.dml.Select.queryWithoutCache(Select.java:671)        at org.h2.command.dml.Query.query(Query.java:322)        at org.h2.command.dml.Query.query(Query.java:290)        at org.h2.command.dml.Query.query(Query.java:36)        at org.h2.command.CommandContainer.query(CommandContainer.java:90)        at org.h2.command.Command.executeQuery(Command.java:197)        at org.h2.jdbc.JdbcPreparedStatement.execute(JdbcPreparedStatement.java:192)        at org.apache.ibatis.executor.statement.PreparedStatementHandler.query(PreparedStatementHandler.java:62)        at org.apache.ibatis.executor.statement.RoutingStatementHandler.query(RoutingStatementHandler.java:78)        at org.apache.ibatis.executor.SimpleExecutor.doQuery(SimpleExecutor.java:62)        at org.apache.ibatis.executor.BaseExecutor.queryFromDatabase(BaseExecutor.java:303)        at org.apache.ibatis.executor.BaseExecutor.query(BaseExecutor.java:154)        at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:102)        at org.apache.ibatis.executor.CachingExecutor.query(CachingExecutor.java:82)        at org.apache.ibatis.session.defaults.DefaultSqlSession.selectList(DefaultSqlSession.java:120)        ... 32 more{noformat}",2,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,2,0,1,1,1,0,0,0
AURORA-1381,Bug,160,Resolved,Remove duplicate thermos_observer,There are currently two thermos_observer python_binaries in the codebase one in src/main/python/apache/aurora/tools/BUILD and the other in ./src/main/python/apache/thermos/observer/bin/BUILD. This is confusing.Let's get rid of one of them I think the latter is the one that's not meant to be used.,2,4,5,1,0,null,Brian Brazil,Brian Brazil,8,0,1,0,0,0,0,0
AURORA-1402,Story,160,Accepted,Allow overriding cluster attributes via environment variables,An example usecase is giving the Aurora Client a different 'scheduler URI' which would allow the client to bypass a downed proxy but still be able to send RPCs. Initially it seemed like this would be the only usecase but after speaking to [~wfarner] and [~kevints] a more general solution to override various parts of a cluster configuration would be useful.There is already a [mechanism to go from a cluster's json|https://github.com/apache/aurora/blob/master/src/main/python/apache/aurora/admin/admin.py#L494] so we should consider using the same formatting to make that read+write vs. just read.,5,3,1,0,0,Joe Smith,Joe Smith,Joe Smith,0,0,0,0,0,0,0,0
AURORA-1395,Bug,160,Resolved,RescheduleCalculator precondition fails when using DbTaskStore,When enabling the DB task store i frequently encounter this exception due to a precondition check fail in RescheduleCalculator:{noformat}E0710 22:33:48.688 THREAD138 org.apache.aurora.scheduler.events.PubsubEventModule$1.handleException: Failed to dispatch event to public void org.apache.aurora.scheduler.async.TaskThrottler.taskChangedState(org.apache.aurora.scheduler.events.PubsubEvent$TaskStateChange): java.lang.IllegalStateExceptionjava.lang.IllegalStateException        at com.google.common.base.Preconditions.checkState(Preconditions.java:161)        at org.apache.aurora.scheduler.async.RescheduleCalculator$RescheduleCalculatorImpl$1.apply(RescheduleCalculator.java:103)        at org.apache.aurora.scheduler.async.RescheduleCalculator$RescheduleCalculatorImpl$1.apply(RescheduleCalculator.java:85)        at org.apache.aurora.scheduler.async.RescheduleCalculator$RescheduleCalculatorImpl.getFlappingPenaltyMs(RescheduleCalculator.java:159)        at org.apache.aurora.scheduler.async.TaskThrottler.taskChangedState(TaskThrottler.java:72)        at sun.reflect.GeneratedMethodAccessor89.invoke(Unknown Source)        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)        at java.lang.reflect.Method.invoke(Method.java:497)        at com.google.common.eventbus.EventSubscriber.handleEvent(EventSubscriber.java:74)        at com.google.common.eventbus.SynchronizedEventSubscriber.handleEvent(SynchronizedEventSubscriber.java:47)        at com.google.common.eventbus.EventBus.dispatch(EventBus.java:322)        at com.google.common.eventbus.AsyncEventBus.access$001(AsyncEventBus.java:34)        at com.google.common.eventbus.AsyncEventBus$1.run(AsyncEventBus.java:117)        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)        at java.lang.Thread.run(Thread.java:745){noformat},5,2,1,1,0,Bill Farner,Bill Farner,Bill Farner,9,0,3,0,0,0,0,0
AURORA-1342,Bug,160,Resolved,shiro.ini with blank users section fails to parse.,The scheduler does not accept a shiro.ini file with a blank `[users]` section. This is a legitimate use as the definitions of users could be provided by another Realm (for example a Kerberos realm).,1,3,1,1,0,Kevin Sweeney,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-1407,Bug,160,Resolved,IllegalArgumentException in end-to-end tests,"When running end-to-end tests on {{38c2e76}} i encountered the following error:{noformat}E0723 00:20:18.231 THREAD137 org.apache.aurora.scheduler.updater.JobUpdateEventSubscriber.taskChangedState: Failed to handle state change: com.google.common.util.concurrent.UncheckedExecutionException: java.lang.IllegalArgumentException: Multiple entries with same key: TaskConfig(job:JobKey(role:vagrant environment:test name:http_example_docker) owner:Identity(role:vagrant user:vagrant) environment:test jobName:http_example_docker isService:true numCpus:0.5 ramMb:34 diskMb:64 priority:0 maxTaskFailures:1 production:false constraints:[Constraint(name:host constraint:<TaskConstraint limit:LimitConstraint(limit:4)>)] requestedPorts:[http] taskLinks:{http=http://%host%:%port:http%} contactEmail:vagrant@localhost executorConfig:ExecutorConfig(name:AuroraExecutor data:{""environment"": ""test"" ""health_check_config"": {""initial_interval_secs"": 5.0 ""endpoint"": ""/health"" ""expected_response_code"": 0 ""expected_response"": ""ok"" ""max_consecutive_failures"": 0 ""timeout_secs"": 1.0 ""interval_secs"": 1.0} ""container"": {""docker"": {""image"": ""http_example"" ""parameters"": []}} ""name"": ""http_example_docker"" ""service"": true ""max_task_failures"": 1 ""cron_collision_policy"": ""KILL_EXISTING"" ""enable_hooks"": false ""cluster"": ""devcluster"" ""task"": {""processes"": [{""daemon"": false ""name"": ""stage_server"" ""ephemeral"": false ""max_failures"": 1 ""min_duration"": 5 ""cmdline"": ""cp /tmp/http_example.py ."" ""final"": false} {""daemon"": false ""name"": ""run_server"" ""ephemeral"": false ""max_failures"": 1 ""min_duration"": 5 ""cmdline"": ""python http_example.py {{thermos.ports[http]}}"" ""final"": false}] ""name"": ""http_example"" ""finalization_wait"": 30 ""max_failures"": 1 ""max_concurrency"": 0 ""resources"": {""disk"": 67108864 ""ram"": 35651584 ""cpu"": 0.5} ""constraints"": [{""order"": [""stage_server"" ""run_server""]}]} ""role"": ""vagrant"" ""contact"": ""vagrant@localhost"" ""announce"": {""primary_port"": ""http"" ""portmap"": {""aurora"": ""http""}} ""priority"": 0 ""lifecycle"": {""http"": {""graceful_shutdown_endpoint"": ""/quitquitquit"" ""port"": ""health"" ""shutdown_endpoint"": ""/abortabortabort""}} ""production"": false ""constraints"": {""host"": ""limit:4""}}) metadata:[] container:<Container docker:DockerContainer(image:http_example)>)=org.apache.aurora.scheduler.storage.db.views.DbTaskConfig@12f27c5c and TaskConfig(job:JobKey(role:vagrant environment:test name:http_example_docker) owner:Identity(role:vagrant user:vagrant) environment:test jobName:http_example_docker isService:true numCpus:0.5 ramMb:34 diskMb:64 priority:0 maxTaskFailures:1 production:false constraints:[Constraint(name:host constraint:<TaskConstraint limit:LimitConstraint(limit:4)>)] requestedPorts:[http] taskLinks:{http=http://%host%:%port:http%} contactEmail:vagrant@localhost executorConfig:ExecutorConfig(name:AuroraExecutor data:{""environment"": ""test"" ""health_check_config"": {""initial_interval_secs"": 5.0 ""endpoint"": ""/health"" ""expected_response_code"": 0 ""expected_response"": ""ok"" ""max_consecutive_failures"": 0 ""timeout_secs"": 1.0 ""interval_secs"": 1.0} ""container"": {""docker"": {""image"": ""http_example"" ""parameters"": []}} ""name"": ""http_example_docker"" ""service"": true ""max_task_failures"": 1 ""cron_collision_policy"": ""KILL_EXISTING"" ""enable_hooks"": false ""cluster"": ""devcluster"" ""task"": {""processes"": [{""daemon"": false ""name"": ""stage_server"" ""ephemeral"": false ""max_failures"": 1 ""min_duration"": 5 ""cmdline"": ""cp /tmp/http_example.py ."" ""final"": false} {""daemon"": false ""name"": ""run_server"" ""ephemeral"": false ""max_failures"": 1 ""min_duration"": 5 ""cmdline"": ""python http_example.py {{thermos.ports[http]}}"" ""final"": false}] ""name"": ""http_example"" ""finalization_wait"": 30 ""max_failures"": 1 ""max_concurrency"": 0 ""resources"": {""disk"": 67108864 ""ram"": 35651584 ""cpu"": 0.5} ""constraints"": [{""order"": [""stage_server"" ""run_server""]}]} ""role"": ""vagrant"" ""contact"": ""vagrant@localhost"" ""announce"": {""primary_port"": ""http"" ""portmap"": {""aurora"": ""http""}} ""priority"": 0 ""lifecycle"": {""http"": {""graceful_shutdown_endpoint"": ""/quitquitquit"" ""port"": ""health"" ""shutdown_endpoint"": ""/abortabortabort""}} ""production"": false ""constraints"": {""host"": ""limit:4""}}) metadata:[] container:<Container docker:DockerContainer(image:http_example)>)=org.apache.aurora.scheduler.storage.db.views.DbTaskConfig@75f259bcom.google.common.util.concurrent.UncheckedExecutionException: java.lang.IllegalArgumentException: Multiple entries with same key: TaskConfig(job:JobKey(role:vagrant environment:test name:http_example_docker) owner:Identity(role:vagrant user:vagrant) environment:test jobName:http_example_docker isService:true numCpus:0.5 ramMb:34 diskMb:64 priority:0 maxTaskFailures:1 production:false constraints:[Constraint(name:host constraint:<TaskConstraint limit:LimitConstraint(limit:4)>)] requestedPorts:[http] taskLinks:{http=http://%host%:%port:http%} contactEmail:vagrant@localhost executorConfig:ExecutorConfig(name:AuroraExecutor data:{""environment"": ""test"" ""health_check_config"": {""initial_interval_secs"": 5.0 ""endpoint"": ""/health"" ""expected_response_code"": 0 ""expected_response"": ""ok"" ""max_consecutive_failures"": 0 ""timeout_secs"": 1.0 ""interval_secs"": 1.0} ""container"": {""docker"": {""image"": ""http_example"" ""parameters"": []}} ""name"": ""http_example_docker"" ""service"": true ""max_task_failures"": 1 ""cron_collision_policy"": ""KILL_EXISTING"" ""enable_hooks"": false ""cluster"": ""devcluster"" ""task"": {""processes"": [{""daemon"": false ""name"": ""stage_server"" ""ephemeral"": false ""max_failures"": 1 ""min_duration"": 5 ""cmdline"": ""cp /tmp/http_example.py ."" ""final"": false} {""daemon"": false ""name"": ""run_server"" ""ephemeral"": false ""max_failures"": 1 ""min_duration"": 5 ""cmdline"": ""python http_example.py {{thermos.ports[http]}}"" ""final"": false}] ""name"": ""http_example"" ""finalization_wait"": 30 ""max_failures"": 1 ""max_concurrency"": 0 ""resources"": {""disk"": 67108864 ""ram"": 35651584 ""cpu"": 0.5} ""constraints"": [{""order"": [""stage_server"" ""run_server""]}]} ""role"": ""vagrant"" ""contact"": ""vagrant@localhost"" ""announce"": {""primary_port"": ""http"" ""portmap"": {""aurora"": ""http""}} ""priority"": 0 ""lifecycle"": {""http"": {""graceful_shutdown_endpoint"": ""/quitquitquit"" ""port"": ""health"" ""shutdown_endpoint"": ""/abortabortabort""}} ""production"": false ""constraints"": {""host"": ""limit:4""}}) metadata:[] container:<Container docker:DockerContainer(image:http_example)>)=org.apache.aurora.scheduler.storage.db.views.DbTaskConfig@12f27c5c and TaskConfig(job:JobKey(role:vagrant environment:test name:http_example_docker) owner:Identity(role:vagrant user:vagrant) environment:test jobName:http_example_docker isService:true numCpus:0.5 ramMb:34 diskMb:64 priority:0 maxTaskFailures:1 production:false constraints:[Constraint(name:host constraint:<TaskConstraint limit:LimitConstraint(limit:4)>)] requestedPorts:[http] taskLinks:{http=http://%host%:%port:http%} contactEmail:vagrant@localhost executorConfig:ExecutorConfig(name:AuroraExecutor data:{""environment"": ""test"" ""health_check_config"": {""initial_interval_secs"": 5.0 ""endpoint"": ""/health"" ""expected_response_code"": 0 ""expected_response"": ""ok"" ""max_consecutive_failures"": 0 ""timeout_secs"": 1.0 ""interval_secs"": 1.0} ""container"": {""docker"": {""image"": ""http_example"" ""parameters"": []}} ""name"": ""http_example_docker"" ""service"": true ""max_task_failures"": 1 ""cron_collision_policy"": ""KILL_EXISTING"" ""enable_hooks"": false ""cluster"": ""devcluster"" ""task"": {""processes"": [{""daemon"": false ""name"": ""stage_server"" ""ephemeral"": false ""max_failures"": 1 ""min_duration"": 5 ""cmdline"": ""cp /tmp/http_example.py ."" ""final"": false} {""daemon"": false ""name"": ""run_server"" ""ephemeral"": false ""max_failures"": 1 ""min_duration"": 5 ""cmdline"": ""python http_example.py {{thermos.ports[http]}}"" ""final"": false}] ""name"": ""http_example"" ""finalization_wait"": 30 ""max_failures"": 1 ""max_concurrency"": 0 ""resources"": {""disk"": 67108864 ""ram"": 35651584 ""cpu"": 0.5} ""constraints"": [{""order"": [""stage_server"" ""run_server""]}]} ""role"": ""vagrant"" ""contact"": ""vagrant@localhost"" ""announce"": {""primary_port"": ""http"" ""portmap"": {""aurora"": ""http""}} ""priority"": 0 ""lifecycle"": {""http"": {""graceful_shutdown_endpoint"": ""/quitquitquit"" ""port"": ""health"" ""shutdown_endpoint"": ""/abortabortabort""}} ""production"": false ""constraints"": {""host"": ""limit:4""}}) metadata:[] container:<Container docker:DockerContainer(image:http_example)>)=org.apache.aurora.scheduler.storage.db.views.DbTaskConfig@75f259b        at com.google.common.cache.LocalCache$Segment.get(LocalCache.java:2201)        at com.google.common.cache.LocalCache.get(LocalCache.java:3934)        at com.google.common.cache.LocalCache.getOrLoad(LocalCache.java:3938)        at com.google.common.cache.LocalCache$LocalLoadingCache.get(LocalCache.java:4821)        at com.google.common.cache.LocalCache$LocalLoadingCache.getUnchecked(LocalCache.java:4827)        at org.apache.aurora.scheduler.storage.db.DbTaskStore.saveTasks(DbTaskStore.java:132)        at com.twitter.common.inject.TimedInterceptor.invoke(TimedInterceptor.java:87)        at org.apache.aurora.scheduler.storage.db.DbTaskStore.mutateTasks(DbTaskStore.java:176)        at com.twitter.common.inject.TimedInterceptor.invoke(TimedInterceptor.java:87)        at org.apache.aurora.scheduler.storage.log.WriteAheadStorage.mutateTasks(WriteAheadStorage.java:195)        at org.apache.aurora.scheduler.state.StateManagerImpl.updateTaskAndExternalState(StateManagerImpl.java:326)        at org.apache.aurora.scheduler.state.StateManagerImpl.insertPendingTasks(StateManagerImpl.java:144)        at org.apache.aurora.scheduler.updater.InstanceActionHandler$AddTask.getReevaluationDelay(InstanceActionHandler.java:85)        at org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.evaluateUpdater(JobUpdateControllerImpl.java:668)        at org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.access$1400(JobUpdateControllerImpl.java:108)        at org.apache.aurora.scheduler.updater.JobUpdateControllerImpl$6.execute(JobUpdateControllerImpl.java:356)        at org.apache.aurora.scheduler.storage.Storage$MutateWork$NoResult.apply(Storage.java:131)        at org.apache.aurora.scheduler.storage.Storage$MutateWork$NoResult$Quiet.apply(Storage.java:148)        at org.apache.aurora.scheduler.storage.log.LogStorage$24.apply(LogStorage.java:605)        at org.apache.aurora.scheduler.storage.log.LogStorage$24.apply(LogStorage.java:602)        at org.apache.aurora.scheduler.storage.db.DbStorage.write(DbStorage.java:143)        at org.mybatis.guice.transactional.TransactionalMethodInterceptor.invoke(TransactionalMethodInterceptor.java:101)        at com.twitter.common.inject.TimedInterceptor.invoke(TimedInterceptor.java:87)        at org.apache.aurora.scheduler.storage.log.LogStorage.doInTransaction(LogStorage.java:602)        at org.apache.aurora.scheduler.storage.log.LogStorage.write(LogStorage.java:635)        at org.apache.aurora.scheduler.storage.CallOrderEnforcingStorage.write(CallOrderEnforcingStorage.java:130)        at org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.instanceChanged(JobUpdateControllerImpl.java:347)        at org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.instanceChangedState(JobUpdateControllerImpl.java:332)        at org.apache.aurora.scheduler.updater.JobUpdateEventSubscriber.taskChangedState(JobUpdateEventSubscriber.java:56)        at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)        at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)        at java.lang.reflect.Method.invoke(Method.java:497)        at com.google.common.eventbus.EventSubscriber.handleEvent(EventSubscriber.java:74)        at com.google.common.eventbus.SynchronizedEventSubscriber.handleEvent(SynchronizedEventSubscriber.java:47)        at com.google.common.eventbus.EventBus.dispatch(EventBus.java:322)        at com.google.common.eventbus.AsyncEventBus.access$001(AsyncEventBus.java:34)        at com.google.common.eventbus.AsyncEventBus$1.run(AsyncEventBus.java:117)        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)        at java.lang.Thread.run(Thread.java:745){noformat}",3,1,2,1,0,Bill Farner,Bill Farner,Bill Farner,4,0,0,0,0,0,0,0
AURORA-1406,Bug,160,Resolved,End-to-end test stalls at SSH prompt,On {{38c2e76}} end-to-end tests stall at this prompt (not sure when specifically this was introduced):{noformat}++ aurora task run devcluster/vagrant/test/http_example lsThe authenticity of host '192.168.33.7 (192.168.33.7)' can't be established.ECDSA key fingerprint is c2:27:21:79:51:2a:cc:49:7d:f8:9b:30:94:e4:e4:ba.Are you sure you want to continue connecting (yes/no)? yes{noformat},2,2,2,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-1409,Bug,160,Resolved,End-to-end tests fail with 401 unuthorized,"Can be consistently reproduced on {{24088ef}}.{noformat}+ kadmin.local -q 'ktadd -keytab testdir/root.keytab root'Authenticating as principal user/admin@KRBTEST.COM with password.Entry for principal root with kvno 2 encryption type aes256-cts-hmac-sha1-96 added to keytab WRFILE:testdir/root.keytab.Entry for principal root with kvno 2 encryption type aes128-cts-hmac-sha1-96 added to keytab WRFILE:testdir/root.keytab.Entry for principal root with kvno 2 encryption type des3-cbc-sha1 added to keytab WRFILE:testdir/root.keytab.Entry for principal root with kvno 2 encryption type arcfour-hmac added to keytab WRFILE:testdir/root.keytab.+ test_snapshot+ snapshot_as vagrant+ local principal=vagrant+ kinit -k -t testdir/vagrant.keytab vagrant++ printf snapshot-response.%s.json vagrant+ curl -u : --negotiate -w '%{http_code}\n' -o snapshot-response.vagrant.json -s http://192.168.33.7:8081/api --data-binary '[1""snapshot""10{}]'401+ kdestroy+ cat snapshot-response.vagrant.json<html><head><meta http-equiv=""Content-Type"" content=""text/html;charset=ISO-8859-1""/><title>Error 401 Unauthorized</title></head><body><h2>HTTP ERROR: 401</h2><p>Problem accessing /api. Reason:<pre>    Unauthorized</pre></p><hr /><i><small>Powered by Jetty://</small></i>                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                </body></html>{noformat}",3,1,2,1,0,Kevin Sweeney,Bill Farner,Bill Farner,2,0,0,0,0,0,0,0
AURORA-97,Task,160,Resolved,Provide a web UI page to show history for a specific job instance,"We currently have dashboard pages for every level of our logical system hierarchy except for ""instance"".Adding this page would be useful for sifting through completed tasks in the scope of a specific instance id.",5,4,3,1,0,Joshua Cohen,Bill Farner,Bill Farner,1,0,1,0,0,0,0,0
AURORA-1410,Task,163,Resolved,Publish RPM and deb for 0.9.0,null,5,3,8,1,0,Bill Farner,Bill Farner,Bill Farner,11,0,1,0,0,0,0,0
AURORA-1429,Story,163,Resolved,Upgrade Mesos to 0.23,Mesos 0.23 was released on July 29th and contains a number of very interesting experimental features and fixes.http://mesos.apache.org/blog/mesos-0-23-0-released/,2,4,4,1,0,Maxim Khutornenko,Dan Norris,Dan Norris,1,1,1,1,1,0,0,0
AURORA-1381,Bug,163,Resolved,Remove duplicate thermos_observer,There are currently two thermos_observer python_binaries in the codebase one in src/main/python/apache/aurora/tools/BUILD and the other in ./src/main/python/apache/thermos/observer/bin/BUILD. This is confusing.Let's get rid of one of them I think the latter is the one that's not meant to be used.,2,4,5,1,0,null,Brian Brazil,Brian Brazil,8,0,1,0,0,0,0,0
AURORA-851,Story,163,Resolved,Create nightly builds,It would be great if we had a Jenkins job that vetted the current state of master and published a nightly build.This would make life easier for folks deploying Aurora from master rather than the (currently anemic) released builds.,3,3,2,1,0,Bill Farner,Joshua Cohen,Joshua Cohen,1,0,0,0,0,0,0,0
AURORA-1415,Task,163,Resolved,De-generalize resource handling in Scheduler,From design doc: {quote}To handle revocable resources correctly Aurora needs to de-generalize and simplify its internal resource representation. The new resource vector should be capable of aggregating resources by revocable flag. This will require refactoring existing resource handling (including  AURORA-105) which will also help to support Mesos framework role in future.{quote},8,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,6,0,0,0,0,0,0,0
AURORA-1421,Task,163,Resolved,Surface revoked task reason in the UI,Need to investigate if fixing AURORA-1193 is still necessary to surface revoked (LOST) task status reason in the UI.,3,3,1,0,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-1395,Bug,163,Resolved,RescheduleCalculator precondition fails when using DbTaskStore,When enabling the DB task store i frequently encounter this exception due to a precondition check fail in RescheduleCalculator:{noformat}E0710 22:33:48.688 THREAD138 org.apache.aurora.scheduler.events.PubsubEventModule$1.handleException: Failed to dispatch event to public void org.apache.aurora.scheduler.async.TaskThrottler.taskChangedState(org.apache.aurora.scheduler.events.PubsubEvent$TaskStateChange): java.lang.IllegalStateExceptionjava.lang.IllegalStateException        at com.google.common.base.Preconditions.checkState(Preconditions.java:161)        at org.apache.aurora.scheduler.async.RescheduleCalculator$RescheduleCalculatorImpl$1.apply(RescheduleCalculator.java:103)        at org.apache.aurora.scheduler.async.RescheduleCalculator$RescheduleCalculatorImpl$1.apply(RescheduleCalculator.java:85)        at org.apache.aurora.scheduler.async.RescheduleCalculator$RescheduleCalculatorImpl.getFlappingPenaltyMs(RescheduleCalculator.java:159)        at org.apache.aurora.scheduler.async.TaskThrottler.taskChangedState(TaskThrottler.java:72)        at sun.reflect.GeneratedMethodAccessor89.invoke(Unknown Source)        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)        at java.lang.reflect.Method.invoke(Method.java:497)        at com.google.common.eventbus.EventSubscriber.handleEvent(EventSubscriber.java:74)        at com.google.common.eventbus.SynchronizedEventSubscriber.handleEvent(SynchronizedEventSubscriber.java:47)        at com.google.common.eventbus.EventBus.dispatch(EventBus.java:322)        at com.google.common.eventbus.AsyncEventBus.access$001(AsyncEventBus.java:34)        at com.google.common.eventbus.AsyncEventBus$1.run(AsyncEventBus.java:117)        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)        at java.lang.Thread.run(Thread.java:745){noformat},5,2,1,1,0,Bill Farner,Bill Farner,Bill Farner,9,0,3,0,0,0,0,0
AURORA-1431,Bug,163,Resolved,Slave reservation is too restrictive,This is a regression introduced in https://reviews.apache.org/r/37001/. The updated TaskAssigner logic looks for an exclusive task->slave match any time a slave reservation is present. Any time scheduling fails and a slave reservation is created by the preemptor a task group gets effectively locked into the reserved slave. Given that reverse slave->task relationship is no longer enforced a reserved slave could be taken by some other task thus slowing down scheduling progress.,3,1,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-1425,Task,163,Resolved,Speed up iteration speed when developing UI code,Developing UI code on Aurora today is quite tedious. While assets are served from the classpath currently the only place they exist on the classpath in the vagrant image is within a jar. This means that any changes to html css or js files requires a build/restart of the scheduler. Ideally these files would be as close to hot reloadable as possible.,5,3,3,1,0,Joshua Cohen,Joshua Cohen,Joshua Cohen,3,0,0,0,0,0,0,0
AURORA-1125,Task,163,Closed,Update page UI should have some indication of ongoing activity,Some thoughts:- The in-progress instance boxes could pulse their background color.- Add a spinner to the bottom of the instance events to indicate that we're continuing to monitor for new events.,3,4,1,0,0,Joshua Cohen,Joshua Cohen,Joshua Cohen,1,0,0,0,0,0,0,0
AURORA-1331,Task,163,Resolved,It should be possible to link to an instance from the update page,E.g. if an instance ran into issues during an update it would be great to be able to link directly to it to investigate the problem (rather than having to go to the job paging and tracking it down in the list of completed tasks).,1,4,1,1,0,Joshua Cohen,Joshua Cohen,Joshua Cohen,1,0,0,0,0,0,0,0
AURORA-97,Task,163,Resolved,Provide a web UI page to show history for a specific job instance,"We currently have dashboard pages for every level of our logical system hierarchy except for ""instance"".Adding this page would be useful for sifting through completed tasks in the scope of a specific instance id.",5,4,3,1,0,Joshua Cohen,Bill Farner,Bill Farner,1,0,1,0,0,0,0,0
AURORA-1427,Task,163,Resolved,Move build-support/packaging to aurora-packaging repo,New repo: https://git-wip-us.apache.org/repos/asf/aurora-packaging.gitGoal is to pull source and history of {{build-support/packaging}} to the new repo and delete it from the source repo.,2,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,3,0,1,1,1,0,0,0
AURORA-1193,Story,163,Resolved,Improve UI task status reporting experience,"Mesos may append an optional message with task status update that is currently surfacing in the UI via TaskEvent. These messages may not be user friendly and add confusion. One example is ""Unregistered executor"" issued when Mesos kills an assigned task that did not have a chance to run yet. While this message does not constitute a failure it may create an illusion of abnormal behavior in an otherwise normal operation.Consider filtering/formatting messages in the UI/scheduler to avoid adverse user experience. The ideal solution should also leverage TaskStatus.reason field to show additional status details.",2,4,2,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,4,0,0,0,0,0,0,0
AURORA-1435,Bug,163,Resolved,Scheduling loop terminates on the first mismatch,This is the regression introduced in https://reviews.apache.org/r/37001/ and is happening due to scheduling loop exiting prematurely when the first mismatch is identified: https://github.com/apache/aurora/blob/cbc42c484cc599d41d5a4bd23c373a64e9b71466/src/main/java/org/apache/aurora/scheduler/state/TaskAssigner.java#L189,2,1,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-1430,Story,163,Resolved,Set up vagrant environment for sudo-less docker commands,Our vagrant development box has docker installed but we should take the extra steps to run docker commands without {{sudo}}.  See commands required here: http://askubuntu.com/questions/477551/how-can-i-use-docker-without-sudo/477554#477554,1,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,1,0,0,0,0,0,0,0
AURORA-1410,Task,174,Resolved,Publish RPM and deb for 0.9.0,null,5,3,8,1,0,Bill Farner,Bill Farner,Bill Farner,11,0,1,0,0,0,0,0
AURORA-1429,Story,174,Resolved,Upgrade Mesos to 0.23,Mesos 0.23 was released on July 29th and contains a number of very interesting experimental features and fixes.http://mesos.apache.org/blog/mesos-0-23-0-released/,2,4,4,1,0,Maxim Khutornenko,Dan Norris,Dan Norris,1,1,1,1,1,0,0,0
AURORA-1417,Task,174,Resolved,Handle revocable resources in scheduler,From design doc:{quote}The TaskAssigner will need to be adjusted to look only at revocable resources for best effort tasks....The OfferManager should maintain a new offer sequence sorted by the presence of revocable resources. This will be used to match best effort tasks.{quote},null,3,1,0,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-1437,Task,174,Resolved,Implement TierManager to translate tiers to task traits,From design doc:{quote}Scheduler will have a new TierManager module translating the task tier into the correspondent set of traits. Initial implementation will statically define test devel staging tier values as revocable. {quote},3,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,2,0,0,0,0,0,0,0
AURORA-1418,Task,174,Resolved,Ignore revocable resources in preemptor,From design doc:{quote}Preemptor needs to ignore best effort task resources when searching for preemption slots.{quote},2,3,2,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,5,0,0,0,0,0,0,0
AURORA-1419,Task,174,Resolved,FrameworkInfo support for REVOCABLE_RESOURCES capability,From design doc:{quote}In order to start receiving revocable offers Aurora will be required to register with REVOCABLE_RESOURCES flag set as a new capability type.{quote},2,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-1414,Task,174,Resolved,Schema changes to support revocable jobs,null,3,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-851,Story,174,Resolved,Create nightly builds,It would be great if we had a Jenkins job that vetted the current state of master and published a nightly build.This would make life easier for folks deploying Aurora from master rather than the (currently anemic) released builds.,3,3,2,1,0,Bill Farner,Joshua Cohen,Joshua Cohen,1,0,0,0,0,0,0,0
AURORA-647,Story,174,Resolved,Don't store serialized thrift objects in the database,To expedite AURORA-610 we accepted some technical debt by storing serialized thrift objects in the database.  Once the database is completely fronted by SQL we need to go back and manage these objects with references to other tables.,3,3,1,1,0,Bill Farner,Bill Farner,Bill Farner,3,0,2,1,1,0,0,0
AURORA-1213,Story,174,Resolved,IP clearance and import of twitter commons java code,We currently have 32  dependencies on libraries from Twitter commons.  {noformat}$ grep com.twitter.common build.gradle  | wc -l      32{noformat}While these libraries have generally served us well this number of dependencies creates a transitive web that inhibits us from upgrading our direct dependencies.Consider removing these dependencies and replacing our uses of them with forks of the code in our repository.  My hunch is that we use relatively insignificant portions of them overall.  However if we end up just cloning the sources and maintaining them ourselves we should back out.,8,4,4,1,0,Zameer Manji,Bill Farner,Bill Farner,9,0,4,1,1,0,0,0
AURORA-1331,Task,174,Resolved,It should be possible to link to an instance from the update page,E.g. if an instance ran into issues during an update it would be great to be able to link directly to it to investigate the problem (rather than having to go to the job paging and tracking it down in the list of completed tasks).,1,4,1,1,0,Joshua Cohen,Joshua Cohen,Joshua Cohen,1,0,0,0,0,0,0,0
AURORA-97,Task,174,Resolved,Provide a web UI page to show history for a specific job instance,"We currently have dashboard pages for every level of our logical system hierarchy except for ""instance"".Adding this page would be useful for sifting through completed tasks in the scope of a specific instance id.",5,4,3,1,0,Joshua Cohen,Bill Farner,Bill Farner,1,0,1,0,0,0,0,0
AURORA-1439,Task,174,Resolved,Modify resource counters to support revocable slot counters,null,3,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-1442,Task,174,Resolved,Move Twitter Commons into org.apache.aurora namespace and add headers,Once AURORA-1213 is complete the code imported from Twitter Commons needs to be moved into the org.apache.aurora namespace and the license headers need to be changed to show Apache copyright. I believe this can be done quickly with automation.,null,3,1,1,0,Zameer Manji,Zameer Manji,Zameer Manji,2,0,1,1,1,0,0,0
AURORA-696,Story,174,Resolved,No way to link directly to Completed Tasks,"I want to send someone a link directly pointing to the ""Completed Tasks"" page on http://scheduler:8081/scheduler/jaybuff/devel/hello-worldCurrently that will take them to active tasks then they have to click ""completed tasks"" ",2,3,3,1,0,Joshua Cohen,Jay Buffington,Jay Buffington,2,0,0,0,0,0,0,0
AURORA-1441,Task,179,Resolved,Document oversubscription in Aurora,null,2,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-1462,Task,179,Resolved,Update quota documentation,null,1,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-1491,Task,179,Resolved,"Make ""aurora task"" commands support optional ssh options","The ""aurora task"" commands should pass ""-v"" flag down to subprocess to make sure ""ssh -v"" is invoked. Otherwise it's impossible to debug command failures due to misbehaving ssh.",2,4,3,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,3,0,0,0,0,0,0,0
AURORA-1459,Bug,179,Resolved,DelayExecutor is flaky within scheduling loop,TaskGroups now uses DelayExecutor introduced to gate async operations. The problem though is that DelayExecutor queue is only flushed on DB transaction completion (1). This means no scheduling can ever proceed unless there is _some_ storage mutation activity. If/when there are no storage writes scheduling effectively halts. While it unlikely to happen in production it is consistently reproducible with e2e tests in vagrant on any subsequent run.(1) - https://github.com/apache/aurora/blob/06ddaadbcba4c66b8019815de6ca27d50a9df77d/src/main/java/org/apache/aurora/scheduler/storage/db/DbStorage.java#L175-L178,5,3,3,1,0,Bill Farner,Maxim Khutornenko,Maxim Khutornenko,3,0,0,0,0,0,0,0
AURORA-1345,Bug,179,Resolved,Update status page for large jobs is killed by Chrome,"When I say ""killed by Chrome"" I mean if left open long enough the page turns into the Chrome ""Aw Snap"" page.This is presumably due to the continued addition of instance events to the page causing it to OOM and Chrome to kill it. One suggestion made to me by those more familiar with Angular was to add {{track by}} to the {{ng-repeat}} used to build the DOM for the instance events.",5,3,1,1,0,Joshua Cohen,Joshua Cohen,Joshua Cohen,1,0,0,0,0,0,0,0
AURORA-783,Story,179,Resolved,Remove redundant page header text,The scheduler web interface has a breadcrumb:{noformat}Home Role: www-data  Environment: devel  Job: hello_world{noformat}And a large heading:{noformat}Job hello_world in role www-data and environment devel{noformat}Consider removing the heading text as it consumes a lot of real-estate and is redundant to the breadcrumb.,2,3,3,1,0,Joshua Cohen,Bill Farner,Bill Farner,8,0,1,0,0,0,0,0
AURORA-1460,Task,179,Resolved,Remove quota enforcement for dedicated jobs,null,3,3,2,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,2,0,0,0,0,0,0,0
AURORA-1461,Task,179,Resolved,Update RPCs and client/UI to properly identify non-dedicated consumption,null,2,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,2,0,0,0,0,0,0,0
AURORA-1464,Task,179,Resolved,Add e2e integration tests for revocable tasks,null,3,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-1445,Bug,179,Resolved,In-progress instances on Update page continue to pulse after update is aborted,When an update is aborted any instances that were in progress still have the css class of {{instance-updating}} and as such continue to pulse.,3,4,1,1,0,Joshua Cohen,Joshua Cohen,Joshua Cohen,1,0,0,0,0,0,0,0
AURORA-696,Story,179,Resolved,No way to link directly to Completed Tasks,"I want to send someone a link directly pointing to the ""Completed Tasks"" page on http://scheduler:8081/scheduler/jaybuff/devel/hello-worldCurrently that will take them to active tasks then they have to click ""completed tasks"" ",2,3,3,1,0,Joshua Cohen,Jay Buffington,Jay Buffington,2,0,0,0,0,0,0,0
AURORA-1474,Story,179,Resolved,Improve discoverability of dashboard link on the Job page,We optionally link to a job dashboard from the Job page (if {{viz_job_url_prefix}} is passed to the Scheduler on the command line). The icon for this is currently uses glyphicons halflings font stats glyph (depending on how you view it a series of 3 vertical bars or a series of hills). It's not at all obvious that this link takes you anywhere interesting. We should revisit the discoverability of this link.,1,3,1,1,0,Joshua Cohen,Joshua Cohen,Joshua Cohen,1,0,0,0,0,0,0,0
AURORA-1441,Task,190,Resolved,Document oversubscription in Aurora,null,2,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-1462,Task,190,Resolved,Update quota documentation,null,1,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-1494,Bug,190,Resolved,Scheduler fails to start due to thrift/SQL schema data type mismatch,"After https://reviews.apache.org/r/38288 we are unable to upgrade scheduler in one of our clusters due to the following failure on restart:{noformat}### Cause: org.h2.jdbc.JdbcSQLException: Numeric value out of range: ""3174400000031744""; SQL statement:INSERT INTO task_configs (      job_key_id      creator_user      service      num_cpus      ram_mb      disk_mb      priority      max_task_failures      production      contact_email      executor_name      executor_data      tier    ) VALUES (      (        SELECT ID        FROM job_keys        WHERE role = ?          AND environment = ?          AND name = ?      )      ?      ?      ?      ?      ?      ?      ?      ?      ?{noformat}This appears due to type mismatch between TaskConfig.diskMb (i64) and task_configs.disk_mb (INT). A possible real-life scenario:- user creates a job with an oversized resource requirement and the job fails to schedule- user realizes the mistake and attempts to correct it by running {{aurora update start}}- scheduler creates an instance of the JobUpdate with the oversized TaskConfig as its initial state and persists it in the log- scheduler restarts to a new version (with the patch above) and attempts to reload job updates from the log but now instead of storing TaskConfigs as binary blobs it attempts to insert into task_configs table where resource columns have narrower type. ",3,1,2,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,1,1,1,0,0,0
AURORA-1491,Task,190,Resolved,"Make ""aurora task"" commands support optional ssh options","The ""aurora task"" commands should pass ""-v"" flag down to subprocess to make sure ""ssh -v"" is invoked. Otherwise it's impossible to debug command failures due to misbehaving ssh.",2,4,3,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,3,0,0,0,0,0,0,0
AURORA-1503,Task,191,Resolved,Determine how best to keep up with Mesos releases,Aurora 0.9.0 was released with a dependency on Mesos 0.22. The current release is Mesos 0.24. There was a change with how data was published into the Mesos ZK node in Mesos 0.23 (Protobuf to JSON) meaning that frameworks that are linked against 0.22 will get a libmesos error when using the 0.24 library.The task is to determine what is the best way forward in scenarios like this. Possible options include:* Release 0.9.x with a newer mesos dependency* Cut a new release from master that depends on 0.24Problems include backwards/forwards compatibility. For example if we release 0.9.1 with a dependency on Mesos 0.24 will Aurora still work against a Mesos Master that runs 0.22?,3,3,10,1,0,Zameer Manji,Zameer Manji,Zameer Manji,7,1,0,0,0,0,0,0
AURORA-1502,Task,191,Resolved,Create a design summary for the jobConfigDiff RPC,null,5,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-1503,Task,197,Resolved,Determine how best to keep up with Mesos releases,Aurora 0.9.0 was released with a dependency on Mesos 0.22. The current release is Mesos 0.24. There was a change with how data was published into the Mesos ZK node in Mesos 0.23 (Protobuf to JSON) meaning that frameworks that are linked against 0.22 will get a libmesos error when using the 0.24 library.The task is to determine what is the best way forward in scenarios like this. Possible options include:* Release 0.9.x with a newer mesos dependency* Cut a new release from master that depends on 0.24Problems include backwards/forwards compatibility. For example if we release 0.9.1 with a dependency on Mesos 0.24 will Aurora still work against a Mesos Master that runs 0.22?,3,3,10,1,0,Zameer Manji,Zameer Manji,Zameer Manji,7,1,0,0,0,0,0,0
AURORA-1516,Task,197,Resolved,"Add update sequence into ""aurora job diff"" command",null,3,3,3,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,2,0,0,0,0,0,0,0
AURORA-1515,Task,197,Resolved,Implement getJobUpdateDiff API without TaskConfig diff support,null,3,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-814,Task,197,Resolved,Migrate client off of deprecated SessionKey APIs,Remove SessionKey injection from the scheduler client instead relying on transport-level authentication.,3,3,3,1,0,Bill Farner,Chris Lambert,Chris Lambert,5,0,2,1,1,0,0,0
AURORA-1522,Bug,197,Resolved,ShiroAuthorizationInterceptor doesn't set thriftAPIVersion,This is because the auth interceptor is applied first. Client users get a confusing error message about the response missing a thriftAPIVersion attribute rather than the AUTH_FAILED message as intended.,null,3,2,0,0,null,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-1511,Bug,203,Resolved,PreemptorService failure does not trigger shutdown,"While observing AURORA-1510 in production I noticed the bug caused the {{PreemptorService}} to transition to the FAILED state. The {{/services}} endpoint had:{noformat}{name: ""PreemptorService""state: ""FAILED""failureCause: ""java.util.ConcurrentModificationException""}{noformat}However the scheduler continued to run. I believe this is a bug.",2,3,3,1,0,Zameer Manji,Zameer Manji,Zameer Manji,4,0,1,0,0,0,0,0
AURORA-1364,Story,203,Resolved,Improve client error messages for Kerberos errors,Currently Kerberos errors are presented as a stack trace to the user looking something like:{noformat}GSSError: (('Unspecified GSS failure.  Minor code may provide more information' 851968) ('No Kerberos credentials available' -1765328243))401 Client Error: Authorization Required{noformat}(And similar for expired tickets). It would be helpful to catch these and display more useful information such as a suggestion to run {{kinit}}.,2,4,2,1,0,Maxim Khutornenko,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-1510,Bug,203,Resolved,ConcurrentModificationException in PreemptorService,On the latest master code:{noformat}E1001 03:41:58.910 THREAD595 com.google.common.util.concurrent.ServiceManager$ServiceListener.failed: Service PreemptorService [FAILED] has failed in the RUNNING state.java.util.ConcurrentModificationException        at java.util.HashMap$HashIterator.nextNode(HashMap.java:1429)        at java.util.HashMap$EntryIterator.next(HashMap.java:1463)        at java.util.HashMap$EntryIterator.next(HashMap.java:1461)        at com.google.common.collect.AbstractMapBasedMultimap$KeySet$1.next(AbstractMapBasedMultimap.java:936)        at java.util.Collections$UnmodifiableCollection$1.next(Collections.java:1042)        at com.google.common.collect.Iterators$5.next(Iterators.java:558)        at com.google.common.collect.Iterators.addAll(Iterators.java:362)        at com.google.common.collect.Sets.newHashSet(Sets.java:238)        at com.google.common.collect.Sets.newHashSet(Sets.java:218)        at org.apache.aurora.scheduler.preemptor.PendingTaskProcessor$1.apply(PendingTaskProcessor.java:134)        at org.apache.aurora.scheduler.preemptor.PendingTaskProcessor$1.apply(PendingTaskProcessor.java:119)        at org.apache.aurora.scheduler.storage.db.DbStorage.read(DbStorage.java:138)        at org.mybatis.guice.transactional.TransactionalMethodInterceptor.invoke(TransactionalMethodInterceptor.java:101)        at org.apache.aurora.common.inject.TimedInterceptor.invoke(TimedInterceptor.java:84)        at org.apache.aurora.scheduler.storage.log.LogStorage.read(LogStorage.java:659)        at org.apache.aurora.scheduler.storage.CallOrderEnforcingStorage.read(CallOrderEnforcingStorage.java:115)        at org.apache.aurora.scheduler.preemptor.PendingTaskProcessor.run(PendingTaskProcessor.java:119)        at org.apache.aurora.scheduler.preemptor.PreemptorModule$PreemptorService.runOneIteration(PreemptorModule.java:148)        at com.google.common.util.concurrent.AbstractScheduledService$1$1.run(AbstractScheduledService.java:174)        at com.google.common.util.concurrent.Callables$3.run(Callables.java:95)        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)        at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)        at java.lang.Thread.run(Thread.java:745){noformat},2,2,2,1,0,Zameer Manji,Zameer Manji,Zameer Manji,3,0,1,0,0,0,0,0
AURORA-1522,Bug,203,Resolved,ShiroAuthorizationInterceptor doesn't set thriftAPIVersion,This is because the auth interceptor is applied first. Client users get a confusing error message about the response missing a thriftAPIVersion attribute rather than the AUTH_FAILED message as intended.,null,3,2,0,0,null,Kevin Sweeney,Kevin Sweeney,1,0,0,0,0,0,0,0
AURORA-1506,Bug,211,Resolved,Job updater does not handle DELETED tasks properly,We have observed cases when job updater fails to correctly process tasks that were deleted from the store (e.g. PENDING or THROTTLED being killed). Sample log:{noformat}I0929 00:01:59.101 THREAD4453 org.apache.aurora.scheduler.updater.JobUpdateControllerImpl$6.execute: Forwarding task change for role/staging/job/1I0929 00:01:59.103 THREAD4453 org.apache.aurora.scheduler.updater.InstanceUpdater.handleActualAndDesiredPresent: Task is in terminal state FAILEDI0929 00:01:59.103 THREAD4453 org.apache.aurora.scheduler.updater.InstanceUpdater.addFailureAndCheckIfFailed: Observed updated task failure.I0929 00:01:59.103 THREAD4453 org.apache.aurora.common.util.StateMachine$Builder$1.execute: Instance 1 state machine transition WORKING -> FAILEDI0929 00:01:59.103 THREAD4453 org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.evaluateUpdater: IJobUpdateKey{job=IJobKey{role=role environment=staging name=job} id=38889720-36e4-4640-99c5-399ebf3a68a0} evaluation result: EvaluationResult{status=FAILED sideEffects={1=SideEffect{action=Optional.absent() statusChanges=[FAILED]}}}I0929 00:01:59.103 THREAD4453 org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.changeJobUpdateStatus: Update IJobUpdateKey{job=IJobKey{role=role environment=staging name=job} id=38889720-36e4-4640-99c5-399ebf3a68a0} is now in state ROLLING_BACKI0929 00:01:59.112 THREAD4453 org.apache.aurora.common.util.StateMachine$Builder$1.execute: Instance 1 state machine transition IDLE -> WORKINGI0929 00:01:59.112 THREAD4453 org.apache.aurora.scheduler.updater.OneWayJobUpdater.startNextInstanceGroup: Changed working set for update to [1]I0929 00:01:59.112 THREAD4453 org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.evaluateUpdater: IJobUpdateKey{job=IJobKey{role=role environment=staging name=job} id=38889720-36e4-4640-99c5-399ebf3a68a0} evaluation result: EvaluationResult{status=WORKING sideEffects={1=SideEffect{action=Optional.of(KILL_TASK) statusChanges=[WORKING]}}}I0929 00:01:59.113 THREAD4453 org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.evaluateUpdater: Executing side-effects for update of IJobUpdateKey{job=IJobKey{role=role environment=staging name=job} id=38889720-36e4-4640-99c5-399ebf3a68a0}: {1=SideEffect{action=Optional.of(KILL_TASK) statusChanges=[WORKING]}}I0929 00:01:59.113 THREAD4453 org.apache.aurora.scheduler.updater.InstanceActionHandler$KillTask.getReevaluationDelay: Killing IInstanceKey{jobKey=IJobKey{role=role environment=staging name=job} instanceId=1} while ROLLING_BACKI0929 00:01:59.113 THREAD4453 org.apache.aurora.common.util.StateMachine$Builder$1.execute: 1443484918618-role-staging-job-1-5d1301fb-5bd8-4d51-b4b9-fd9115d766f0 state machine transition THROTTLED -> KILLINGI0929 00:01:59.113 THREAD4453 org.apache.aurora.scheduler.state.TaskStateMachine.addFollowup: Adding work command DELETE for 1443484918618-role-staging-job-1-5d1301fb-5bd8-4d51-b4b9-fd9115d766f0{noformat}Later on when a task change event is received the updater attempts to run evaluator again but this time can't find a task that has just being DELETED:{noformat}I0929 00:01:59.382 THREAD4454 org.apache.aurora.scheduler.updater.JobUpdateControllerImpl$6.execute: Forwarding task change for role/staging/job/1I0929 00:01:59.385 THREAD4454 org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.evaluateUpdater: IJobUpdateKey{job=IJobKey{role=role environment=staging name=job} id=38889720-36e4-4640-99c5-399ebf3a68a0} evaluation result: EvaluationResult{status=WORKING sideEffects={1=SideEffect{action=Optional.of(KILL_TASK) statusChanges=[]}}}I0929 00:01:59.385 THREAD4454 org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.evaluateUpdater: Executing side-effects for update of IJobUpdateKey{job=IJobKey{role=role environment=staging name=job} id=38889720-36e4-4640-99c5-399ebf3a68a0}: {1=SideEffect{action=Optional.of(KILL_TASK) statusChanges=[]}}E0929 00:01:59.386 THREAD4454 org.apache.aurora.scheduler.updater.JobUpdateEventSubscriber.taskChangedState: Failed to handle state change: java.util.NoSuchElementExceptionjava.util.NoSuchElementException        at com.google.common.collect.Iterators$1.next(Iterators.java:80)        at com.google.common.collect.Iterators.getOnlyElement(Iterators.java:302)        at com.google.common.collect.Iterables.getOnlyElement(Iterables.java:289)        at org.apache.aurora.scheduler.updater.InstanceActionHandler$KillTask.getReevaluationDelay(InstanceActionHandler.java:104)        at org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.evaluateUpdater(JobUpdateControllerImpl.java:668)        at org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.access$1400(JobUpdateControllerImpl.java:108)        at org.apache.aurora.scheduler.updater.JobUpdateControllerImpl$6.execute(JobUpdateControllerImpl.java:356)        at org.apache.aurora.scheduler.storage.Storage$MutateWork$NoResult.apply(Storage.java:137)        at org.apache.aurora.scheduler.storage.Storage$MutateWork$NoResult.apply(Storage.java:132)        at org.apache.aurora.scheduler.storage.log.LogStorage$24.apply(LogStorage.java:614)        at org.apache.aurora.scheduler.storage.log.LogStorage$24.apply(LogStorage.java:611)        at org.apache.aurora.scheduler.storage.db.DbStorage.transactionedWrite(DbStorage.java:146)        at org.mybatis.guice.transactional.TransactionalMethodInterceptor.invoke(TransactionalMethodInterceptor.java:101)        at org.apache.aurora.scheduler.storage.db.DbStorage$2.doWithGateClosed(DbStorage.java:162)        at org.apache.aurora.scheduler.async.GatingDelayExecutor.closeDuring(GatingDelayExecutor.java:62)        at org.apache.aurora.scheduler.storage.db.DbStorage.write(DbStorage.java:158)        at org.apache.aurora.common.inject.TimedInterceptor.invoke(TimedInterceptor.java:84)        at org.apache.aurora.scheduler.storage.log.LogStorage.doInTransaction(LogStorage.java:611)        at org.apache.aurora.scheduler.storage.log.LogStorage.write(LogStorage.java:644)        at org.apache.aurora.scheduler.storage.CallOrderEnforcingStorage.write(CallOrderEnforcingStorage.java:130)        at org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.instanceChanged(JobUpdateControllerImpl.java:347)        at org.apache.aurora.scheduler.updater.JobUpdateControllerImpl.instanceChangedState(JobUpdateControllerImpl.java:332)        at org.apache.aurora.scheduler.updater.JobUpdateEventSubscriber.taskChangedState(JobUpdateEventSubscriber.java:56)        at sun.reflect.GeneratedMethodAccessor121.invoke(Unknown Source)        at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)        at java.lang.reflect.Method.invoke(Method.java:497)        at com.google.common.eventbus.EventSubscriber.handleEvent(EventSubscriber.java:74)        at com.google.common.eventbus.SynchronizedEventSubscriber.handleEvent(SynchronizedEventSubscriber.java:47)        at com.google.common.eventbus.EventBus.dispatch(EventBus.java:322)        at com.google.common.eventbus.AsyncEventBus.access$001(AsyncEventBus.java:34)        at com.google.common.eventbus.AsyncEventBus$1.run(AsyncEventBus.java:117)        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)        at java.util.concurrent.FutureTask.run(FutureTask.java:266)        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)        at java.lang.Thread.run(Thread.java:745){noformat},5,3,2,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,2,0,0,0,0,0,0,0
AURORA-1250,Task,211,Resolved,0.10.0 release candidate,null,3,3,4,1,0,Zameer Manji,Bill Farner,Bill Farner,2,0,4,3,3,0,0,0
AURORA-1258,Story,212,Resolved,Improve procedure for adding instances to a job,The current process for adding instances to a job is highly manual and potentially dangerous.1. Take a config for a job with 10 instances update it to 20 instances.2. The batch size will be increased and users will need to specify shards 10 to 19.3. After this update is complete users will need to manually update shards 0-9 again.There may be other changes pulled in as part of this update other than just increasing the number of instances which could further complicate things.One possible improvement would be to change the updater from 'under-provision' where it kills instances first then schedules new instances to an 'over-provision' where it adds on new instances then backpedals and kills the old instances.Overall a single command or process for a user to take an already-existing job and increase the number of instances would reduce overhead and fat-fingering.,8,3,7,1,0,Maxim Khutornenko,Joe Smith,Joe Smith,12,2,0,0,0,0,0,0
AURORA-1582,Bug,212,Resolved,Task History Pruning attempts can fail silently,As discovered in AURORA-1580 task history pruning attempts can fail and if they do fail they fail silently. The root cause seems to be that AsyncModule's {{AsyncProcessor}} threads just log the unhandled exception if it exists:{noformat}  private static void evaluateResult(Runnable runnable Throwable throwable Logger logger) {    // See java.util.concurrent.ThreadPoolExecutor#afterExecute(Runnable Throwable)    // for more details and an implementation example.    if (throwable == null) {      if (runnable instanceof Future) {        try {          Future<?> future = (Future<?>) runnable;          if (future.isDone()) {            future.get();          }        } catch (InterruptedException ie) {          Thread.currentThread().interrupt();        } catch (ExecutionException ee) {          logger.error(ee.toString() ee);        }      }    } else {      logger.error(throwable.toString() throwable);    }  }{noformat}I think instead of silently failing if work on these threads fail we should shut down the scheduler much like how if the preemptor or other guava service fails we shut down the scheduler. This way the scheduler does not enter an undefined state and operators are informed of the abnormal behaviour.,3,3,1,1,0,Zameer Manji,Zameer Manji,Zameer Manji,4,0,3,0,0,0,0,0
AURORA-1583,Task,212,Resolved,Consider changing killTasks RPC to be job-scoped,The killTasks RPC signature currently allows killing tasks across multiple jobs/roles and even killing the entire cluster. Consider refactoring {{TaskQuery}} parameter to something like {{JobKey + instanceIds}} instead.,null,3,2,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-1607,Bug,220,Resolved,"Persistent ""Error accessing PooledConnection. Connection is invalid"" exceptions with DbTaskStore enabled",Even after the resolution of AURORA-1596 (adding a ping query) I still see exceptions like this in the log:{noformat}Feb 02 2016 11:24:01 PM com.google.common.util.concurrent.ServiceManager$ServiceListener failedSEVERE: Service PreemptorService [FAILED] has failed in the RUNNING state.org.apache.ibatis.exceptions.PersistenceException: ### Error rolling back transaction.  Cause: java.sql.SQLException: Error accessing PooledConnection. Connection is invalid.### Cause: java.sql.SQLException: Error accessing PooledConnection. Connection is invalid.at org.apache.ibatis.exceptions.ExceptionFactory.wrapException(ExceptionFactory.java:30)at org.apache.ibatis.session.defaults.DefaultSqlSession.rollback(DefaultSqlSession.java:216)at org.apache.ibatis.session.SqlSessionManager.rollback(SqlSessionManager.java:299)at org.mybatis.guice.transactional.TransactionalMethodInterceptor.invoke(TransactionalMethodInterceptor.java:116)at org.apache.aurora.common.inject.TimedInterceptor.invoke(TimedInterceptor.java:83)at org.apache.aurora.scheduler.storage.log.LogStorage.read(LogStorage.java:570)at org.apache.aurora.scheduler.storage.CallOrderEnforcingStorage.read(CallOrderEnforcingStorage.java:113)at org.apache.aurora.scheduler.preemptor.PendingTaskProcessor.run(PendingTaskProcessor.java:119)at org.apache.aurora.scheduler.preemptor.PreemptorModule$PreemptorService.runOneIteration(PreemptorModule.java:145)at com.google.common.util.concurrent.AbstractScheduledService$ServiceDelegate$Task.run(AbstractScheduledService.java:189)at com.google.common.util.concurrent.Callables$3.run(Callables.java:100)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)at java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$301(ScheduledThreadPoolExecutor.java:180)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:294)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)at java.lang.Thread.run(Thread.java:745)Caused by: java.sql.SQLException: Error accessing PooledConnection. Connection is invalid.at org.apache.ibatis.datasource.pooled.PooledConnection.checkConnection(PooledConnection.java:254)at org.apache.ibatis.datasource.pooled.PooledConnection.invoke(PooledConnection.java:243)at com.sun.proxy.$Proxy130.getAutoCommit(Unknown Source)at org.apache.ibatis.transaction.jdbc.JdbcTransaction.rollback(JdbcTransaction.java:79)at org.apache.ibatis.executor.BaseExecutor.rollback(BaseExecutor.java:249)at org.apache.ibatis.executor.CachingExecutor.rollback(CachingExecutor.java:119)at org.apache.ibatis.session.defaults.DefaultSqlSession.rollback(DefaultSqlSession.java:213)... 16 moreE0202 23:24:01.414 [PreemptorService RUNNING GuavaUtils$LifecycleShutdownListener:53] Service: PreemptorService [FAILED] failed unexpectedly. Triggering shutdown. I0202 23:24:01.414 [PreemptorService RUNNING Lifecycle:84] Shutting down application {noformat}To me this signals a problem in the mybatis connection pool implementation. Enabling verbose logging in all database related code does not show anything obvious in the logs.,null,3,2,0,0,Zameer Manji,Zameer Manji,Zameer Manji,8,0,1,0,0,0,0,0
AURORA-1258,Story,220,Resolved,Improve procedure for adding instances to a job,The current process for adding instances to a job is highly manual and potentially dangerous.1. Take a config for a job with 10 instances update it to 20 instances.2. The batch size will be increased and users will need to specify shards 10 to 19.3. After this update is complete users will need to manually update shards 0-9 again.There may be other changes pulled in as part of this update other than just increasing the number of instances which could further complicate things.One possible improvement would be to change the updater from 'under-provision' where it kills instances first then schedules new instances to an 'over-provision' where it adds on new instances then backpedals and kills the old instances.Overall a single command or process for a user to take an already-existing job and increase the number of instances would reduce overhead and fat-fingering.,8,3,7,1,0,Maxim Khutornenko,Joe Smith,Joe Smith,12,2,0,0,0,0,0,0
AURORA-1600,Bug,220,Resolved,Job updates with large count of instance overrides halt scheduler perf,We have observed a case when a user update with a large number of specified instance overrides (updateOnlyTheseInstances) results in significant performance deterioration to the extent of scheduler processing almost no offers and not scheduling any pending tasks for long periods (minutes to hours). The culprit appears to be the {{selectInstructions}} query. It's unacceptably slow when number of instanceConfigs and/or instance overrides approaches 100. Since it's called inside a write lock to guide individual instance updates nothing else can proceed including status updates and offer activities. I was able to replicate this in jmh. Fix is incoming.,null,2,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,3,0,0,0,0,0,0,0
AURORA-1603,Bug,220,Resolved,Scheduler fails to start after rollback,We had to rollback scheduler due to the duplicate instances in the UI and when tried to restart on the older version (8d3fb2413306387bc533b1b800bbc97149f96b26) got the following error preventing scheduler from loading snapshot:{noformat}To index multiple values under a key use Multimaps.index.        at com.google.common.collect.Maps.uniqueIndex(Maps.java:1215) ~[guava-19.0.jar:na]        at com.google.common.collect.Maps.uniqueIndex(Maps.java:1173) ~[guava-19.0.jar:na]        at org.apache.aurora.scheduler.storage.db.TaskConfigManager.getConfigRow(TaskConfigManager.java:46) ~[aurora-113.jar:na]        at org.apache.aurora.scheduler.storage.db.TaskConfigManager.insert(TaskConfigManager.java:57) ~[aurora-113.jar:na]        at org.apache.aurora.scheduler.storage.db.DbJobUpdateStore.saveJobUpdate(DbJobUpdateStore.java:125) ~[aurora-113.jar:na]        at org.apache.aurora.common.inject.TimedInterceptor.invoke(TimedInterceptor.java:83) ~[commons-113.jar:na]        at org.apache.aurora.scheduler.storage.log.SnapshotStoreImpl$7.restoreFromSnapshot(SnapshotStoreImpl.java:208) ~[aurora-113.jar:na]        at org.apache.aurora.scheduler.storage.log.SnapshotStoreImpl.lambda$applySnapshot$238(SnapshotStoreImpl.java:278) ~[aurora-113.jar:na]        at org.apache.aurora.scheduler.storage.Storage$MutateWork$NoResult.apply(Storage.java:137) ~[aurora-113.jar:na]        at org.apache.aurora.scheduler.storage.Storage$MutateWork$NoResult.apply(Storage.java:132) ~[aurora-113.jar:na]        at org.apache.aurora.scheduler.storage.db.DbStorage.transactionedWrite(DbStorage.java:146) ~[aurora-113.jar:na]        at org.mybatis.guice.transactional.TransactionalMethodInterceptor.invoke(TransactionalMethodInterceptor.java:101) ~[mybatis-guice-3.7.jar:3.7]        at org.apache.aurora.scheduler.storage.db.DbStorage.lambda$write$203(DbStorage.java:160) ~[aurora-113.jar:na]        at org.apache.aurora.scheduler.async.GatingDelayExecutor.closeDuring(GatingDelayExecutor.java:62) ~[aurora-113.jar:na]        at org.apache.aurora.scheduler.storage.db.DbStorage.write(DbStorage.java:158) ~[aurora-113.jar:na]        at org.apache.aurora.common.inject.TimedInterceptor.invoke(TimedInterceptor.java:83) ~[commons-113.jar:na]        at org.apache.aurora.scheduler.storage.log.SnapshotStoreImpl.applySnapshot(SnapshotStoreImpl.java:274) ~[aurora-113.jar:na]        at org.apache.aurora.common.inject.TimedInterceptor.invoke(TimedInterceptor.java:83) ~[commons-113.jar:na]        at org.apache.aurora.scheduler.storage.log.SnapshotStoreImpl.applySnapshot(SnapshotStoreImpl.java:63) ~[aurora-113.jar:na]        at org.apache.aurora.common.inject.TimedInterceptor.invoke(TimedInterceptor.java:83) ~[commons-113.jar:na]...{noformat}We blamed that to fee5943a95c4f08e148dc5f1366486a8c23d5773 and reverted it in https://reviews.apache.org/r/42922/. I have been unable to reproduce it in unit tests yet. Need some further investigation.,null,2,6,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,11,0,1,1,1,0,0,0
AURORA-1604,Bug,220,Resolved,Identity.role is still used in the UI leading to duplicate instances on job page,While trying to investigate AURORA-1603 found a bug in the UI that results in duplicate instances under the job page. The below code is [now gone|https://reviews.apache.org/r/42811/] but the UI is still [relying on it|https://github.com/apache/aurora/blob/89fad5a8895482b6c3fa45356137aa250d766dfe/src/main/resources/scheduler/assets/js/services.js#L32-L35]:h6.Query.java{noformat}     if (query.isSetOwner()) {        query.setRole(query.getOwner().getRole());        query.unsetOwner();      }{noformat}I was able to repo this in vagrant by creating 2 prod/hello jobs with different roles: 'vagrant' and 'www-data' (see picture attached).,null,3,1,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,3,0,1,1,1,0,0,0
AURORA-1596,Bug,220,Resolved,Invalid connection error from MyBatis.,In a scheduler with the db task store enabled we're seeing this error causing frequent shutdowns:{noformat}Jan 26 2016 3:30:00 PM com.google.common.util.concurrent.ServiceManager$ServiceListener failedSEVERE: Service TaskHistoryPruner [FAILED] has failed in the RUNNING state.org.apache.ibatis.exceptions.PersistenceException:### Error rolling back transaction.  Cause: java.sql.SQLException: Error accessing PooledConnection. Connection is invalid.### Cause: java.sql.SQLException: Error accessing PooledConnection. Connection is invalid.        at org.apache.ibatis.exceptions.ExceptionFactory.wrapException(ExceptionFactory.java:30)        at org.apache.ibatis.session.defaults.DefaultSqlSession.rollback(DefaultSqlSession.java:216)        at org.apache.ibatis.session.SqlSessionManager.rollback(SqlSessionManager.java:299)        at org.mybatis.guice.transactional.TransactionalMethodInterceptor.invoke(TransactionalMethodInterceptor.java:116)        at org.apache.aurora.common.inject.TimedInterceptor.invoke(TimedInterceptor.java:83)        at org.apache.aurora.scheduler.storage.log.LogStorage.read(LogStorage.java:570)        at org.apache.aurora.scheduler.storage.CallOrderEnforcingStorage.read(CallOrderEnforcingStorage.java:113)        at org.apache.aurora.scheduler.storage.Storage$Util.fetchTasks(Storage.java:297)        at org.apache.aurora.scheduler.pruning.TaskHistoryPruner.lambda$registerInactiveTask$103(TaskHistoryPruner.java:167)        at org.apache.aurora.scheduler.pruning.TaskHistoryPruner.lambda$failureNotifyingRunnable$101(TaskHistoryPruner.java:144)        at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)        at java.util.concurrent.FutureTask.run(FutureTask.java:266)        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:180)        at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:293)        at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)        at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)        at java.lang.Thread.run(Thread.java:745)Caused by: java.sql.SQLException: Error accessing PooledConnection. Connection is invalid.        at org.apache.ibatis.datasource.pooled.PooledConnection.checkConnection(PooledConnection.java:254)        at org.apache.ibatis.datasource.pooled.PooledConnection.invoke(PooledConnection.java:243)        at com.sun.proxy.$Proxy131.getAutoCommit(Unknown Source)        at org.apache.ibatis.transaction.jdbc.JdbcTransaction.rollback(JdbcTransaction.java:79)        at org.apache.ibatis.executor.BaseExecutor.rollback(BaseExecutor.java:249)        at org.apache.ibatis.executor.CachingExecutor.rollback(CachingExecutor.java:119)        at org.apache.ibatis.session.defaults.DefaultSqlSession.rollback(DefaultSqlSession.java:213)        ... 15 moreE0126 15:30:00.202 [AsyncProcessor-4 GuavaUtils$LifecycleShutdownListener:54] Service: TaskHistoryPruner [FAILED] failed unexpectedly. Triggering shutdown.I0126 15:30:00.202 [AsyncProcessor-4 Lifecycle:84] Shutting down applicationI0126 15:30:00.202 [AsyncProcessor-4 ShutdownRegistry$ShutdownRegistryImpl:77] Executing 2 shutdown commands.{noformat},null,3,4,1,0,Zameer Manji,Joshua Cohen,Joshua Cohen,14,0,3,0,0,0,0,0
AURORA-1614,Bug,220,Resolved,Failed sandbox initialization can cause tasks to go LOST,When we initialize the sandbox we only catch Sandbox specific error types meaning that if an unexpected error is raised the executor just hangs until the timeout is exceeded at which point the task goes lost.We should instead broadly catch exceptions raised during sandbox initialization and quickly fail tasks.Additionally the {{DockerDirectorySandbox}} was not properly catching errors raised when creating/symlinking which led to the above problem in the event of a misconfiguration. In practice this issue shouldn't have occurred in normal usage but it made development slow until I tracked down what was causing the tasks to just hang.,3,4,1,1,0,Joshua Cohen,Joshua Cohen,Joshua Cohen,1,0,0,0,0,0,0,0
AURORA-1605,Task,223,Resolved,Update recovery docs to reflect changes,We had to restore one of our clusters from backup recently and it turns out there's been some drift between the [documented process](https://github.com/apache/aurora/blob/f630bf705ac8a9de2b7b987858ada3b876f65abf/docs/storage-config.md#recovering-from-a-scheduler-backup) and what's currently necessary.Specifically we needed to disable the leader redirect filter and I believe mesos authentication.We should make sure the recovery docs are up to date with what's actually required.,null,4,5,1,0,Maxim Khutornenko,Joshua Cohen,Joshua Cohen,5,0,1,1,1,0,0,0
AURORA-1710,Task,243,Resolved,Make 'tier' required and remove support for 'production' flag in Job configuration,# -Make {{tier}} a required field in {{TaskConfig}} Thrift struct.-# Backfill {{tier}} based on {{production}} flag.# The command line tool should query scheduler and revise the choice of {{tier}} and {{production}} in job configuration if necessary.#* If {{tier}} is set set/reset {{production}} to ensure consistency.#* Otherwise set {{tier}} based on the value of {{production}}.# The command line tool should warn user if the {{production}} flag is used.Additionally it must be ensured that not providing {{tier}} or specifying {{production}} flag prevents Job from being accepted by the scheduler.,null,3,2,1,0,Mehrdad Nurolahzade,Mehrdad Nurolahzade,Mehrdad Nurolahzade,6,0,1,0,0,0,0,0
AURORA-1458,Task,243,Resolved,"Add tier into the UI ""show config"" summary",Expose {{tier}} field in the config summary if present.,null,3,3,1,0,Mehrdad Nurolahzade,Maxim Khutornenko,Maxim Khutornenko,2,0,0,0,0,0,0,0
AURORA-1690,Task,243,Resolved,Allow for isolating the executor's filesystem from the task's,Per https://github.com/apache/mesos/blob/master/docs/container-image.md#executor-dependencies-in-a-container-image we should be able to specify an image to be mounted containing the executor's filesystem. Amongst other things this will allow us to remove the requirement that task images contain a python 2.7 runtime.,null,3,7,1,0,Joshua Cohen,Joshua Cohen,Joshua Cohen,4,1,0,0,0,0,0,0
AURORA-1223,Task,243,Resolved,"Modify scheduler updater to not use ""watch_secs"" for health-check enabled jobs","When health checks are enabled in a job config scheduler updater should ignore ""watch_secs"" UpdateConfig value. ",5,3,3,1,0,Kai Huang,Maxim Khutornenko,Maxim Khutornenko,3,0,0,0,0,0,0,0
AURORA-1222,Task,243,Resolved,Modify stats and SLA metrics to properly account for STARTING,Both platform and job uptime calculations will be affected by treating STARTING as a new live state. Also a new MTTS (Median Time To Starting) metric would be great to have in addition to MTTA and MTTR.,null,3,2,1,0,Kai Huang,Maxim Khutornenko,Maxim Khutornenko,1,0,0,0,0,0,0,0
AURORA-1725,Task,243,Resolved,Expose tier configurations as a debug page ,Provide a debug page ({{/tiers}}) under Aurora UI root path to provide visibility into the available tiers. This http endpoint simply dumps the tier configuration file {{tiers.json}} into response for debugging purposes.,null,4,2,1,0,Mehrdad Nurolahzade,Mehrdad Nurolahzade,Mehrdad Nurolahzade,2,0,0,0,0,0,0,0
AURORA-1771,Task,250,Resolved,Consider scheduling multiple tasks per scheduling round,This is a placeholder for the scheduling loop perf optimization approach described in https://reviews.apache.org/r/51759/. ,null,3,4,1,0,Maxim Khutornenko,Maxim Khutornenko,Maxim Khutornenko,4,0,1,0,0,0,0,0
AURORA-1225,Task,250,Resolved,Modify executor state transition logic to rely on health checks (if enabled),Executor needs to start executing user content in STARTING and transition to RUNNING when a successful required number of health checks is reached.,null,3,6,1,0,Santhosh Kumar Shanmugham,Maxim Khutornenko,Maxim Khutornenko,11,0,1,0,0,0,0,0
AURORA-1681,Task,250,Resolved,Remove deprecated --restart-threshold option from 'aurora job restart',null,null,3,2,1,0,Joshua Cohen,Maxim Khutornenko,Maxim Khutornenko,1,0,1,0,0,0,0,0
AURORA-1014,Story,250,Resolved,Client binding_helper to resolve docker label to a stable ID at create,Follow-up from discussion on IRC:Some docker labels are mutable meaning the image a task runs in could change from restart to restart even if the rest of the task config doesn't change. This breaks assumptions that make rolling updates the safe and preferred way to deploy a new Aurora jobAdd a binding helper that resolves a docker label to an immutable image identifier at create time and make it the default for the Docker helper introduced in https://reviews.apache.org/r/28920/,5,3,9,1,0,Santhosh Kumar Shanmugham,Kevin Sweeney,Kevin Sweeney,10,0,4,1,1,0,0,0
AURORA-1767,Story,250,Closed,Shell health checker is not namespace and taskfs aware,We launch the shell health checker within the context of the host filesystem. As this is a user-defined command it makes probably sense to launch this within the container instead.,null,3,1,1,0,Joshua Cohen,Stephan Erb,Stephan Erb,0,0,1,0,0,0,0,0
AURORA-1688,Task,250,Resolved,Change framework_name default value from 'TwitterScheduler' to 'aurora',null,null,3,2,1,0,Santhosh Kumar Shanmugham,Stephan Erb,Stephan Erb,1,0,0,0,0,0,0,0
AURORA-1777,Bug,250,Resolved,aurora_admin client unable to drain hosts,"Running the following command:{noformat}aurora-admin host_drain --hosts=<some-host> <some-cluster>{noformat}Results in the following error message:{noformat}WARN] Connection error with scheduler: Unknown error talking to http://<snip>/api: Header value False must be of type str or bytes not <type 'bool'> reconnecting...{noformat}Diving deeper shows that we are setting the value of 'User-Agent' in the transport to 'False'.The root cause of this can be found in {{host_maintenance.py}} where we create the client like so:{noformat}  def __init__(self cluster verbosity wait_event=None):    self._client = AuroraClientAPI(cluster verbosity == 'verbose')    self._wait_event = wait_event or Event(){noformat}However the constructor for {{AuroraClientAPI}} is:{noformat}  def __init__(      self      cluster      user_agent      verbose=False      bypass_leader_redirect=False):    if not isinstance(cluster Cluster):      raise TypeError('AuroraClientAPI expects instance of Cluster for ""cluster"" got %s' %          type(cluster))    self._scheduler_proxy = SchedulerProxy(        cluster        verbose=verbose        user_agent=user_agent        bypass_leader_redirect=bypass_leader_redirect)    self._cluster = cluster{noformat}Notice the second argument is {{user_agent}}.This bug started to become a problem because we upgraded requests and it includes https://github.com/kennethreitz/requests/commit/be31a90906deb5553c2e703fb05cf6964ee23ed5.",null,3,2,1,0,Joshua Cohen,Zameer Manji,Zameer Manji,1,0,0,0,0,0,0,0
